[{"content":" 原书中的代码片段基于 Go 1.15，笔记则根据 Go 1.22 版本的更新进行了相应替换。\nFor 和 Range Go 语言中的经典循环在编译器看来是一个OFOR类型的节点，这个节点由以下四个部分组成：\n初始化循环的Ninit； 循环的继续条件Left； 循环体结束时执行的Right； 循环体NBody： 1 2 3 for Ninit; Left; Right { NBody } 在生成 SSA 中间代码 的阶段，cmd/compile/internal/ssagen.stmt 会将循环中的代码分成不同的块：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // stmt converts the statement n to SSA and adds it to s. func (s *state) stmt(n ir.Node) { ... switch n.Op() { ... case ir.OFOR: // OFOR: for Ninit; Left; Right { Nbody } // cond (Left); body (Nbody); incr (Right) n := n.(*ir.ForStmt) base.Assert(!n.DistinctVars) bCond := s.f.NewBlock(ssa.BlockPlain) bBody := s.f.NewBlock(ssa.BlockPlain) bIncr := s.f.NewBlock(ssa.BlockPlain) bEnd := s.f.NewBlock(ssa.BlockPlain) ... } } 这些代码块之间的连接表示汇编语言中的跳转关系，与我们理解的for循环控制结构没有太多的差别：\n除了使用经典的三段式循环之外，Go 语言还引入了另一个关键字range帮助我们快速遍历数组、切片、哈希表以及管道等集合类型。编译器会在编译期间将所有 for-range 循环变成普通 for 循环，即将ORANGE类型的节点转换成OFOR节点。我们将按照元素类型依次介绍遍历数组和切片、哈希表、字符串以及管道的过程。\n数组和切片 对于数组和切片来说，Go 语言有三种不同的遍历方式，分别对应着代码中的不同条件。它们会在 cmd/compile/internal/walk.walkRange 函数中转换成不同的控制逻辑：\n遍历数组和切片清空元素的情况； 使用for range a {}遍历数组和切片； 使用for i := range a {}遍历数组和切片； 使用for i, elem := range a {}遍历数组和切片； 遍历清空元素 相比于依次清除数组或者切片中的数据，Go 语言会直接使用 runtime.memclrNoHeapPointers 或者 runtime.memclrHasPointers 清除目标数组内存空间中的全部数据，并在执行完成后更新遍历数组的索引：\n1 2 3 4 5 6 7 8 9 10 11 12 // 原代码 for i := range a { a[i] = zero } // 优化后 if len(a) != 0 { hp = \u0026a[0] hn = len(a)*sizeof(elem(a)) memclrNoHeapPointers(hp, hn) i = len(a) - 1 } for range a{} 调用者不关心数组a的索引和元素，循环会被编译器转换成如下形式：\n1 2 3 4 5 6 ha := a hv1 := 0 hn := len(ha) for ; hv1 \u003c hn; hv1++ { ... } for i := range a {} 调用者不关心数组的元素，只关心遍历数组使用的索引。循环会被编译器转换成如下形式：\n1 2 3 4 5 6 7 8 ha := a hv1 := 0 hn := len(ha) for ; hv1 \u003c hn; hv1++ { // 传递遍历数组时的索引 v1 := hv1 ... } for i, elem := range a {} 调用者同时关心数组的索引和切片，循环会被编译器转换成如下形式：\n1 2 3 4 5 6 7 8 ha := a hv1 := 0 hn := len(ha) for ; hv1 \u003c hn; hv1++ { // 变量在循环内部定义 v1, v2 := hv1, ha[hv1] ... } 对于所有的 for-range 循环，Go 语言都会在编译期将原切片或者数组赋值给一个新变量ha，在赋值的过程中发生了拷贝。而我们又通过len关键字预先获取了切片的长度，所以在循环中追加新的元素并不会改变循环执行的次数：\n1 2 3 4 5 6 7 8 9 10 11 func main() { arr := []int{1, 2, 3} for _, v := range arr { arr = append(arr, v) } fmt.Println(arr) } // 循环不会永动 $ go run main.go 1 2 3 1 2 3 另外，之前版本的 Go 语言会在循环外部定义变量v2，每次迭代v2的地址均不变，因此会出现如下 Bug：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { arr := []int{1, 2, 3} newArr := []*int{} for _, v := range arr { fmt.Printf(\"origin addr: %p value: %v\\n\", \u0026v, v) // newArr = append(newArr, \u0026arr[i]) newArr = append(newArr, \u0026v) } for _, v := range newArr { fmt.Printf(\"addr: %p value: %v\\n\", v, *v) } } // go 1.21 $ go run main.go origin addr: 0xc0000a0000 value: 1 origin addr: 0xc0000a0000 value: 2 origin addr: 0xc0000a0000 value: 3 addr: 0xc0000a0000 value: 3 addr: 0xc0000a0000 value: 3 addr: 0xc0000a0000 value: 3 Go 语言在 1.22 版本修改了控制结构的执行语义，短声明定义的循环变量将在每次迭代重新定义，详见：Proposal: Less Error-Prone Loop Variable Scoping。因此执行上述代码会输出我们期望得到的结果：\n1 2 3 4 5 6 7 8 // go 1.22 $ go run main.go origin addr: 0xc000012028 value: 1 origin addr: 0xc000012060 value: 2 origin addr: 0xc000012068 value: 3 addr: 0xc000012028 value: 1 addr: 0xc000012060 value: 2 addr: 0xc000012068 value: 3 哈希表 runtime.hiter 是 Go 语言内部用于哈希表迭代的结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type hiter struct { key unsafe.Pointer // 指向当前迭代的键，nil 代表迭代结束 elem unsafe.Pointer // 指向当前迭代的值 t *maptype // 指向当前 map 的类型信息 h *hmap // 指向当前正在迭代的 map buckets unsafe.Pointer // 指向迭代初始化时的桶 bptr *bmap // 指向当前迭代的桶 overflow *[]*bmap oldoverflow *[]*bmap startBucket uintptr offset uint8 wrapped bool B uint8 i uint8 bucket uintptr checkBucket uintptr } 在遍历哈希表时，编译器会使用 runtime.mapiterinit 和 runtime.mapiternext 重写原始的 for-range 循环。前者首先初始化 runtime.hiter 结构体中的字段并保存当前桶的状态，然后随机选择一个桶作为遍历的起始位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func mapiterinit(t *maptype, h *hmap, it *hiter) { it.t = t it.h = h // grab snapshot of bucket state it.B = h.B it.buckets = h.buckets if t.Bucket.PtrBytes == 0 { h.createOverflow() it.overflow = h.extra.overflow it.oldoverflow = h.extra.oldoverflow } // decide where to start r := uintptr(rand()) it.startBucket = r \u0026 bucketMask(h.B) it.offset = uint8(r \u003e\u003e h.B \u0026 (bucketCnt - 1)) // iterator state it.bucket = it.startBucket mapiternext(it) } runtime.mapiternext 函数的执行主要分为桶的选择和桶内元素遍历两部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 func mapiternext(it *hiter) { h := it.h t := it.t bucket := it.bucket // b 指向待遍历的桶 b := it.bptr i := it.i checkBucket := it.checkBucket next: if b == nil { if bucket == it.startBucket \u0026\u0026 it.wrapped { // 当不存在待遍历的桶时，结束迭代 it.key = nil it.elem = nil return } if h.growing() \u0026\u0026 it.B == h.B { // 哈希表正在扩容中，处理扩容逻辑 ... } else { // 待遍历的桶为空时，计算需要遍历的新桶地址 b = (*bmap)(add(it.buckets, bucket*uintptr(t.BucketSize))) checkBucket = noCheck } bucket++ if bucket == bucketShift(it.B) { bucket = 0 it.wrapped = true } i = 0 } for ; i \u003c bucketCnt; i++ { offi := (i + it.offset) \u0026 (bucketCnt - 1) // 根据偏移量计算桶内键值对指针 k := add(unsafe.Pointer(b), dataOffset+uintptr(offi)*uintptr(t.KeySize)) e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.KeySize)+uintptr(offi)*uintptr(t.ValueSize)) if checkBucket != noCheck \u0026\u0026 !h.sameSizeGrow() { // 哈希表正在增量扩容中，处理扩容逻辑 ... } if (b.tophash[offi] != evacuatedX \u0026\u0026 b.tophash[offi] != evacuatedY) || !(t.ReflexiveKey() || t.Key.Equal(k, k)) { // 目标元素未迁移，k 和 e 为准确数据，可以直接返回 it.key = k it.elem = e } else { // 目标元素已迁移，需要通过 runtime.mapaccessK 获取键值对 rk, re := mapaccessK(t, h, k) it.key = rk it.elem = re } it.bucket = bucket it.i = i + 1 it.checkBucket = checkBucket return } // 如果当前桶已迭代完成，继续迭代溢出桶 b = b.overflow(t) i = 0 goto next } 由此可见，哈希表的遍历过程为：首先随机选出一个正常桶开始遍历，然后遍历其所有的溢出桶，最后按照索引顺序遍历其他的正常桶和溢出桶，直到全部桶遍历完成。\n哈希表遍历的随机性也会导致一些奇怪现象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func main() { var m = map[string]int{ \"A\": 21, \"B\": 22, \"C\": 23, } counter := 0 for k, v := range m { if counter == 0 { m[\"D\"] = 20 } counter++ fmt.Println(k, v) } fmt.Println(counter) } // 可能的结果 $ go run main.go B 22 A 21 C 23 3 多次执行上述代码可能出现counter为 3 且输出结果不包含D的情况。这是因为遍历开始时随机选择的桶为空桶，而D又恰好插入了该桶。\n字符串 字符串的遍历过程与数组、切片和哈希表非常相似，只是会将字符串中的字节转换成rune类型。for i, r := range s {}的结构会被转换成如下所示的形式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ha := s for hv1 := 0; hv1 \u003c len(ha); { hv1t := hv1 hv2 := rune(ha[hv1]) // 当前字节是常规 ASCII 码，只占用一个字节长度 if hv2 \u003c utf8.RuneSelf { hv1++ } else { // 占用多个字节，使用 runtime.decoderune 解码 hv2, hv1 = decoderune(ha, hv1) } v1, v2 := hv1t, hv2 } 管道 使用range遍历管道也是比较常见的做法，一个形如for v := range ch {}的语句最终会被转换成如下的格式：\n1 2 3 4 5 6 7 8 9 10 11 ha := a // 从管道中取出等待处理的值并阻塞当前协程 hv1, hb := \u003c-ha // 若当前值不存在，则管道已被关闭 for ; hb != false; hv1, hb = \u003c-ha { // 若当前值存在，将其赋给 v1 v1 := hv1 // 清除 hv1 中的数据，重新陷入阻塞等待新数据 hv1 = nil ... } 这里的代码可能与编译器生成的稍微有一些出入，但是结构和效果是完全相同的。\nSelect C 语言中的系统调用 select 可以同时监听多个文件描述符的可读或者可写的状态，而 Go 语言中的select关键字也能让 Goroutine 同时等待多个管道可读或者可写。\nselect是与switch相似的控制结构，但与后者不同的是，前者中的case表达式必须是管道的收发操作。当select中的两个case同时触发时，会随机执行其中一个以避免饥饿问题的出现。\n数据结构 Go 语言的源代码中没有select对应的结构体，但其控制结构中的case关键字是由 runtime.scase 结构体表示的：\n1 2 3 4 type scase struct { c *hchan // chan elem unsafe.Pointer // data element } 非default的case都与管道的发送和接收有关，因此该结构体中也包含了一个 runtime.hchan 类型的字段存储case中使用的管道。\n实现原理 编译器在中间代码生成期间会根据以下四种情况对控制语句进行优化：\nselect不存在任何的case； select只存在一个case； select存在两个case，其中一个case是default； select存在多个case； 上述过程均发生在 cmd/compile/internal/walk.walkSelectCases 函数中。\n直接阻塞 如果select中不存在任何case：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func walkSelectCases(cases []*ir.CommClause) []ir.Node { ncas := len(cases) if ncas == 0 { // mkcallstmt 调用 runtime.block 函数 return []ir.Node{mkcallstmt(\"block\")} } ... } func block() { // 当前 Goroutine 让出对处理器的使用权 // 传入等待原因 waitReasonSelectNoCases gopark(nil, nil, waitReasonSelectNoCases, traceBlockForever, 1) } 因此，空的select语句会直接阻塞当前 Goroutine，导致其进入无法被唤醒的永久休眠状态。\n单一管道 如果当前select中只包含一个 case，那么编译器会将其改写为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 改写前 select { case v, ok \u003c-ch: // case ch \u003c- v ... } // 改写后 if ch == nil { // 若 case 中的 ch 为空，当前 Goroutine 会被挂起并陷入永久休眠 block() } v, ok := \u003c-ch // case ch \u003c- v ... 非阻塞操作 当select中仅包含两个 case，并且其中一个是 default 时，Go 语言的编译器就会认为这是一次非阻塞的收发操作。cmd/compile/internal/walk.walkSelectCases 会对这种情况单独处理。\n发送 当case中表达式的类型是OSEND时，编译器会使用条件语句和 runtime.selectnbsend 函数改写代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 改写前 select { case ch \u003c- v: ... foo default: ... bar } // 改写后 if selectnbsend(ch, v) { ... foo } else { ... bar } runtime.selectnbsend 向 runtime.chansend 函数传入的block参数为false，因此当无缓冲管道不存在等待的接收者或有缓冲管道的缓冲区空间不足时，当前 Goroutine 不会被阻塞而是直接返回。详见：发送数据。\n1 2 3 func selectnbsend(c *hchan, elem unsafe.Pointer) (selected bool) { return chansend(c, elem, false, getcallerpc()) } 接收 当case中表达式的类型是OSELRECV2时，编译器会使用条件语句和 runtime.selectnbrecv 函数改写代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 改写前 select { case v, ok = \u003c-c: ... foo default: ... bar } // 改写后 if selected, ok = selectnbrecv(\u0026v, c); selected { ... foo } else { ... bar } runtime.selectnbrecv 向 runtime.chanrecv 函数传入的block参数为false，因此当不存在等待的发送者且缓冲区中也没有数据时，当前 Goroutine 不会被阻塞而是直接返回。详见：接收数据。\n1 2 3 func selectnbrecv(elem unsafe.Pointer, c *hchan) (selected, received bool) { return chanrecv(c, elem, false) } 常见流程 在默认情况下，编译器会使用如下流程处理select语句：\n将所有的case转换成包含管道和类型等信息的 runtime.scase 结构体； 调用运行时函数 runtime.selectgo 从多个准备就绪的管道中选择一个可执行的 runtime.scase 结构体； 通过for循环生成一组if语句，从而判断自己是否为被选中的case。 上述过程可以用示例代码表示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 sel := make([]scase, len(cases)) nsends, nrecvs := 0, 0 dflt := -1 for i, rc := range cases { var j int switch rc.dir { case selectDefault: dflt = i continue case selectSend: j = nsends nsends++ case selectRecv: nrecvs++ j = len(cases) - nrecvs } sel[j] = scase{c: rc.ch, elem: rc.val} } order := make([]uint16, 2*(nsends+nrecvs)) var pc0 *uintptr chosen, recvOK := selectgo(\u0026sel[0], \u0026order[0], pc0, nsends, nrecvs, dflt == -1) if chosen == 0 { ... break } if chosen == 1 { ... break } ... if chosen == len(cases) { ... break } Defer Go 语言的defer会在当前函数返回前执行传入的函数，经常用于关闭文件描述符、关闭数据库连接以及解锁资源。\n数据结构 runtime._defer 结构体是延迟调用链表中的一个元素，所有的结构体都会通过link字段串联成链表：\n1 2 3 4 5 6 7 8 9 10 11 12 type _defer struct { heap bool rangefunc bool // true for rangefunc list sp uintptr // sp at time of defer pc uintptr // pc at time of defer fn func() // can be nil for open-coded defers link *_defer // next defer on G; can point to either heap or stack! // If rangefunc is true, *head is the head of the atomic linked list // during a range-over-func execution. head *atomic.Pointer[_defer] } fn字段表示defer关键字传入的函数，曾经是*funcval类型，其指向的函数可以拥有任意签名。而在 runtime: use func() for deferred functions 提交之后，该字段就变成了没有参数和返回值的func()类型。这是因为 Go 语言会在类型检查阶段调用 cmd/compile/internal/typecheck.normalizeGoDeferCall 将OGO和ODEFER声明中形如f(x, y)的函数标准化为：\n1 2 x1, y1 := x, y // added to init func() { f(x1, y1) }() // result 执行机制 中间代码生成阶段的 cmd/compile/internal/ssagen.stmt 负责处理程序中的defer关键字，该函数会根据情况使用三种不同的执行机制：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // stmt converts the statement n to SSA and adds it to s. func (s *state) stmt(n ir.Node) { ... switch n.Op() { ... case ir.ODEFER: n := n.(*ir.GoDeferStmt) ... if s.hasOpenDefers { s.openDeferRecord(n.Call.(*ir.CallExpr)) // 开放编码 } else { d := callDefer // 堆中分配 if n.Esc() == ir.EscNever \u0026\u0026 n.DeferAt == nil { d = callDeferStack // 栈上分配 } s.call(n.Call.(*ir.CallExpr), d, false, n.DeferAt) } } } 早期的 Go 语言会在堆上分配 runtime._defer 结构体，不过实现的性能较差； 1.13 版本的 Go 语言引入栈上分配的defer，减少了 30% 的额外开销，详见：runtime: allocate defer records on the stack； 1.14 版本的 Go 语言引入了基于开放编码的defer，使其额外开销可以忽略不计，详见：runtime: make defers low-cost through inline code and extra funcdata。 堆中分配 1 2 3 4 5 func main() { for i := 0; i \u003c unpredictableNumber; i++ { defer fmt.Println(i) // Heap-allocated defer } } 编译器无法预测示例代码中循环的迭代次数，runtime._defer 的数量会在运行期间改变，因此该结构体只能在堆中分配。在编译器看来，defer也是函数调用，因此会执行 cmd/compile/internal/ssagen.call 为其生成中间代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func (s *state) call(n *ir.CallExpr, k callKind, returnResultAddr bool, deferExtra ir.Expr) *ssa.Value { ... var call *ssa.Value ... switch { case k == callDefer: // 运行期间将调用 runtime.deferproc sym := ir.Syms.Deferproc aux := ssa.StaticAuxCall(sym, s.f.ABIDefault.ABIAnalyzeTypes(ACArgs, ACResults)) call = s.newValue0A(ssa.OpStaticLECall, aux.LateExpansionResultType(), aux) ... } } Go 语言的编译器不仅将defer转换成了 runtime.deferproc，还通过以下三个步骤为所有调用defer的函数末尾插入 runtime.deferreturn：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // cmd/compile/internal/walk.walkStmt func walkStmt(n ir.Node) ir.Node { ... switch n.Op() { case ir.ODEFER: n := n.(*ir.GoDeferStmt) // 设置当前函数的 hasdefer 属性 ir.CurFunc.SetHasDefer(true) ... fallthrough ... } } // cmd/compile/internal/ssagen.buildssa func buildssa(fn *ir.Func, worker int) *ssa.Func { ... var s state // 更新 state 的 hasdefer 字段 s.hasdefer = fn.HasDefer() ... } // cmd/compile/internal/ssagen.exit func (s *state) exit() *ssa.Block { if s.hasdefer { ... // 在函数返回前插入 runtime.deferreturn s.rtcall(ir.Syms.Deferreturn, true, nil) } ... } 上述两个函数是defer运行时机制的入口，分别承担了不同的工作：\nruntime.deferproc 负责创建新的延迟调用； runtime.deferreturn 负责在函数调用结束时执行所有的延迟调用。 创建延迟调用 1 2 3 4 5 6 7 8 9 10 11 12 func deferproc(fn func()) { gp := getg() d := newdefer() // 将 _defer 追加到链表最前面 d.link = gp._defer gp._defer = d d.fn = fn d.pc = getcallerpc() d.sp = getcallersp() return0() } runtime.newdefer 的作用是想尽办法获得 runtime._defer 结构体，包含三种方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 func newdefer() *_defer { var d *_defer mp := acquirem() pp := mp.p.ptr() if len(pp.deferpool) == 0 \u0026\u0026 sched.deferpool != nil { lock(\u0026sched.deferlock) for len(pp.deferpool) \u003c cap(pp.deferpool)/2 \u0026\u0026 sched.deferpool != nil { // 从调度器的延迟调用缓存池 sched.deferpool 中取出 _defer d := sched.deferpool sched.deferpool = d.link d.link = nil // 并追加到当前 Goroutine 的缓存池中 pp.deferpool = append(pp.deferpool, d) } unlock(\u0026sched.deferlock) } if n := len(pp.deferpool); n \u003e 0 { // 从 Goroutine 的延迟调用缓存池 pp.deferpool 中取出 _defer d = pp.deferpool[n-1] pp.deferpool[n-1] = nil pp.deferpool = pp.deferpool[:n-1] } releasem(mp) mp, pp = nil, nil if d == nil { // 在堆上创建一个新的 _defer d = new(_defer) } d.heap = true return d } 无论使用哪种方式，runtime._defer 结构体都会被追加到所在 Goroutine _defer链表的最前面。defer关键字的插入顺序是从后向前的，而执行则是从前向后的，这也解释了为什么后调用的defer会先执行：\n1 2 3 4 5 6 7 8 9 10 func main() { for i := 0; i \u003c 3; i++ { defer fmt.Println(i) } } $ go run main.go 2 1 0 另外，runtime.deferproc 在创建延迟调用时会立刻复制函数的参数，因此后者不会等到真正执行时计算：\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { n := 1 if n == 1 { defer fmt.Println(n) n += 100 } fmt.Println(n) } $ go run main.go 101 1 执行延迟调用 runtime.deferreturn 会在函数返回之前执行 Goroutine _defer链表中注册的所有函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func deferreturn() { var p _panic p.deferreturn = true p.start(getcallerpc(), unsafe.Pointer(getcallersp())) for { // 获取下一个要执行的 defer 函数 fn, ok := p.nextDefer() // 若没有更多的 defer 函数要执行，则退出循环 if !ok { break } // 执行 defer 函数 fn() } } 栈上分配 当defer在函数体中最多执行一次时，runtime._defer 会在编译期间被分配到栈上：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // cmd/compile/internal/ssagen.call func (s *state) call(n *ir.CallExpr, k callKind, returnResultAddr bool, deferExtra ir.Expr) *ssa.Value { ... var call *ssa.Value if k == callDeferStack { // 在栈上初始化 defer 结构体 t := deferstruct() // 运行期间将调用 runtime.deferprocStack ACArgs = append(ACArgs, types.Types[types.TUINTPTR]) aux := ssa.StaticAuxCall(ir.Syms.DeferprocStack, s.f.ABIDefault.ABIAnalyzeTypes(ACArgs, ACResults)) callArgs = append(callArgs, addr, s.mem()) call = s.newValue0A(ssa.OpStaticLECall, aux.LateExpansionResultType(), aux) call.AddArgs(callArgs...) call.AuxInt = int64(types.PtrSize) } ... } runtime.deferprocStack 只需要设置一些未在编译期间初始化的字段，就可以把defer结构体追加到 Goroutine 的延迟调用链表中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func deferprocStack(d *_defer) { gp := getg() d.heap = false d.rangefunc = false d.sp = getcallersp() d.pc = getcallerpc() // The lines below implement: // d.panic = nil // d.fd = nil // d.link = gp._defer // d.head = nil // gp._defer = d *(*uintptr)(unsafe.Pointer(\u0026d.link)) = uintptr(unsafe.Pointer(gp._defer)) *(*uintptr)(unsafe.Pointer(\u0026d.head)) = 0 *(*uintptr)(unsafe.Pointer(\u0026gp._defer)) = uintptr(unsafe.Pointer(d)) return0() } 除了分配位置不同，栈上分配和堆中分配并没有本质区别，前者可以适用于绝大多数场景。\n开放编码 开放编码将defer调用直接内联到函数末尾以及汇编代码中每一个返回语句之前，仅在满足以下条件时启用：\n函数的defer数量少于或者等于 8 个； 函数的defer关键字不能在循环中执行； 函数的return语句与defer语句的乘积小于或者等于 15 个。 否则，最终生成的二进制代码将会非常臃肿。除上述几个条件外，也有其他条件会限制开放编码的使用。不过它们都是不太重要的细节，这里不会深究。\n启用优化 Go 语言会在编译期间决定是否启用开放编码。在编译器生成中间代码之前，cmd/compile/internal/walk.walkStmt 会 修改已经生成的抽象语法树，设置函数体上的OpenCodedDeferDisallowed属性：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func walkStmt(n ir.Node) ir.Node { ... case ir.ODEFER: ... // 函数的 defer 数量大于 8 if ir.CurFunc.NumDefers \u003e maxOpenDefers || n.DeferAt != nil { ir.CurFunc.SetOpenCodedDeferDisallowed(true) } // defer 在循环中出现 if n.Esc() != ir.EscNever { ir.CurFunc.SetOpenCodedDeferDisallowed(true) } fallthrough ... } 我们在 SSA 中间代码生成阶段的 cmd/compile/internal/ssagen.buildssa 函数中也能够看到启用开放编码优化的其他条件：\n1 2 3 4 5 6 7 8 9 10 11 func buildssa(fn *ir.Func, worker int) *ssa.Func { ... s.hasOpenDefers = base.Flag.N == 0 \u0026\u0026 s.hasdefer \u0026\u0026 !s.curfn.OpenCodedDeferDisallowed() ... if s.hasOpenDefers \u0026\u0026 // return 和 defer 语句数量的乘积大于 15 s.curfn.NumReturns*s.curfn.NumDefers \u003e 15 { s.hasOpenDefers = false } ... } 延迟记录 延迟比特和延迟记录是使用开放编码实现defer的两个最重要结构，Go 语言会在编译期间调用 cmd/compile/internal/ssagen.buildssa 在栈上初始化大小为 8 个比特的deferBits变量。\n该变量中的每个比特位都表示对应的defer关键字是否需要被执行。如下图所示，倒数第二个比特位被设置成了 1，那么其对应的函数将在函数返回前执行：\n编译器还会通过 cmd/compile/internal/ssagen.openDeferRecord 添加代码以评估和存储defer调用的函数，并记录有关defer的信息。传入defer的函数和参数存储在 cmd/compile/internal/ssagen.openDeferInfo 结构体中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 func (s *state) openDeferRecord(n *ir.CallExpr) { ... opendefer := \u0026openDeferInfo{ n: n, } fn := n.Fun closureVal := s.expr(fn) closure := s.openDeferSave(fn.Type(), closureVal) opendefer.closureNode = closure.Aux.(*ir.Name) if !(fn.Op() == ir.ONAME \u0026\u0026 fn.(*ir.Name).Class == ir.PFUNC) { opendefer.closure = closure } index := len(s.openDefers) s.openDefers = append(s.openDefers, opendefer) bitvalue := s.constInt8(types.Types[types.TUINT8], 1\u003c\u003cuint(index)) newDeferBits := s.newValue2(ssa.OpOr8, types.Types[types.TUINT8], s.variable(deferBitsVar, types.Types[types.TUINT8]), bitvalue) s.vars[deferBitsVar] = newDeferBits s.store(types.Types[types.TUINT8], s.deferBitsAddr, newDeferBits) } 在函数返回前，cmd/compile/internal/ssagen.openDeferExit 将处理所有使用开放编码优化的defer关键字，检查延迟比特的每个位以确定是否执行了相应的defer语句：\n1 2 3 4 5 6 7 8 9 10 // cmd/compile/internal/ssagen.exit func (s *state) exit() *ssa.Block { if s.hasdefer { if s.hasOpenDefers { ... s.openDeferExit() } } ... } 上述优化过程可以用伪码表示为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 deferBits := 0 // 初始化延迟比特 deferBits |= 1\u003c\u003c0 // 延迟比特最后一位设为 1 _f1, _a1 := f1, a1 // 保存函数及参数 if condition { deferBits |= 1\u003c\u003c1 // 若条件满足，延迟比特倒数第二位设为 1 _f2, _a2 := f2, a2 // 保存函数及参数 } exit: if deferBits \u0026 1\u003c\u003c1 != 0 { // 00000011 \u0026 00000010 != 0 deferBits \u0026^= 1\u003c\u003c1 // 将倒数第二位复原为 0 以进行下一次判断 _f2(_a2) } if deferBits \u0026 1\u003c\u003c0 != 0 { // 00000001 \u0026 00000001 != 0 deferBits \u0026^= 1\u003c\u003c0 _f1(_a1) } 综上所述，开放编码使用延迟比特和 cmd/compile/internal/ssagen.openDeferInfo 结构体存储defer的相关信息，将其直接在当前函数内展开，并在返回前根据延迟比特位决定是否执行调用。这种方法只使用了少量的位运算指令和内存资源，因此性能最好。\nPanic \u0026 Recover panic能够改变程序的控制流。调用panic后会立刻停止执行当前函数的剩余代码，并递归执行当前 Goroutine 中的defer； recover可以中止panic造成的程序崩溃，不过只能在defer中发挥作用。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func badCall() { panic(\"bad end\") } func test() { defer func() { if e := recover(); e != nil { fmt.Printf(\"Panicing %s\\r\\n\", e) } }() badCall() fmt.Printf(\"After bad call\\r\\n\") // 无法到达 } func main() { fmt.Printf(\"Calling test\\r\\n\") test() fmt.Printf(\"Test completed\\r\\n\") } $ go run main.go Calling test Panicing bad end Test completed 数据结构 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 type _panic struct { argp unsafe.Pointer // 指向发生 panic 时执行 defer 调用的参数的指针 arg any // panic 的参数 link *_panic // 指向更早的 runtime._panic // 调用 _panic.start 时的程序计数器和栈指针 startPC uintptr startSP unsafe.Pointer // 调用 defer 时的栈帧 sp unsafe.Pointer lr uintptr fp unsafe.Pointer // 存储 panic 应当跳转回去的程序计数器位置 retpc uintptr // 用于处理开放编码优化的 defer deferBitsPtr *uint8 slotsPtr unsafe.Pointer recovered bool // 是否已经被 recover 恢复 goexit bool // 保证 rutime.Goexit 不会被 defer 中的 // panic 和 recover 取消 deferreturn bool } runtime._panic 中的link字段与 runtime._defer 类似，因此panic关键字也支持嵌套调用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func main() { defer fmt.Println(\"in main\") defer func() { defer func() { panic(\"panic again and again\") }() panic(\"panic again\") }() panic(\"panic once\") } $ go run main.go in main panic: panic once panic: panic again panic: panic again and again goroutine 1 [running]: ... exit status 2 程序崩溃 编译器会将关键字panic转换成 runtime.gopanic：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func gopanic(e any) { ... // 初始化 runtime._panic var p _panic p.arg = e runningPanicDefers.Add(1) // *_panic.start 设置 _panic 结构体的字段 // 并将其添加到所在 Goroutine _panic 链表的最前端 p.start(getcallerpc(), unsafe.Pointer(getcallersp())) // 不断从当前 Goroutine _defer 链表中获取并执行 defer 调用 for { fn, ok := p.nextDefer() if !ok { break } fn() } preprintpanics(\u0026p) // 终止整个程序 fatalpanic(\u0026p) *(*int)(nil) = 0 } 该函数最后调用的 runtime.fatalpanic 实现了无法被恢复的程序崩溃：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func fatalpanic(msgs *_panic) { pc := getcallerpc() sp := getcallersp() gp := getg() var docrash bool systemstack(func() { if startpanic_m() \u0026\u0026 msgs != nil { runningPanicDefers.Add(-1) // 打印全部 panic 消息以及调用时传入的参数 printpanics(msgs) } docrash = dopanic_m(gp, pc, sp) }) if docrash { crash() } // 退出当前程序并返回错误码 2 systemstack(func() { exit(2) }) *(*int)(nil) = 0 } 崩溃恢复 编译器会将关键字recover转换为 runtime.gorecover：\n1 2 3 4 5 6 7 8 9 10 11 func gorecover(argp uintptr) any { gp := getg() p := gp._panic if p != nil \u0026\u0026 !p.goexit \u0026\u0026 !p.recovered \u0026\u0026 argp == uintptr(p.argp) { // 修改 runtime._panic 的 recovered 字段 p.recovered = true // 返回 panic 的参数 return p.arg } return nil } p != nil：如果当前 Goroutine 没有panic，该函数将返回nil。因此，recover只能在defer调用中生效：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main() { defer fmt.Println(\"in main\") if err := recover(); err != nil { fmt.Println(err) } panic(\"unknown err\") } $ go run main.go in main panic: unknown err goroutine 1 [running]: ... exit status 2 argp == uintptr(p.argp)：runtime.gorecover 的参数argp是当前栈帧的栈指针，而p.argp则是发生panic时执行defer调用的参数的指针。因此，下面两段代码，第一段的panic可以recover，第二段则不会：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // 第一段 func main() { defer func() { // argp 为 匿名函数的栈指针 recover() }() panic(\"ooo\") } // 第二段 func main() { // argp 为 main 函数的栈指针 defer recover() panic(\"ooo\") } runtime.gorecover 中并不包含恢复程序的逻辑，这项工作是由 runtime.recovery 完成的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 func gopanic(e any) { ... for { fn, ok := p.nextDefer() if !ok { break } fn() } ... } func (p *_panic) nextDefer() (func(), bool) { gp := getg() if !p.deferreturn { if gp._panic != p { throw(\"bad panic stack\") } if p.recovered { mcall(recovery) // 不会返回 throw(\"recovery failed\") } } ... } func recovery(gp *g) { p := gp._panic pc, sp, fp := p.retpc, uintptr(p.sp), uintptr(p.fp) p0, saveOpenDeferState := p, p.deferBitsPtr != nil \u0026\u0026 *p.deferBitsPtr != 0 ... gp.sched.sp = sp gp.sched.pc = pc gp.sched.lr = 0 ... // 将函数的返回值设置为 1 gp.sched.ret = 1 // 根据 pc 和 sp 跳回 defer 关键字调用的位置 gogo(\u0026gp.sched) } runtime.deferproc的 注释 表明，当函数的返回值为 1 时，编译器生成的代码会直接跳转到 runtime.deferreturn 并恢复到正常的执行流程。\nMake \u0026 New make：初始化内置的数据结构，如切片、哈希表和管道； new：根据传入的类型分配一片内存空间并返回指向这片内存空间的指针； Make 在类型检查阶段，编译器会将代表make关键字的OMAKE节点根据参数类型转换成OMAKESLICE、OMAKEMAP和OMAKECHAN三种不同的节点。这些节点调用不同的运行时函数初始化对应的数据结构。\nNew 编译器在中间代码生成的 遍历和替换 阶段调用 cmd/compile/internal/walk.walkExpr1 和 cmd/compile/internal/walk.walkNew 决定变量的分配方式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func walkExpr1(n ir.Node, init *ir.Nodes) ir.Node { switch n.Op() { ... case ir.ONEW: n := n.(*ir.UnaryExpr) return walkNew(n, init) ... } } func walkNew(n *ir.UnaryExpr, init *ir.Nodes) ir.Node { t := n.Type().Elem() // 该类型无法分配到堆上 if t.NotInHeap() { base.Errorf(\"%v can't be allocated in Go; it is incomplete (or unallocatable)\", n.Type().Elem()) } // 变量没有逃逸到堆上 if n.Esc() == ir.EscNone { // 类型的大小超过了编译器允许的隐式栈变量的最大大小 if t.Size() \u003e ir.MaxImplicitStackVarSize { base.Fatalf(\"large ONEW with EscNone: %v\", n) } // 在栈上分配变量 tmp 并将 \u0026tmp 表达式附加到 init return stackTempAddr(init, t) } // 计算类型的大小和对齐方式 types.CalcSize(t) n.MarkNonNil() return n } 如果变量需要被分配到堆上，new关键字后续将由 cmd/compile/internal/ssagen.*state.expr 等函数处理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func (s *state) expr(n ir.Node) *ssa.Value { return s.exprCheckPtr(n, true) } func (s *state) exprCheckPtr(n ir.Node, checkPtrOK bool) *ssa.Value { ... switch n.Op() { ... case ir.ONEW: n := n.(*ir.UnaryExpr) var rtype *ssa.Value if x, ok := n.X.(*ir.DynamicType); ok \u0026\u0026 x.Op() == ir.ODYNAMICTYPE { rtype = s.expr(x.RType) } return s.newObject(n.Type().Elem(), rtype) ... } } func (s *state) newObject(typ *types.Type, rtype *ssa.Value) *ssa.Value { // 若申请的空间为 0，则返回一个表示空指针的 Zerobase if typ.Size() == 0 { return s.newValue1A(ssa.OpAddr, types.NewPtr(typ), ir.Syms.Zerobase, s.sb) } if rtype == nil { rtype = s.reflectType(typ) } // 将关键字转换为 runtime.Newobject return s.rtcall(ir.Syms.Newobject, true, []*types.Type{types.NewPtr(typ)}, rtype)[0] } runtime.newobject 根据传入类型所占空间的大小，调用 runtime.mallocgc 在堆中申请一块内存并返回指向它的指针：\n1 2 3 func newobject(typ *_type) unsafe.Pointer { return mallocgc(typ.Size_, typ, true) } 使用var关键字初始化变量的过程与之类似：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // cmd/compile/internal/ssagen.*state.stmt func (s *state) stmt(n ir.Node) { ... switch n.Op() { ... case ir.ODCL: n := n.(*ir.Decl) // 若变量逃逸到堆上 if v := n.X; v.Esc() == ir.EscHeap { s.newHeapaddr(v) } ... } } // cmd/compile/internal/ssagen.*state.newHeapaddr func (s *state) newHeapaddr(n *ir.Name) { s.setHeapaddr(n.Pos(), n, s.newObject(n.Type(), nil)) } Future Work 在阅读源码时发现了书中未提到的 runtime.deferrangefunc 和 runtime.deferprocat 函数，它们的作用是什么？ 两者用于实现 Go 1.22 版本的新特性：Go Wiki: Rangefunc Experiment； ","description":"","tags":["Go"],"title":"《Go 语言设计与实现》读书笔记：常用关键字","uri":"/posts/go-common-keywords-note/"},{"content":" 原书中的代码片段基于 Go 1.15，笔记则根据 Go 1.22 版本的更新进行了相应替换。\n函数调用 函数是 Go 语言的一等公民，这意味着它可以作为参数传递给其他函数、作为其他函数的返回以及分配给变量或存储在数据结构中。\n调用惯例 调用惯例（Calling Convention）是调用方与被调用方对参数和返回值传递的约定，它是 应用二进制接口（Application Binary Interface，ABI）的一部分。\nC 语言的调用惯例详见 过程，其主要特点为：\n六个以及六个以下的参数会按从左往右的顺序分别使用 rdi、rsi、rdx、rcx、r8 和 r9 寄存器传递； 六个以上的参数会使用栈传递，函数的参数会按从右往左的顺序依次存入栈中； 函数的返回值主要是通过 rax 寄存器进行传递的，不能同时返回多个值； 如果被调用函数要使用 rbx、rbp 和 %r12–%r15 寄存器（即 被保存的寄存器），则有责任保存调用之前的数据。 在之前版本的 Go 语言中，被调用函数的参数和返回值均保存在调用者栈中，被调用者根据栈的相对位置读取参数和返回值。这种设计只需要在栈上多分配一些内存就可以返回多个值并且降低了实现的复杂度，但同样也牺牲了函数调用的性能。\nGo 语言从 1.17 版本开始将使用寄存器传参，见 Proposal: Register-based Go calling convention。其主要特点如下：\n九个以及九个以下的参数和返回值会按顺序分别使用 AX、BX、CX、DI、SI、R8、R9、R10 和 R11 寄存器传递； 九个以上的参数和返回值则使用栈传递； 所有寄存器都是调用者保存（Caller-saved）寄存器，被调用者可以随意修改其值。 参数传递 传值和传引用之间的区别：\n传值：函数调用时会对参数进行复制，被调用方和调用方两者持有不相关的两份数据； 传引用：函数调用时会传递参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方。 Go 语言选择传值的方式，无论是传递基本类型、结构体还是指针，都会赋值传递的参数。在传递数组或者内存占用非常大的结构体时，我们应该尽量使用指针作为参数类型来避免发生数据拷贝进而影响性能。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 type MyStruct struct { i int } func myFunction(a MyStruct, b *MyStruct) { a.i = 31 (*b).i = 41 fmt.Printf(\"in my_function - a=(%d, %p) b=(%v, %p)\\n\", a, \u0026a, b, \u0026b) } func main() { a := MyStruct{i: 30} b := \u0026MyStruct{i: 40} fmt.Printf(\"before calling - a=(%d, %p) b=(%v, %p)\\n\", a, \u0026a, b, \u0026b) myFunction(a, b) fmt.Printf(\"after calling - a=(%d, %p) b=(%v, %p)\\n\", a, \u0026a, b, \u0026b) } $ go run main.go before calling - a=({30}, 0xc000018178) b=(\u0026{40}, 0xc00000c028) in my_function - a=({31}, 0xc000018198) b=(\u0026{41}, 0xc00000c038) after calling - a=({30}, 0xc000018178) b=(\u0026{41}, 0xc00000c028) 接口 概述 在计算机科学中，接口是计算机系统中多个组件共享的边界，不同的组件能够在边界上交换信息。如下图所示，接口的本质是引入一个新的中间层，调用方可以通过接口与具体实现分离，解除上下游的耦合，上层的模块不再需要依赖下层的具体模块，只需要依赖一个约定好的接口。\nGo 语言中的接口是一种内置的类型，它定义了一组方法的签名。\n隐式接口 Go 语言中接口的实现都是隐式的，且只会在传递参数、返回参数以及变量赋值时才会对某个类型是否实现接口进行检查。\n类型 Go 语言中有两种略微不同的接口，一种是带有一组方法的接口，另一种是不带任何方法的interface{}。与 C 语言中的void *不同，interface{}类型不是任意类型。\n1 2 3 4 5 6 7 8 9 func main() { type Test struct{} v := Test{} Print(v) } func Print(v interface{}) { println(v) } 上述代码中，Print函数只接受interface{}类型的参数，变量v在被该函数调用时会由原来的Test类型转换为interface{}类型。\n指针和接口 当方法的接收者是指针时，只有指针类型的变量才能实现接口，使用结构体初始化变量则无法通过编译：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Duck interface { Quack() } type Cat struct{} func (c *Cat) Quack() { fmt.Println(\"meow\") } func main() { var c Duck = Cat{} c.Quack() } // cannot use Cat{} (value of type Cat) as Duck value in variable declaration: // Cat does not implement Duck (method Quack has pointer receiver) 而当方法的接收者是结构体时，指针类型和结构体类型的变量都能实现接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type Duck interface { Quack() } type Cat struct{} func (c Cat) Quack() { fmt.Println(\"meow\") } func main() { var c Duck = \u0026Cat{} c.Quack() } 这是因为编译器会自动生成一个接收者为*Cat类型的Quack()方法：\n1 2 3 4 $ go tool compile -l -p main main.go $ go tool nm main.o | grep 'T' | grep Cat 2403 T main.(*Cat).Quack 1e86 T main.Cat.Quack nil 和 non-nil 1 2 3 4 5 6 7 8 9 10 11 12 13 package main type TestStruct struct{} func NilOrNot(v interface{}) bool { return v == nil } func main() { var s *TestStruct fmt.Println(s == nil) // #=\u003e true fmt.Println(NilOrNot(s)) // #=\u003e false } 调用NilOrNot函数时发生了隐式的类型转换，即*TestStruct类型被转换成interface{}类型。转换后的变量不仅包含转换前的变量，还包含变量的类型信息TestStruct，因此转换后的变量与nil不相等。\n数据结构 Go 语言根据接口类型是否包含一组方法将接口类型分成了两类：\n使用 runtime.iface 结构体表示包含方法的接口； 使用 runtime.eface （Empty Interface）结构体表示不包含任何方法的interface{}类型。 1 2 3 4 5 6 7 8 9 10 11 12 type iface struct { // 16 字节 tab *itab data unsafe.Pointer } type eface struct { // 16 字节 // 只包含指向底层数据和类型的两个指针 _type *_type data unsafe.Pointer } 类型结构体 runtime._type 是 Go 语言类型的运行时表示，它其实是 internal/abi.Type 的别名：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 type Type struct { Size_ uintptr // 类型占用的内存空间 PtrBytes uintptr Hash uint32 // 用于快速确定类型是否相等 TFlag TFlag Align_ uint8 FieldAlign_ uint8 Kind_ uint8 // 判断当前类型的多个对象是否相等 Equal func(unsafe.Pointer, unsafe.Pointer) bool GCData *byte Str NameOff PtrToThis TypeOff } itab 结构体 1 2 3 4 5 6 7 8 9 10 // 每个 itab 结构体 均占 32 字节 type itab struct { inter *interfacetype // 接口类型 _type *_type // 具体类型 hash uint32 // 对 _type.hash 的拷贝，用于类型转换 _ [4]byte // 一个用于动态派发的虚函数表，存储了一组函数指针 // 虽然被声明成大小固定的数组，但在使用时会通过原始指针获取其中的数据 fun [1]uintptr } 类型转换 使用指针类型实现接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Duck interface { Quack() } type Cat struct { Name string } //go:noinline func (c *Cat) Quack() { println(c.Name + \" meow\") } func main() { var c Duck = \u0026Cat{Name: \"draven\"} c.Quack() } Cat结构体的初始化和赋值触发的类型转换过程对应的汇编代码经简化后如下：\n1 2 3 4 5 6 7 LEAQ main..autotmp_3+40(SP), DX ;; DX = SP + 40 + autotmp_3 MOVQ $6, 8(DX) ;; (DX + 8) = 6 LEAQ go:string.\"draven\"(SB), SI ;; SI = \u0026\"draven\" MOVQ SI, (DX) ;; (DX) = SI LEAQ go:itab.*\u003cunlinkable\u003e.Cat,\u003cunlinkable\u003e.Duck(SB), AX MOVQ AX, main.c+24(SP) ;; (SP + 24) = \u0026go:itab.*.Cat,.Duck MOVQ DX, main.c+32(SP) ;; (SP + 32) = \u0026Cat SP + 24 ～ SP + 32 共同构成了 runtime.iface 结构体，因此可以作为Quack()方法的入参。runtime.itab 结构体的fun字段位于其内部的第 24 字节，而Duck接口只有一个方法，因此itab.fun[0]存储的就是指向Quack方法的指针：\n1 2 MOVQ 24(AX), CX ;; CX = AX.fun[0] = Cat.Quack CALL CX 使用结构体类型实现接口 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Duck interface { Quack() } type Cat struct { Name string } //go:noinline func (c Cat) Quack() { println(c.Name + \" meow\") } func main() { var c Duck = Cat{Name: \"draven\"} c.Quack() } Cat结构体的初始化和赋值触发的类型转换过程与上一节相似：\n1 2 3 4 5 6 7 LEAQ go:string.\"draven\"(SB), DX ;; DX = \u0026\"draven\" MOVQ DX, main..autotmp_2+40(SP) ;; (SP + 40 + tmp) = DX MOVQ $6, main..autotmp_2+48(SP) ;; (SP + 48 + tmp) = 6 LEAQ go:itab.\u003cunlinkable\u003e.Cat,\u003cunlinkable\u003e.Duck(SB), DX MOVQ DX, main.c+24(SP) ;; (SP + 24) = \u0026go:itab..Cat,.Duck LEAQ main..autotmp_2+40(SP), DX ;; DX = SP + 40 + tmp MOVQ DX, main.c+32(SP) ;; (SP + 32) = DX 变量c调用接口方法Quack()对应的汇编代码经简化后如下。之所以代码中调用的是Duck.Quack但生成的汇编是Cat.Quack，是因为编译器会将一些需要 动态派发 的方法改写成对目标方法的直接调用，以减少性能开销。\n1 2 3 4 5 6 MOVQ main.c+24(SP), AX ;; AX = \u0026go:itab..Cat,.Duck LEAQ go:itab.main.Cat,main.Duck(SB), SI CMPQ AX, SI ;; 检查 c 的具体类型是否为 Cat JEQ 111 ;; 如果是，跳转到方法调用 JMP 139 ;; 否则跳转到 runtime.panicdottypeI CALL main.Cat.Quack(SB) 如果我们在初始化变量时使用指针类型\u0026Cat{Name: \"draven\"}，生成的汇编代码便与上一节几乎完全相同。\n类型断言 基本概念详见：类型断言：如何检测和转换接口变量的类型。\n非空接口转换为具体类型 1 2 3 4 5 6 7 8 func main() { var c Duck = \u0026Cat{Name: \"draven\"} switch c.(type) { case *Cat: cat := c.(*Cat) cat.Quack() } } Switch 语句生成的汇编指令会将目标类型的Hash字段与接口变量中的itab.hash字段进行比较。\n空接口转换为具体类型 1 2 3 4 5 6 7 8 func main() { var c interface{} = \u0026Cat{Name: \"draven\"} switch c.(type) { case *Cat: cat := c.(*Cat) cat.Quack() } } 如果禁用编译器优化，上述代码会在类型断言时从eface._type中获取变量的具体类型，汇编指令仍然会使用目标类型的Hash字段与接口变量的类型进行比较。\n动态派发 动态派发（Dynamic Dispatch）是在运行时选择具体多态操作（方法或者函数）执行的过程，它是面向对象语言中的常见特性。Go 语言虽然不是严格意义上的面向对象语言，但是接口的引入为它带来了动态派发这一特性。调用接口类型的方法时，如果在编译期间不能确认接口的类型，Go 语言会在运行时决定具体调用该方法的哪个实现。\n1 2 3 4 5 func main() { var c Duck = \u0026Cat{Name: \"draven\"} c.Quack() c.(*Cat).Quack() } 示例代码中，main函数调用了两次Quack方法：第一次以接口类型Duck调用，调用时需要经过运行时的动态派发，前文 已分析过它的执行过程；第二次以具体类型*Cat调用，因此编译时便可以确定调用的函数CALL main.(*Cat).Quack(SB)。\n两次方法调用对应的汇编指令差异就是动态派发带来的额外开销，这些额外开销在有低延时、高吞吐量需求的服务中是不能被忽视的。使用结构体实现接口带来的开销会大于使用指针实现，而动态派发在结构体上的表现非常差，这提醒我们应当尽量避免使用结构体类型实现接口。\n使用结构体带来的巨大性能差异不仅是接口带来的问题，还主要因为 Go 语言在函数调用时是传值的，动态派发的过程只是放大了参数拷贝带来的影响。\n反射 reflect 包实现了运行时的反射能力，能够让程序操作不同类型的对象。其中有两对非常重要的函数和类型，它们一一对应：\n函数 reflect.TypeOf 能获取任意变量的类型信息，返回一个接口类型 reflect.Type；\n1 2 3 4 5 6 7 8 9 10 type Type interface { Align() int FieldAlign() int Method(int) Method MethodByName(string) (Method, bool) // 获取当前类型对应方法的引用 NumMethod() int ... Implements(u Type) bool // 判断当前类型是否实现了某个接口 ... } 函数 reflect.ValueOf 能获取数据的运行时表示，返回一个结构体类型 reflect.Value。后者没有对外暴露的字段，但是提供了获取或者写入数据的方法。\n1 2 3 4 5 6 7 8 type Value struct { // 包含过滤的或者未导出的字段 } func (v Value) Addr() Value func (v Value) Bool() bool func (v Value) Bytes() []byte ... 三大法则 反射作为一种元编程方式可以减少重复代码，但是过量使用反射会使我们的程序逻辑变得难以理解并且运行缓慢。Go 语言反射的三大法则为：\n从interface{}变量可以反射出反射对象； 从反射对象可以获取interface{}变量； 要修改反射对象，其值必须可以设置。 第一法则 函数 reflect.TypeOf 和 reflect.ValueOf 的入参均为any类型（即interface{}的别名），所以类似reflect.ValueOf(1)这样的调用实际上首先完成了隐式的类型转换。上述两个函数是连接 Go 语言类型和反射类型的桥梁：\n一旦我们获取到了变量对应的反射对象，就能根据其类型调用不同的方法获取相关信息：\n结构体：获取字段的数量并通过下标和字段名获取字段StructField； 哈希表：获取哈希表的Key类型； 函数或方法：获取入参和返回值的类型； … 第二法则 reflect.Value.Interface 可以将反射对象还原为interface{}类型的变量。如果想要将其还原为最原始状态，还需要进行显式的类型转换：\n1 2 v := reflect.ValueOf(1) v.Interface().(int) 第三法则 如果我们要更新一个reflect.Value，那么它“持有”的值一定是可以被更新的：\n1 2 3 4 5 6 7 8 9 func main() { i := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) } $ go run reflect.go panic: reflect: reflect.Value.SetInt using unaddressable value 由于 Go 语言函数调用采用值传递，反射对象v和原始变量i之间没有任何关系，因此直接修改反射对象是无法改变原始变量的。正确的做法是：\n1 2 3 4 5 6 7 8 9 func main() { i := 1 v := reflect.ValueOf(\u0026i) v.Elem().SetInt(10) fmt.Println(i) } $ go run reflect.go 10 上述代码先获取指针\u0026i对应的反射对象v，然后通过 reflect.Value.Elem 方法得到指针指向的变量对应的反射对象，最后调用 reflect.Value.SetInt 更新变量的值。整个流程的思路与下列代码相同：\n1 2 3 4 5 func main() { i := 1 v := \u0026i *v = 10 } 类型和值 Go 语言的interface{}类型在语言内部是通过 reflect.emptyInterface 结构体表示的：\n1 2 3 4 type emptyInterface struct { typ *rtype // 变量类型 word unsafe.Pointer // 指向内部封装的数据 } 函数 reflect.TypeOf 会将传入的变量隐式地转换为reflect.emptyInterface类型并获取其中存储的类型信息 reflect.rtype：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func TypeOf(i any) Type { eface := *(*emptyInterface)(unsafe.Pointer(\u0026i)) return toType((*abi.Type)(noescape(unsafe.Pointer(eface.typ)))) } func toType(t *abi.Type) Type { if t == nil { return nil } return toRType(t) } func toRType(t *abi.Type) *rtype { return (*rtype)(unsafe.Pointer(t)) } reflect.rtype是一个实现了reflect.Type接口的结构体，其 String 方法可以帮助我们获取当前类型的名称：\n1 2 3 4 5 6 7 func (t *rtype) String() string { s := t.nameOff(t.t.Str).Name() if t.t.TFlag\u0026abi.TFlagExtraStar != 0 { return s[1:] } return s } 函数 reflect.ValueOf 的实现也非常简单，它调用 reflect.unpackEface 从接口中获取reflect.Value结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func ValueOf(i any) Value { if i == nil { return Value{} } return unpackEface(i) } func unpackEface(i any) Value { // 类型转换 e := (*emptyInterface)(unsafe.Pointer(\u0026i)) t := e.typ if t == nil { return Value{} } f := flag(t.Kind()) if t.IfaceIndir() { f |= flagIndir } // 将具体类型和指针包装成 reflect.Value 结构体 return Value{t, e.word, f} } 实际上，当我们要将一个变量转换成反射对象时，其类型和值在编译期间就会被转换成interface{}。\n更新变量 我们可以调用 reflect.Value.Set 来更新反射变量的值：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func (v Value) Set(x Value) { v.mustBeAssignable() // 检查当前反射对象是否是可以被设置的 x.mustBeExported() // 检查新反射对象的字段是否是对外公开的 var target unsafe.Pointer // 定义一个指向目标的指针 if v.kind() == Interface { target = v.ptr } // 调整 x 的类型，使之能够分配给 v，返回值将覆盖 x x = x.assignTo(\"reflect.Set\", v.typ, target) if x.flag\u0026flagIndir != 0 { if x.ptr == unsafe.Pointer(\u0026zeroVal[0]) { // 若 x 指向的是零值则清除 v 指向的内存 typedmemclr(v.typ(), v.ptr) } else { // 将 x.ptr 指向的值复制到 v.ptr 指向的值 typedmemmove(v.typ(), v.ptr, x.ptr) } } else { // 若 x 不是间接引用的，则直接将 x.ptr 赋给 v.ptr *(*unsafe.Pointer)(v.ptr) = x.ptr } } 其中最为重要的函数是 reflect.Value.assignTo：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 func (v Value) assignTo(context string, dst *rtype, target unsafe.Pointer) Value { // 注意这里的 dst 是 Set 函数里的 v.typ，而 v 是 Set 函数里的 x ... switch { // 若当前反射对象的类型可以直接被目标对象替换，则返回目标反射对象 case directlyAssignable(dst, v.typ): ... return Value{dst, v.ptr, fl} // 若当前反射对象是接口且目标对象实现了接口，则将目标对象简单包装成接口值 // implements 的实现详见下一节 case implements(dst, v.typ): if v.Kind() == Interface \u0026\u0026 v.IsNil() { return Value{dst, nil, flag(Interface)} } x := valueInterface(v, false) if dst.NumMethod() == 0 { *(*any)(target) = x } else { ifaceE2I(dst, x, target) } return Value{dst, target, flagIndir | flag(Interface)} } panic(context + \": value of type \" + stringFor(v.typ()) + \" is not assignable to type \" + stringFor(dst)) } 实现协议 reflect.rtype.Implements 方法可以用于判断某些类型是否遵循特定的接口，示例代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type CustomError struct{} func (*CustomError) Error() string { return \"\" } func main() { // 获取内置接口类型 error 的反射类型比较复杂 // (*error)(nil) 是一个指向 error 的空指针 // reflect.TypeOf((*error)(nil)) 获取空指针的类型信息 // Elem() 获取 *error 指针指向的元素类型，即 error 接口类型本身 typeOfError := reflect.TypeOf((*error)(nil)).Elem() // 获取结构体的反射类型则很简单 customErrorPtr := reflect.TypeOf(\u0026CustomError{}) customError := reflect.TypeOf(CustomError{}) fmt.Println(customErrorPtr.Implements(typeOfError)) // #=\u003e true fmt.Println(customError.Implements(typeOfError)) // #=\u003e false } 该函数会检查传入的类型是不是接口，然后在参数符合条件的情况下调用私有方法 reflect.implements：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 func implements(T, V *abi.Type) bool { t := (*interfaceType)(unsafe.Pointer(T)) // 如果接口中没有任何方法，则说明 t 是空接口 // 任何类型都实现了空接口，因此返回 true if len(t.methods) == 0 { return true } ... v := V.uncommon() i := 0 vmethods := v.methods() // 遍历接口和类型的方法 // 方法均按字母顺序存储，复杂度为 O(N) for j := 0; j \u003c int(v.Mcount); j++ { tm := \u0026t.Methods[i] tmName := t.nameOff(tm.Name) vm := vmethods[j] vmName := nameOffFor(V, vm.Name) if vmName.Name() == tmName.Name() \u0026\u0026 typeOffFor(V, vm.Mtyp) == t.typeOff(tm.Typ) { ... if i++; i \u003e= len(t.Methods) { return true } } } return false } 方法调用 示例代码使用反射来执行Add(0, 1)函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func Add(a, b int) int { return a + b } func main() { // 获取函数 Add 对应的反射对象 v := reflect.ValueOf(Add) if v.Kind() != reflect.Func { return } t := v.Type() // NumIn 获取函数的入参个数 argv := make([]reflect.Value, t.NumIn()) for i := range argv { if t.In(i).Kind() != reflect.Int { return } // 将切片中的元素设置为索引（即 0，1）对应的反射对象 argv[i] = reflect.ValueOf(i) } // 调用 Add 反射对象的 Call 方法并传入参数列表 result := v.Call(argv) // Add 只有一个返回值，因此 result 切片中只有一个元素 if len(result) != 1 || result[0].Kind() != reflect.Int { return } fmt.Println(result[0].Int()) } 使用反射来调用方法非常复杂，原本只需要一行代码就能完成的工作，现在需要十几行代码才能完成，但这也是在静态语言中使用动态特性必须付出的成本。\n其中，reflect.Value.Call 是运行时调用方法的入口，它通过两个mustBe开头的方法确定了当前反射对象的类型是函数以及可见性，随后调用 reflect.Value.call 完成方法调用：\n1 2 3 4 5 func (v Value) Call(in []Value) []Value { v.mustBe(Func) v.mustBeExported() return v.call(\"Call\", in) } 这个私有方法的执行过程会分成以下几部分：\n检查输入参数以及类型的合法性； 将传入的参数切片in设置到寄存器和栈； 通过函数指针和输入参数调用函数； 从寄存器和栈上获取函数的返回值。 应用场景 实现通用函数 反射可以用于实现通用函数，这些函数可以接受任意类型的参数：\n1 2 3 4 5 6 7 8 9 10 11 func printTypeAndValue(x interface{}) { v := reflect.ValueOf(x) t := v.Type() fmt.Printf(\"Type: %s, Value: %v\\n\", t, v.Interface()) } func main() { printTypeAndValue(100) // Type: int, Value: 100 printTypeAndValue(\"Hello\") // Type: string, Value: Hello printTypeAndValue(3.14) // Type: float64, Value: 3.14 } 动态调用函数 反射可以根据传入的函数名来调用相应的函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 func hello() { fmt.Println(\"Hello, world!\") } func goodbye() { fmt.Println(\"Goodbye!\") } func callFunc(funcName string) { funcs := map[string]interface{}{ \"hello\": hello, \"goodbye\": goodbye, } f := reflect.ValueOf(funcs[funcName]) f.Call(nil) } func main() { funcName := \"hello\" // 这个值可以是来自用户输入，或者其他动态来源 callFunc(funcName) } 反射的缺点 与反射相关的代码，经常是难以阅读的。在软件工程中，代码可读性也是一个非常重要的指标。 Go 语言作为一门静态语言，编码过程中，编译器能提前发现一些类型错误，但是对于反射代码是无能为力的。所以包含反射相关的代码，很可能会运行很久，才会出错，这时候经常是直接 panic，可能会造成严重的后果。 反射对性能影响还是比较大的，比正常代码运行速度慢一到两个数量级。所以，对于一个项目中处于运行效率关键位置的代码，尽量避免使用反射特性。 ","description":"","tags":["Go"],"title":"《Go 语言设计与实现》读书笔记：语言特性","uri":"/posts/go-language-feature-note/"},{"content":" 原书中的代码片段基于 Go 1.15，笔记则根据 Go 1.22 版本的更新进行了相应替换。\n数组 我们通常会从两个维度描述数组：数组中存储的元素类型（Type）和数组最大能存储的元素个数（Bound）。\n1 2 3 4 type Array struct { Elem *Type // element type Bound int64 // number of elements; \u003c0 if unknown yet } Go 语言数组在初始化之后大小就无法改变。存储元素类型相同、但大小不同的数组类型在 Go 语言看来也是完全不同的，只有两个条件都相同才是同一类型。\n编译期间的数组类型是由 cmd/compile/internal/types.NewArray 函数生成的：\n1 2 3 4 5 6 7 8 9 10 11 func NewArray(elem *Type, bound int64) *Type { if bound \u003c 0 { base.Fatalf(\"NewArray: invalid bound %v\", bound) } t := newType(TARRAY) t.extra = \u0026Array{Elem: elem, Bound: bound} if elem.HasShape() { t.SetHasShape(true) } return t } 初始化 Go 语言的数组有两种不同的创建方式，一种是显式的指定数组大小，另一种是使用[...]T声明数组。如下两种声明方式在运行期间得到的结果是完全相同的：\n1 2 arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3} 不过第一种方式声明的数组的大小在 类型检查 阶段就会被提取出来，而第二种方式则需要编译器通过遍历元素来计算。因此，[...]T 这种初始化方式其实是 Go 语言为我们提供的一种语法糖。\n对于一个由字面量（Literal）组成的数组，根据数组元素数量的不同，编译器会在负责初始化字面量的 cmd/compile/internal/walk.anylit 函数中做出两种不同的优化：\n当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上； 当元素数量大于 4 个时，会将数组中的元素放置到静态区并在运行时复制到栈中。 举例来说，[3]int{1, 2, 3}会被拆分成一个声明变量的表达式和几个赋值表达式：\n1 2 3 4 var arr [3]int arr[0] = 1 arr[1] = 2 arr[2] = 3 而[5]int{1, 2, 3, 4, 5}的初始化过程则等效于如下伪码：\n1 2 3 4 5 6 7 8 var arr [5]int // 元素存储于静态区 statictmp_0[0] = 1 statictmp_0[1] = 2 statictmp_0[2] = 3 statictmp_0[3] = 4 statictmp_0[4] = 5 arr = statictmp_0 访问和赋值 无论是在栈上还是静态存储区，数组在内存中都是一连串的内存空间，我们通过指向数组开头的指针、元素的数量以及元素类型占的空间大小表示数组。\nGo 语言中可以在编译期间的静态类型检查判断数组越界，但是如果使用变量去访问数组或者字符串时，我们就需要 Go 语言运行时阻止不合法的访问：\n1 2 3 4 // 静态类型检查 arr[4]: invalid argument: index 4 out of bounds [0:3] // 运行时 runtime.panicIndex arr[i]: panic: runtime error: index out of range [4] with length 3 切片 切片，即动态数组，其长度并不固定，所以声明时只需要指定切片中的元素类型：\n1 2 []int []interface{} 编译期间的切片是 cmd/compile/internal/types.Slice 类型的，只确定了元素的类型：\n1 2 3 type Slice struct { Elem *Type // element type } 在运行时则由 internal/unsafeheader.Slice 结构体表示：\n1 2 3 4 5 type SliceHeader struct { Data unsafe.Pointer // 指向底层数组的指针 Len int // 当前切片的长度 Cap int // 当前切片的容量，即底层数组的大小 } 由于大量开发者使用 reflect.StringHeader 和 reflect.SliceHeader 实现零复制的字符串/字节数组转换而产生诸多内存泄露问题，两者在 Go 1.20 版本中被弃用，详见：unsafe: add StringData, String, SliceData。切片和字符串的运行时表示目前为：unsafeheader.Slice 和 unsafeheader.String，区别在于Data字段的类型由uintptr改为unsafe.Pointer。\n因此我们可以将切片理解成一片连续的内存空间（底层数组）以及长度与容量的标识：\n初始化 Go 语言中支持三种初始化切片的方式：\n1 2 3 arr[0:3] or slice[0:3] // 通过下标获取数组或切片的一部分 slice := []int{1, 2, 3} // 使用字面量初始化新切片 slice := make([]int, 10) // 使用关键字 make 创建切片 使用下标 使用下标初始化切片不会复制原数组或者原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。这种操作是所有创建切片的方法中最为底层的。\n使用字面量 当我们使用字面量[]int{1, 2, 3}创建新的切片时，cmd/compile/internal/walk.slicelit 函数会在编译期间将它展开成如下所示的代码片段：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 根据切片元素数量创建底层数组 var vstat [3]int // 将字面量元素存储到初始化的数组中 // 如 vstat[0] = 1 vstat = constpart{} // 创建一个指向 [3]int 类型的数组指针 // 并在堆上为其分配内存 var vauto *[3]int = new([3]int) // 将数组 vstat 复制到 vauto 指向的数组 // 注意，Go 语言的数组名是值而非 C 中的隐式指针 *vauto = vstat vauto[i] = dynamic part // 通过 [:] 操作获取一个底层使用 vauto 的切片 slice := vauto[:] 最后一步实际上就是使用下标创建切片。\n使用 make 与其他两种方法相比，使用make关键字创建切片时，很多工作需要运行时的参与。类型检查期间的 cmd/compile/internal/typecheck.typecheck1 函数会校验len是否传入，以及cap是否大于或等于len。\n随后 cmd/compile/internal/walk.walkMakeSlice 会根据切片的大小以及是否发生内存逃逸进行不同的处理：如果当前的切片不会发生逃逸并且切片非常小的时候，make([]int, 3, 4) 会在编译阶段被直接转换成如下所示的代码：\n1 2 var arr [4]int n := arr[:3] 而当切片发生逃逸或者非常大时，运行时需要 runtime.makeslice 在堆上初始化切片：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func makeslice(et *_type, len, cap int) unsafe.Pointer { // 计算切片占用的内存空间 // 内存空间 = 元素大小 * 切片容量 mem, overflow := math.MulUintptr(et.size, uintptr(cap)) // 检查内存是否发生溢出或超出最大可分配内存 // 长度是否小于 0 或长度是否大于容量 if overflow || mem \u003e maxAlloc || len \u003c 0 || len \u003e cap { mem, overflow := math.MulUintptr(et.size, uintptr(len)) if overflow || mem \u003e maxAlloc || len \u003c 0 { panicmakeslicelen() } panicmakeslicecap() } // 申请一块连续的内存空间 return mallocgc(mem, et, true) } 在之前版本的 Go 语言中，该函数最后会将数组指针、长度和容量合成一个 runtime.slice 结构体。但是从 cmd/compile: move slice construction to callers of makeslice 提交之后，这项工作就交给了函数的调用方。后者会在编译期间构建切片结构体，而 runtime.makeslice 仅返回指向底层数组的指针。\n访问元素 使用len和cap获取长度或者容量是切片最常见的操作，编译器将这它们看成两种特殊操作，即 OLEN 和 OCAP。\n在编译期间，对切片中元素的访问操作 OINDEX 会被转换成对地址的直接访问，而包含range关键字的遍历则被转换成形式更简单的循环。\n追加和扩容 如果 append 返回的新切片不会覆盖原切片：\n1 2 3 4 5 6 7 8 9 10 11 12 // new_slice := append(s, 1, 2, 3) ptr, len, cap := s len += 3 if uint(len) \u003e uint(cap) { ptr, len, cap = growslice(ptr, len, cap, 3, typ) // Note that len is unmodified by growslice. } // with write barriers, if needed: *(ptr+(len-3)) = e1 *(ptr+(len-2)) = e2 *(ptr+(len-1)) = e3 return makeslice(ptr, len, cap) 如果 append 返回的切片会覆盖原切片：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // s = append(s, 1, 2, 3) a := \u0026s ptr, len, cap := s len += 3 if uint(len) \u003e uint(cap) { ptr, len, cap = growslice(ptr, len, cap, 3, typ) vardef(a) // if necessary, advise liveness we are writing a new a *a.cap = cap // write before ptr to avoid a spill *a.ptr = ptr // with write barrier } *a.len = len // with write barriers, if needed: *(ptr+(len-3)) = e1 *(ptr+(len-2)) = e2 *(ptr+(len-1)) = e3 两者的逻辑其实差不多，最大的区别在于得到的新切片是否会赋值回原变量。\n扩容是为切片分配新的内存空间并复制原切片中元素的过程，runtime.growslice 函数最终会返回一个新的切片，其中包含了新的数组指针、大小和容量。runtime.nextslicecap 则根据切片的期望容量和当前容量选择不同的策略进行扩容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // nextslicecap computes the next appropriate slice length. func nextslicecap(newLen, oldCap int) int { newcap := oldCap doublecap := newcap + newcap if newLen \u003e doublecap { return newLen } const threshold = 256 if oldCap \u003c threshold { return doublecap } for { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) \u003e\u003e 2 // We need to check `newcap \u003e= newLen` and whether `newcap` overflowed. // newLen is guaranteed to be larger than zero, hence // when newcap overflows then `uint(newcap) \u003e uint(newLen)`. // This allows to check for both with the same comparison. if uint(newcap) \u003e= uint(newLen) { break } } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap \u003c= 0 { return newLen } return newcap } 当我们执行如下代码时，会触发 runtime.growslice 函数扩容arr切片并传入期望的新容量 5，此时期望分配的内存大小为 40 字节。不过运行时会调用 runtime.roundupsize 将切片占用的内存大小对齐到 48 字节，因此新切片的容量为 48 / 8 = 6：\n1 2 var arr []int64 arr = append(arr, 1, 2, 3, 4, 5) 复制切片 无论是编译期间复制还是运行时复制，两种复制方式都会通过 runtime.memmove 将整块内存的内容复制到目标的内存区域中：\n相比于依次复制元素，这种方式能够提供更好的性能。不过，整块复制内存仍然会占用非常多的资源，对大切片执行复制操作时一定要注意对性能的影响。\n哈希表 设计原理 哈希表是计算机科学中的最重要数据结构之一，这不仅因为它 𝑂(1) 的读写性能非常优秀，还因为它提供了键值之间的映射。想要实现一个性能优异的哈希表，需要注意两个关键点 —— 哈希函数和冲突解决方法。\n哈希函数映射的结果一定要尽可能均匀，结果不均匀的哈希函数会带来更多的哈希冲突以及更差的读写性能。\n解决哈希冲突的常见方法有开放寻址法和拉链法。\n开放寻址法 这种方法的核心思想是依次探测和比较数组中的元素以判断目标键值对是否存在于哈希表中，此时实现哈希表底层的数据结构是数组。不过因为数组的长度有限，向哈希表写入键值对时会从如下的索引开始遍历：\n1 index := hash(\"Key3\") % array.len 如下图所示，当 Key3 与已经存入哈希表中的两个键值对 Key1 和 Key2 发生冲突时，Key3 会被写入 Key2 后面的空闲位置。当我们再去读取 Key3 对应的值时就会先获取键的哈希并取模，这会先帮助我们找到 Key1，找到 Key1 后发现它与 Key 3 不相等，所以会继续查找后面的元素，直到内存为空或者找到目标元素。\n开放寻址法中对性能影响最大的是装载因子，它是数组中元素的数量与数组大小的比值。随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会影响哈希表的读写性能。当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找和插入任意元素的时间复杂度都是 𝑂(𝑛) 的，即需要遍历数组中的全部元素。\n拉链法 大多数编程语言都采用拉链法，它的平均查找时间较短且可以动态申请内存以减少内存占用。实现拉链法一般会使用数组加上链表，我们可以将它看成可以扩展的二维数组：\n和开放地址法一样，选择桶的方式是直接对哈希函数返回的结果取模：\n1 index := hash(\"Key6\") % array.len 如上图所示，Key 6 的索引为 2，此时遍历 2 号桶中的链表时可能会遇到两种情况：\n找到键相同的键值对，则读取/写入键对应的值； 未找到键相同的键值对，则返回该键不存在（读取）/在链表的末尾追加新的键值对（写入）； 拉链法的装载因子等于元素数量除以桶的数量，装载因子越大（一般不会超过 1），读写性能就越差。当装载因子较大时会触发哈希的扩容，即创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。\n数据结构 Go 语言运行时同时使用了多个数据结构组合表示哈希表，其中 runtime.hmap 是最核心的结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type hmap struct { count int // 当前哈希表中的元素数量 flags uint8 B uint8 // 当前哈希表的桶数量为 2 ^ B noverflow uint16 // 使用的溢出桶数量 hash0 uint32 // 为哈希函数引入随机性种子 buckets unsafe.Pointer // 指向 bmap 数组的指针 oldbuckets unsafe.Pointer // 扩容时保存的旧桶，大小为当前的一半 nevacuate uintptr // 标识扩容进度，小于此地址的桶已迁移完成 extra *mapextra } type mapextra struct { overflow *[]*bmap // 已使用的溢出桶地址 oldoverflow *[]*bmap // 扩容时旧桶使用的溢出桶地址 nextOverflow *bmap // 指向下一个空闲的溢出桶 } 如上图所示哈希表 runtime.hmap 的桶是 runtime.bmap，后者能存储 8 个键值对。当哈希表中存储的数据过多，单个桶已经装满时就会使用extra.nextOverflow中的桶存储溢出的数据。\n上述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶，上图中黄色的 runtime.bmap 就是正常桶，绿色的 runtime.bmap 是溢出桶。\n当 map 中找不到可用的溢出桶时，runtime.newoverflow 会通过 newobject 新建溢出桶，此时正常桶和溢出桶在内存中的存储空间就不再连续了。\n桶的结构体 runtime.bmap 在 Go 语言源代码中的定义只包含一个简单的tophash字段，它存储了键的哈希值的高 8 位。通过比较tophash可以减少访问键值对的次数以提高性能。\n在运行期间，该结构体其实不止包含tophash字段，我们可以根据编译期间的 cmd/compile/internal/reflectdata.MapBucketType 函数重建它的结构：\n1 2 3 4 5 6 type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype overflow uintptr } 初始化 字面量 当哈希表中的元素数量少于或者等于 25 个时，编译器会将字面量初始化的结构体转换成以下的代码，将所有的键值对一次加入到哈希表中：\n1 2 3 4 hash := make(map[string]int, 3) hash[\"1\"] = 2 hash[\"3\"] = 4 hash[\"5\"] = 6 一旦哈希表中元素的数量超过了 25 个，编译器会创建两个数组分别存储键和值，这些键值对会通过如下所示的for循环加入哈希：\n1 2 3 4 5 6 hash := make(map[string]int, 26) vstatk := []string{\"1\", \"2\", \"3\", ... ， \"26\"} vstatv := []int{1, 2, 3, ... , 26} for i := 0; i \u003c len(vstak); i++ { hash[vstatk[i]] = vstatv[i] } 无论使用哪种方法，使用字面量初始化的过程都会使用 Go 语言中的关键字make来创建新的哈希并通过最原始的[]语法向哈希追加元素。\n运行时 当创建的哈希被分配到栈上并且其容量小于BUCKETSIZE = 8时，cmd/compile/internal/walk.walkMakeSlice 函数会在编译阶段快速初始化哈希，这是编译器对小容量的哈希所做的优化：\n1 2 3 4 5 6 7 8 9 10 var h *hmap // Allocate hmap on stack var hv hmap h = \u0026hv if hint \u003c= BUCKETSIZE { var bv bmap b := \u0026bv h.buckets = b h.hash0 = rand32() } 除此之外，所有初始化map的语句都会被转换成 runtime.makemap：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 func makemap(t *maptype, hint int, h *hmap) *hmap { // 计算哈希占用的内存是否溢出或者超出能分配的最大值 mem, overflow := math.MulUintptr(uintptr(hint), t.Bucket.Size_) if overflow || mem \u003e maxAlloc { hint = 0 } if h == nil { h = new(hmap) } // 获取一个随机的哈希种子 h.hash0 = uint32(rand()) B := uint8(0) // 根据传入的 hint（make(map[k]v, hint)）计算出至少需要的桶数量； for overLoadFactor(hint, B) { B++ } h.B = B if h.B != 0 { var nextOverflow *bmap // 使用 runtime.makeBucketArray 创建用于保存桶的数组 h.buckets, nextOverflow = makeBucketArray(t, h.B, nil) if nextOverflow != nil { h.extra = new(mapextra) h.extra.nextOverflow = nextOverflow } } return h } runtime.makeBucketArray 会根据B计算出需要创建的桶数并在内存中分配一片连续的空间用于存储数据：\n当桶的数量小于 $2^4$ 时，由于数据较少、使用溢出桶的可能性较低，会省略创建的过程以减少额外开销； 当桶的数量大于 $2^4$ 时，会额外创建 $2^{B-4}$ 个溢出桶。 读写操作 访问 v := hash[key] 操作会先被转化为 runtime.mapaccess1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... // map 不支持并发读写 if h.flags\u0026hashWriting != 0 { fatal(\"concurrent map read and map write\") } // 通过哈希函数和种子获取 key 对应的哈希值 hash := t.Hasher(key, uintptr(h.hash0)) // m 为桶掩码，等于 1\u003c\u003cB - 1 m := bucketMask(h.B) // hash\u0026m 为 key 所在桶的编号 // 通过指针计算目标桶的位置 b := (*bmap)(add(h.buckets, (hash\u0026m)*uintptr(t.BucketSize))) // 获取 key 对应的哈希值的高八位 top := tophash(hash) bucketloop: // 依次遍历正常桶和溢出桶中的数据 for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u003c bucketCnt; i++ { // 将 key 对应的哈希值的高八位与桶中存储的 tophash 进行比较 if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } // 若 tophash 相等，则移动指针得到桶中存储的键 k // 其中，dataOffset 是桶中第一个键相对于 bmap 起始地址的偏移量 k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.KeySize)) // 再将 key 与 k 进行比较，若相等则读取指向目标值的指针并返回 if t.Key.Equal(key, k) { e := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.KeySize)+i*uintptr(t.t.ValueSize)) return e } } } return unsafe.Pointer(\u0026zeroVal[0]) } 如下图所示，正是因为每个桶都是一片连续的内存空间，我们才能通过 runtime.add 操作指针以访问桶中存储的键。\n另外，选择桶序号时用的是键的哈希值的最低几位（hash\u0026m），而加速访问用的是键的哈希值的高 8 位，这种设计能够减少同一个桶中有大量相等tophash的概率以免影响性能。\nv, ok := hash[key]操作则会被转化为 runtime.mapaccess2，它在此基础之上多返回了一个标识键值对是否存在的布尔值。我们能够通过这个布尔值更准确地知道：当v == nil时，v 到底是哈希中存储的元素还是表示该键对应的元素不存在。因此我们在访问哈希表时更推荐使用这种方式判断元素是否存在。\n写入 hash[k] = v操作会在编译期间被转换成 runtime.mapassign，该函数需要兼顾以下三种情况：\nk在桶中存在，返回v在桶中的地址； k在桶中不存在且桶中有空位，返回k和v应当插入的地址； k在桶中不存在且桶已满，对当前桶进行扩容然后再返回k和v应当插入的地址。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { // 根据 key 计算哈希值 hash := t.hasher(key, uintptr(h.hash0)) again: // 获取 key 所在的桶序号 bucket := hash \u0026 bucketMask(h.B) b := (*bmap)(add(h.buckets, bucket*uintptr(t.BucketSize))) // 获取 key 对应的哈希值的高八位 top := tophash(hash) var inserti *uint8 // key 的哈希值在 tophash 数组中的索引 var insertk unsafe.Pointer // key 插入的地址 var elem unsafe.Pointer // elem 插入的地址 bucketloop: for { // 遍历所有正常桶和溢出桶 for i := uintptr(0); i \u003c bucketCnt; i++ { // 将 key 对应的哈希值的高八位与桶中存储的 tophash 进行比较 if b.tophash[i] != top { // 若不相等，则判断是否为空位 if isEmpty(b.tophash[i]) \u0026\u0026 inserti == nil { // 若为空位，则将其标记为键值对插入的位置 inserti = \u0026b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.KeySize)) elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.KeySize)+i*uintptr(t.ValueSize)) } if b.tophash[i] == emptyRest { break bucketloop } // 若 tophash 均不匹配，则跳出内循环 continue } // 若 tophash 相等，则移动指针得到桶中存储的键 k k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.KeySize)) // 再将 key 与 k 进行比较 if !t.Key.Equal(key, k) { continue } // 通过指针移动得到值的地址并直接返回 elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.KeySize)+i*uintptr(t.ValueSize)) goto done } // 遍历完正常桶后，将在下一个内循环中遍历溢出桶 ovf := b.overflow(t) if ovf == nil { break } b = ovf } // inserti 为 nil，说明当前桶和溢出桶已满 if inserti == nil { // 调用 runtime.newoverflow 创建新桶 newb := h.newoverflow(t, b) inserti = \u0026newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) elem = add(insertk, bucketCnt*uintptr(t.KeySize)) } // 若 key 在哈希表中不存在，则为新键值对规划内存 if t.indirectkey() { kmem := newobject(t.Key) *(*unsafe.Pointer)(insertk) = kmem insertk = kmem } if t.indirectelem() { vmem := newobject(t.Elem) *(*unsafe.Pointer)(elem) = vmem } // 通过 runtime.typedmemmove 将 key 移动到对应的内存空间中 typedmemmove(t.Key, insertk, key) *inserti = top h.count++ done: // 返回 key 对应的 elem 地址 return elem } 由此可见，runtime.mapassign 并不会将值复制到桶中，真正的赋值操作是在编译期间插入的：\n1 2 3 4 00018 (+5) CALL runtime.mapassign_fast64(SB) 00020 (5) MOVQ 24(SP), DI ;; DI = \u0026value 00026 (5) LEAQ go.string.\"88\"(SB), AX ;; AX = \u0026\"88\" 00027 (5) MOVQ AX, (DI) ;; *DI = AX runtime.mapassign_fast64 与 runtime.mapassign 函数的逻辑差不多，我们需要关注的是后面的三行代码。其中24(SP)是该函数返回的值地址，我们通过LEAQ指令将字符串的地址存储到寄存器AX中，MOVQ 指令将字符串\"88\"存储到了目标地址上从而完成了这次哈希的写入。\n扩容 上一节在介绍mapassign时其实省略了其中的扩容操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... // 哈希的扩容不是一个原子的过程，需要判断当前是否处于扩容状态 // 判断 h.growing() 返回的 oldbuckets 是否非空 // 若 oldbuckets 非空，则说明正在扩容 // 装载因子超过 6.5 或溢出桶过多时触发扩容 hashgrow if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) // Growing the table invalidates everything, so try again goto again } ... } 我们可以发现有以下两种情况将触发扩容：\n装载因子超过 6.5：哈希的空间使用率过高，哈希冲突的概率较大； 溢出桶过多：如果我们持续向哈希中插入数据并将它们全部删除，那么即使哈希表中的装载因子没有超过阈值，溢出桶的数量也会越来越多从而造成缓慢的 内存泄漏。 runtime.hashGrow 会根据具体情况采取不同的扩容策略：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 func hashGrow(t *maptype, h *hmap) { bigger := uint8(1) // 若装载因子未超过阈值，则说明溢出桶过多触发了扩容 if !overLoadFactor(h.count+1, h.B) { bigger = 0 // 扩容规则将是 sameSizeGrow，即等量扩容，h.B 不变 h.flags |= sameSizeGrow } oldbuckets := h.buckets // 创建一组新桶和预创建的溢出桶 // 若装载因子超过阈值，h.b 加一，桶的数量翻倍 newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) h.B += bigger h.flags = flags //将 oldbucket 设为原有的桶 h.oldbuckets = oldbuckets // 将 bucket 设为新的新的空桶 h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 // 溢出桶采用相同的逻辑 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 我们可以看出，等量扩容创建的新桶数量和旧桶一样，而增量扩容创建的新桶则为原来的两倍。hashGrow只是创建了新桶，并没有对数据进行复制和转移。哈希表的数据迁移是由 runtime.growWork 和 runtime.evacuate 共同完成的，后者会对桶中的元素分流：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 func evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 计算要迁移的旧桶 b 的地址 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.BucketSize))) // 计算扩容前桶的数量 newbit := h.noldbuckets() // 若 b 没有被迁移 if !evacuated(b) { // 创建两个 evacDst 结构体用于保存分配上下文 // 它们分别指向一个新桶 var xy [2]evacDst x := \u0026xy[0] // 迁移到 x 的桶序号不变 x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.BucketSize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.KeySize)) if !h.sameSizeGrow() { // 只有在翻倍扩容的情况下才计算 y y := \u0026xy[1] // 迁移到 y 的桶序号增加扩容前桶的数量 y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.BucketSize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.KeySize)) } // 遍历所有的正常桶和溢出桶 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.KeySize)) // // 遍历桶 b 中的所有元素 for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.KeySize)), add(e, uintptr(t.ValueSize)) { top := b.tophash[i] // 若为空位，则直接跳过 if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } k2 := k var useY uint8 if !h.sameSizeGrow() { // 计算哈希值确定该元素应当迁移到 x 指向的桶还是 y 指向的桶 hash := t.Hasher(k2, uintptr(h.hash0)) // k2 为特殊值时的处理 if h.flags\u0026iterator != 0 \u0026\u0026 !t.ReflexiveKey() \u0026\u0026 !t.Key.Equal(k2, k2) {. useY = top \u0026 1 top = tophash(hash) } else { // 常规情况下的处理 if hash\u0026newbit != 0 { // 元素应当迁移到 y 指向的桶 useY = 1 } } } ... // 更新 tophash 以标记对应的元素已经被迁移 b.tophash[i] = evacuatedX + useY // 确定元素最终的迁移位置 dst := \u0026xy[useY] // 若新桶已满，则创建溢出桶 if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.KeySize)) } // 复制键值对到新 bucket dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.IndirectKey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.Key, dst.k, k) // copy elem } if t.IndirectElem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.Elem, dst.e, e) } dst.i++ dst.k = add(dst.k, uintptr(t.KeySize)) dst.e = add(dst.e, uintptr(t.ValueSize)) } } ... } // 若所有旧桶迁移完成，则清空 oldbuckets 和 oldoverflow if oldbucket == h.nevacuate { advanceEvacuationMark(h, t, newbit) } } 举例来说，旧桶数量是 4，新桶数量是 8。则旧桶的掩码是 $11_2$，新桶的掩码是 $111_2$。那么旧桶中 3 号桶的元素（哈希值后两位为 $11$）就会被分流到新桶中的 3 号桶（哈希值后三位为 $011$）和 7 号桶（哈希值后三位为 $111$）：\n之前在分析访问哈希表时其实省略了扩容期间获取键值对的逻辑，当哈希表的oldbuckets存在时，会先定位到旧桶并在该桶没有被迁移时从中获取键值对。\n而当哈希表正在处于扩容状态时，只有向哈希表写入值时才会触发 runtime.growWork 增量复制哈希表中的内容。先迁移旧桶，再完成写入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { ... again: bucket := hash \u0026 bucketMask(h.B) if h.growing() { growWork(t, h, bucket) } ... } func growWork(t *maptype, h *hmap, bucket uintptr) { // evacuate 将旧桶中的元素迁移到扩容后的新桶 evacuate(t, h, bucket\u0026h.oldbucketmask()) // 如果已处于扩容阶段，则再迁移第一个未迁移的旧桶 // 防止某些旧桶没有被写入导致扩容长时间无法完成 if h.growing() { evacuate(t, h, h.nevacuate) } } 传入该函数的bucket参数是我们即将访问的某一个新桶，bucket\u0026h.oldbucketmask()是与之对应的旧桶地址。举例来说，旧桶数量是 4，新桶数量是 8，旧桶的掩码是 $11_2$。如果bucket指向新桶中的 5 号桶，那么它在旧桶中的序号就应当是 $0101_2 \\And 0011_2$，即 1 号。该函数仅操作单个桶而非整个bmap数组，因此 Go 语言中哈希的扩容是渐进式的，每次最多迁移两个桶。\n删除 delete关键字可以删除哈希表中某一个键对应的元素，它会在编译时被转换为 runtime.mapdelete 函数簇中的一个。用于处理删除逻辑的函数与 runtime.mapassign 几乎完全相同，不太需要刻意关注。\n字符串 Go 语言中的字符串是一个只读的字节数组：\n不过我们仍然可以通过在string和[]byte类型之间反复转换实现修改这一目的：\n先将这段内存复制到堆或者栈上； 将变量的类型转换成[]byte后并修改字节数据； 将修改后的字节数组转换回string； 使用双引号声明的字符串只能用于单行字符串的初始化，如果字符串内部出现双引号，则需要使用\\符号避免编译器的解析错误。而反引号声明的字符串可以摆脱单行的限制，并且可以在字符串内部直接使用\"，在遇到需要手写 JSON 或者其他复杂数据格式的场景下非常方便：\n1 2 3 4 str1 := \"this is a string\" str2 := `this is another string` json := `{\"author\": \"draven\", \"tags\": [\"golang\"]}` 数据结构 每一个字符串在运行时都会使用如下的 internal/unsafeheader.String 表示，其中包含指向字节数组的指针和数组的大小：\n1 2 3 4 type String struct { Data unsafe.Pointer Len int } 因此我们常说字符串是只读的切片类型，所有在字符串上的写入操作都是通过复制实现的。\n拼接 正常情况下，运行时会调用copy将输入的多个字符串复制到目标字符串所在的内存空间。新的字符串是一片新的内存空间，与原来的字符串也没有任何关联，一旦需要拼接的字符串非常大，复制带来的性能损失是无法忽略的。\n如果需要拼接多次，应使用strings.Builder，最小化内存复制次数。\n类型转换 从字节数组[]byte到字符串的转换需要使用 runtime.slicebytetostring 函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // ptr 是指向切片第一个元素的指针 // n 是切片的长度，buf 是用于保存结果的固定长度缓冲区 func slicebytetostring(buf *tmpBuf, ptr *byte, n int) string { if n == 0 { return \"\" } ... if n == 1 { p := unsafe.Pointer(\u0026staticuint64s[*ptr]) // unfase.String 根据传入的指针和长度 // 返回实际的 string return unsafe.String((*byte)(p), 1) } var p unsafe.Pointer // 根据缓冲区大小决定是否需要为新字符串分配一片内存空间 if buf != nil \u0026\u0026 n \u003c= len(buf) { p = unsafe.Pointer(buf) } else { p = mallocgc(uintptr(n), nil, false) } // 将字节数组中的元素复制到新的内存空间中 memmove(p, unsafe.Pointer(ptr), uintptr(n)) return unsafe.String((*byte)(p), n) } 当我们想要将字符串转换成[]byte类型时，需要使用 runtime.stringtoslicebyte 函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func stringtoslicebyte(buf *tmpBuf, s string) []byte { var b []byte if buf != nil \u0026\u0026 len(s) \u003c= len(buf) { *buf = tmpBuf{} // 传入缓冲区时，用缓冲区存储字节切片 b = buf[:len(s)] } else { // 无缓冲区时，创建新的字节切片 b = rawbyteslice(len(s)) } // 将字符串中的内容复制到字节切片 copy(b, s) return b } 因此不过无论从哪种类型转换到另一种都需要复制数据，而内存复制的性能损耗会随着字符串和[]byte长度的增长而增长。\n","description":"","tags":["Go","Data-structure"],"title":"《Go 语言设计与实现》读书笔记：数据结构","uri":"/posts/go-data-structure-note/"},{"content":" 原书中的代码片段基于 Go 1.15，笔记则根据 Go 1.22 版本的更新进行了相应替换。\n预备知识 抽象语法树 抽象语法树（Abstract Syntax Tree，AST），是源代码语法的结构的一种抽象表示。它用树状的方式表示编程语言的语法结构，每个节点都表示源代码中的一个元素，每一颗子树都表示一个语法元素。以下列代码为例：\n1 2 3 4 5 6 while b ≠ 0: if a \u003e b: a := a - b else: b := b - a return a 编译器的语法分析阶段会生成如下图所示的抽象语法树：\n抽象语法树抹去了源代码中不重要的一些字符——空格、分号或者括号等等。编译器在执行完语法分析之后会输出一个抽象语法树，这个抽象语法树会辅助编译器进行语义分析，我们可以用它来确定语法正确的程序是否存在一些类型不匹配的问题。\n静态单赋值 静态单赋值（Static Single Assignment，SSA）是中间代码（IR）的一种特性，即每个变量只会被赋值一次。在实践中，我们通常会用下标实现静态单赋值。下列代码中第一行的赋值语句显然没有起到任何作用：\n1 2 3 x := 1 x := 2 y := x 但对于编译器来说，必须执行一定分析才能确定这一点。而如果中间代码具备 SSA 特性：\n1 2 3 x_1 := 1 x_2 := 2 y_1 := x_2 编译器便可以清楚地发现x_1和y_1没有任何关系，它在生成机器码时就可以省去x := 1的赋值，从而通过减少需要执行的指令来优化这段代码。\n编译器前端负责将源代码翻译成与编程语言无关的中间代码，后端主要负责目标代码的生成和优化。因为 SSA 的主要作用是对代码进行优化，所以它是编译器后端的一部分。\nISA 复杂指令集：通过增加指令的类型，减少需要执行的指令数量； 精简指令集：通过更少的指令类型完成计算任务。 编译原理 原图链接：Understanding Go Compiler\n词法分析 词法分析的作用是解析源代码文件，它将文件中的字符串序列转换成 Token 序列（即分词），如package,json,import, ……，方便后面的处理和解析。我们一般会把执行词法分析的程序称为词法解析器（Lexer）。\n从 Go 语言中定义的 Token 类型，我们可以将元素分成几个不同的类别，分别是名称、字面量、操作符、分隔符和关键字。词法分析主要由 cmd/compile/internal/syntax.scanner 结构体的 next 方法驱动，该结构体会持有当前被扫描到的 Token，而该函数的主体则是一个switch/case结构。\n语法分析 语法分析器则会将词法分析器输出的 Token 序列按照编程语言规定好的文法（Grammar）归纳成一个 SourceFile 结构，即抽象语法树：\n1 2 3 4 5 6 7 \"json.go\": SourceFile { PackageName: \"json\", ImportDecl: []Import{ \"io\", }, TopLevelDecl: ... } 该树的根节点 cmd/compile/internal/syntax.File 包含了当前文件所属的包名、定义的常量、结构体和函数等：\n1 2 3 4 5 6 7 type File struct { Pragma Pragma PkgName *Name DeclList []Decl Lines uint node } 其他节点的结构体则在 cmd/compile/internal/syntax/nodes.go 文件中定义，其中包含了全部声明类型，如函数声明：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type ( Decl interface { Node aDecl() } ... FuncDecl struct { Attr map[string]bool Recv *Field // 接收者 Name *Name // 函数名 Type *FuncType // 函数类型 Body *BlockStmt // 函数体 Pragma Pragma decl } ) 类型检查 编译器遍历抽象语法树以保证节点不存在类型错误，所有的类型错误和不匹配都会在这一个阶段被暴露出来（强类型），包括结构体对接口的实现。\nGo 语言的编译器不仅使用静态类型检查来保证程序运行的类型安全，还会在编译期间引入类型信息，让工程师能够使用反射来判断参数和变量的类型。当我们想要将interface{}转换成具体类型时会进行动态类型检查，如果无法发生转换程序就会崩溃。\n编译器类型检查的主要逻辑都在 cmd/compile/internal/typecheck.typecheck 和 cmd/compile/internal/typecheck.typecheck1 中，后者是类型检查的核心。该函数根据传入 节点 的操作类型进入不同分支：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func typecheck1(n ir.Node, top int) ir.Node { switch n.Op { ... // type or expr case ir.ODEREF: n := n.(*ir.StarExpr) return tcStar(n, top) ... case ir.OMAKE: n := n.(*ir.CallExpr) return tcMake(n) case ir.ONEW: n := n.(*ir.UnaryExpr) return tcNew(n) ... } } 以OMAKE节点为例，cmd/compile/internal/typecheck.tcMake 会对传入make的参数进行合法性检查，并根据第一个参数修改节点的操作类型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 func tcMake(n *ir.CallExpr) ir.Node { args := n.Args if len(args) == 0 { base.Errorf(\"missing argument to make\") n.SetType(nil) return n } n.Args = nil l := args[0] l = typecheck(l, ctxType) t := l.Type() if t == nil { n.SetType(nil) return n } // i 代表参数的最小个数 i := 1 var nn ir.Node switch t.Kind() { ... case types.TSLICE: ... // 节点的操作类型变为 OMAKESLICE nn = ir.NewMakeExpr(n.Pos(), ir.OMAKESLICE, l, r) case types.TMAP: ... // 节点的操作类型变为 OMAKEMAP nn = ir.NewMakeExpr(n.Pos(), ir.OMAKEMAP, l, nil) case types.TCHAN: ... // 节点的操作类型变为 OMAKECHAN nn = ir.NewMakeExpr(n.Pos(), ir.OMAKECHAN, l, nil) } if i \u003c len(args) { base.Errorf(\"too many arguments to make(%v)\", t) n.SetType(nil) return n } nn.SetType(t) return nn } 中间代码生成 在编译过程中，编译器会在将源代码转换到机器码的过程中，先把源代码转换成一种中间的表示形式，即 中间代码。很多编译器需要将源代码翻译成多种机器码，而直接翻译高级编程语言相对比较困难。中间代码是一种更接近机器语言的表示形式，对它的优化和分析相比直接分析高级编程语言更容易。\n编译阶段入口的主函数 cmd/compile/internal/gc.Main 中关于中间代码生成的部分如下，主要分为配置初始化和编译函数两部分：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func Main(archInit func(*ssagen.ArchInfo)) { ... // Prepare for backend processing. ssagen.InitConfig() ... // The SSA backend supports using multiple goroutines, // so keep it as late as possible to maximize // how much work we can batch and process concurrently. if len(compilequeue) != 0 { compileFunctions() continue } } 配置初始化 cmd/compile/internal/ssagen.InitConfig 的执行过程可以分为三个部分，首先便是创建结构体并缓存类型信息：\n1 2 3 4 5 6 7 8 9 10 11 12 func InitConfig() { // ssa.types 存储了 Go 所有基本类型对应的指针 types_ := ssa.NewTypes() // types.NewPtr 根据类型生成指向对应类型的指针 // 同时根据编译器的配置将生成的指针类型缓存在当前类型中 // 从而优化类型指针的获取效率 _ = types.NewPtr(types.Types[types.TINTER]) // *interface{} _ = types.NewPtr(types.NewPtr(types.Types[types.TSTRING])) _ = types.NewPtr(types.NewSlice(types.Types[types.TINTER])) ... _ = types.NewPtr(types.ErrorType) // *error 该函数随后根据当前的 CPU 架构、类型结构体和上下文信息设置用于生成中间代码和机器码的函数。所有的配置一旦被创建，在整个编译期间就变为只读的且被中间代码生成和机器码生成阶段共享：\n1 2 3 4 // ssa.NewConfig 返回一个 ssa.Config 结构体 // 后者包含了用于生成中间代码和机器码的函数以及 // 编译器使用的指针、寄存器大小、可用寄存器列表等编译选项： ssaConfig = ssa.NewConfig(base.Ctxt.Arch.Name, *types_, base.Ctxt, base.Flag.N == 0, Arch.SoftFloat) 最后，该函数会初始化一些编译器可能用到的 Go 语言运行时的函数：\n1 2 3 4 5 6 7 8 // Set up some runtime functions we'll need to call ... // LookupRuntimeFunc looks up Go function name in package runtime // 表示该方法已经注册到运行时包中 ir.Syms.Growslice = typecheck.LookupRuntimeFunc(\"growslice\") ir.Syms.Memmove = typecheck.LookupRuntimeFunc(\"memmove\") ir.Syms.Newobject = typecheck.LookupRuntimeFunc(\"newobject\") ... 遍历和替换 在生成中间代码之前，编译器还需要替换抽象语法树中节点的一些元素，这是通过 cmd/compile/internal/walk 包中的相关函数实现的：\n1 2 3 4 5 6 7 func walkExpr1(n ir.Node, init *ir.Nodes) ir.Node {} func walkAppend(n *ir.CallExpr, init *ir.Nodes, dst ir.Node) ir.Node {} func walkMakeMap(n *ir.MakeExpr, init *ir.Nodes) ir.Node {} func walkMakeSlice(n *ir.MakeExpr, init *ir.Nodes) ir.Node {} func walkSelect(sel *ir.SelectStmt) {} func walkSwitch(sw *ir.SwitchStmt) {} ... 它们会将一些关键字和内建函数转换成运行时包中的函数调用：\n因此，关键字和内置函数的功能是由编译器和运行时共同完成的：\nSSA 生成 经过walk系列函数的处理之后，抽象语法树就不会再改变了。改写后的语法树会经过多轮处理（去掉无用代码并精简操作数）转变成最后的 SSA 中间代码，我们可以通过如下命令生成main.go的中间代码ssa.html：\n1 2 3 4 5 $ GOSSAFUNC=main go build main.go # runtime dumped SSA to /usr/local/Cellar/go/1.14.2_1/libexec/src/runtime/ssa.html # command-line-arguments dumped SSA to ./ssa.html 机器码生成 Go 语言源代码的 cmd/compile/internal 目录中包含了很多机器码生成相关的包，不同类型的 CPU 分别使用了不同的包生成机器码，其中包括 amd64、arm、arm64、mips、mips64、ppc64、s390x、x86 和 wasm。\n机器码的生成主要由两部分协同完成：\nSSA 降级：将中间代码降级为汇编代码； 汇编器：将汇编代码翻译为机器码。 推荐阅读 Lexical Scanning in Go - Rob Pike Go: Overview of the Compiler ","description":"","tags":["Go","Compiler-principle"],"title":"《Go 语言设计与实现》读书笔记：编译原理","uri":"/posts/go-compiler-principle-note/"},{"content":"根据 第八章 介绍的内容，两个在时间上重叠的逻辑控制流是并发的。硬件异常处理程序、进程和 Linux 信号处理程序等都是计算机系统在不同层级上对并发的应用。现代操作系统为构建并发程序提供了三种基本方法：\n进程 I/O 多路复用（Multiplexing） 线程（Thread） 使用进程实现并发 构建并发程序最简单的方法是使用进程，如在父进程中接受客户端请求，然后创建子进程为客户端提供服务。\n假设服务器在监听描述符listenfd(3)上接受来自客户端 1 的连接请求，并返回一个连接描述符connfd(4)：\n服务器将调用fork创建一个子进程（下图中的“Child 1”），它获得服务器 描述符表 的完整副本。由于子进程不再需要监听描述符，而父进程不再需要连接描述符，我们应当将它们关闭：\n随后服务器接受来自客户端 2 的连接请求并返回一个新的连接描述符connfd(5)：\n服务器再次调用fork创建另一个子进程（下图中的“Child 2”）。此时，父进程正在等待下一个连接请求，两个子进程则并发地为各自的客户端提供服务：\n基于进程的并发服务器 一个基于进程的并发服务器代码如下，其中第 32 行调用的echo函数来自于上一章介绍的 echo.c：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #include \"csapp.h\" void echo(int connfd); void sigchld_handler(int sig) { while (waitpid(-1, 0, WNOHANG) \u003e 0) ; return; } int main(int argc, char **argv) { int listenfd, connfd; socklen_t clientlen; struct sockaddr_storage clientaddr; if (argc != 2) { fprintf(stderr, \"usage: %s \u003cport\u003e\\n\", argv[0]); exit(0); } Signal(SIGCHLD, sigchld_handler); listenfd = Open_listenfd(argv[1]); while (1) { clientlen = sizeof(struct sockaddr_storage); connfd = Accept(listenfd, (SA *)\u0026clientaddr, \u0026clientlen); if (Fork() == 0) { Close(listenfd); /* Child closes its listening socket */ echo(connfd); /* Child services client */ Close(connfd); /* Child closes connection with client */ exit(0); /* Child exits */ } Close(connfd); /* Parent closes connected socket (important!) */ } } 考虑到服务器将运行很长时间，我们需要安装一个 SIGCHLD 信号处理程序来回收子进程（第 4～9 行），详见 正确的信号处理。\n父进程必须关闭connfd（第 36 行），否则连接描述符指向的 打开文件表条目 永远不会被释放，从而导致内存泄漏。子进程则不需要关闭connfd（第 33 行可以省略），因为它会在子进程退出时由内核自动关闭。\n进程的优缺点 父子进程共享打开文件表，但并不共享用户地址空间（虚拟内存），因此进程之间必须显式地使用 IPC（Interprocess Communications）机制来共享状态信息。由于进程控制和 IPC 的开销很高，基于进程的并发程序往往很慢。\n使用 I/O 多路复用实现并发 I/O 多路复用技术的基本思想是应用程序调用select函数监视多个文件描述符，等待一个或多个描述符准备好用于某种 I/O 操作。该函数十分复杂并有多种使用场景，这里我们只讨论 I/O 操作为读取的情况：\n1 2 3 4 5 6 7 8 9 #include \u003csys/select.h\u003e int select(int n, fd_set *fdset, NULL, NULL, NULL); // Returns: nonzero count of ready descriptors, −1 on error // Macros for manipulating descriptor sets FD_ZERO(fd_set *fdset); /* Clear all bits in fdset */ FD_CLR(int fd, fd_set *fdset); /* Clear bit fd in fdset */ FD_SET(int fd, fd_set *fdset); /* Turn on bit fd in fdset */ FD_ISSET(int fd, fd_set *fdset); /* Is bit fd in fdset on? */ 参数fd_set是一个描述符集，它在逻辑上是一个位向量（固定长度的 0，1 序列）：\n$$b_{n - 1},…, b_1, b_0$$\n其中的每个位 $b_k$ 都对应了一个描述符 $k$。当且仅当 $b_k$ 等于 1 时，描述符 $k$ 属于该描述符集。\n在我们的应用场景中，参数fd_set是读取描述符集（Read Set），参数n是读取集的基数（Cardinality）。程序调用select函数后会一直阻塞，直到读取集中至少有一个描述符准备好被读取（即从该描述符中读取一个字节的请求不会阻塞）。\n我们将读取集中已准备好被读取的描述符集合称为就绪集（Ready Set）。select函数会将fdset修改为就绪集，并返回就绪集的基数。因此，我们在每次调用该函数前都应当先更新读取集。\n基于 I/O 多路复用的并发服务器 一个基于 I/O 多路复用的并发服务器代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 #include \"csapp.h\" typedef struct { /* represents a pool of connected descriptors */ int maxfd; /* largest descriptor in read_set */ fd_set read_set; /* set of all active descriptors */ fd_set ready_set; /* subset of descriptors ready for reading */ int nready; /* number of ready descriptors from select */ int maxi; /* highwater index into client array */ int clientfd[FD_SETSIZE]; /* set of active descriptors */ rio_t clientrio[FD_SETSIZE]; /* set of active read buffers */ } pool; int byte_cnt = 0; /* counts total bytes received by server */ int main(int argc, char **argv) { int listenfd, connfd; socklen_t clientlen; struct sockaddr_storage clientaddr; static pool pool; if (argc != 2) { fprintf(stderr, \"usage: %s \u003cport\u003e\\n\", argv[0]); exit(0); } listenfd = Open_listenfd(argv[1]); init_pool(listenfd, \u0026pool); while (1) { /* Wait for listening/connected descriptor(s) to become ready */ pool.ready_set = pool.read_set; pool.nready = Select(pool.maxfd + 1, \u0026pool.ready_set, NULL, NULL, NULL); /* If listening descriptor ready, add new client to pool */ if (FD_ISSET(listenfd, \u0026pool.ready_set)) { clientlen = sizeof(struct sockaddr_storage); connfd = Accept(listenfd, (SA *)\u0026clientaddr, \u0026clientlen); add_client(connfd, \u0026pool); } /* Echo a text line from each ready connected descriptor */ check_clients(\u0026pool); } } 该程序使用pool类型的结构体（第 3～12 行）保存活跃的客户端，并使用init_pool函数初始化客户端池（第 29 行）。在无限循环的每次迭代中，服务器调用select函数检测两种不同类型的输入事件：来自新客户端的连接请求；为现有客户端提供服务的连接描述符已准备好被读取。当连接请求到达时（第 38 行），服务器打开连接（第 41 行）并将新客户端加入到客户端池中（第 42 行）。最后，服务器调用check_clients函数向每个已连接的描述符写入文本行（第 46 行）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 void init_pool(int listenfd, pool *p) { /* Initially, there are no connected descriptors */ int i; p-\u003emaxi = -1; for (i = 0; i \u003c FD_SETSIZE; i++) p-\u003eclientfd[i] = -1; /* Initially, listenfd is only member of select read set */ p-\u003emaxfd = listenfd; FD_ZERO(\u0026p-\u003eread_set); FD_SET(listenfd, \u0026p-\u003eread_set); } init_pool函数初始化客户端池。p-\u003eclientfd数组包含了所有已连接的描述符，一开始我们使用 -1 填充它（第 5～7 行）。此时listenfd是读取集p-\u003eread_set中唯一的描述符（第 10～12 行）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 void add_client(int connfd, pool *p) { int i; p-\u003enready--; for (i = 0; i \u003c FD_SETSIZE; i++) /* Find an available slot */ if (p-\u003eclientfd[i] \u003c 0) { /* Add connected descriptor to the pool */ p-\u003eclientfd[i] = connfd; Rio_readinitb(\u0026p-\u003eclientrio[i], connfd); /* Add the descriptor to descriptor set */ FD_SET(connfd, \u0026p-\u003eread_set); /* Update max descriptor and pool highwater mark */ if (connfd \u003e p-\u003emaxfd) p-\u003emaxfd = connfd; if (i \u003e p-\u003emaxi) p-\u003emaxi = i; break; } if (i == FD_SETSIZE) /* Couldn't find an empty slot */ app_error(\"add_client error: Too many clients\"); } add_client函数将一个新客户端添加到活跃客户端池中。如果p-\u003eclientfd数组中还有空位（第 6 行），该函数就将连接描述符connfd添加到该数组并初始化一个读取缓冲区以调用 rio_readlineb（第 9～10 行）。随后函数将连接描述符connfd添加到读取集（第 13 行），并更新客户端池的一些属性：变量maxfd代表select函数监视的最大文件描述符；变量maxi代表p-\u003eclientfd数组的最大索引（这样check_clients函数就不需要遍历整个数组）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 void check_clients(pool *p) { int i, connfd, n; char buf[MAXLINE]; rio_t rio; for (i = 0; (i \u003c= p-\u003emaxi) \u0026\u0026 (p-\u003enready \u003e 0); i++) { connfd = p-\u003eclientfd[i]; rio = p-\u003eclientrio[i]; /* If the descriptor is ready, echo a text line from it */ if ((connfd \u003e 0) \u0026\u0026 (FD_ISSET(connfd, \u0026p-\u003eready_set))) { p-\u003enready--; if ((n = Rio_readlineb(\u0026rio, buf, MAXLINE)) != 0) { byte_cnt += n; printf(\"Server received %d (%d total) bytes on fd %d\\n\", n, byte_cnt, connfd); Rio_writen(connfd, buf, n); } /* EOF detected, remove descriptor from pool */ else { Close(connfd); FD_CLR(connfd, \u0026p-\u003eread_set); p-\u003eclientfd[i] = -1; } } } } check_clients函数遍历客户端池中所有已就绪的连接描述符，如果从描述符中读取文本行成功（第 16 行），就将该行返回给客户端（第 18-21 行）。一旦客户端关闭连接且服务器检测到 EOF，服务器便关闭连接描述符（第 27 行）并将该描述符从读取集和客户端池中删除（第 28-29 行）。\nI/O 多路复用的本质是将逻辑控制流建模为状态机（State Machines）：\n如上图所示，基于 I/O 多路复用的并发服务器为每个新客户端 $k$ 创建一个状态机 $s_k$ 并将其与连接描述符 $d_k$ 关联。每个状态机都有一个状态（等待描述符 $d_k$ 准备好被读取），一个输入事件（描述符 $d_k$ 已准备好被读取）和一个状态转换（从描述符 $d_k$ 中读取文本行）。\n在示例的并发服务器中，select函数检测输入事件，add_client函数创建新的状态机（逻辑控制流）。check_clients函数通过读写文本行来执行状态转换，并在客户端发送完文本行后删除状态机。\nI/O 多路复用的优缺点 基于 I/O 多路复用的应用程序运行在单个进程的上下文中，因此每个逻辑控制流都可以访问整个进程的地址空间，这使得控制流之间共享数据变得非常容易。由于它不需要通过上下文切换管理新进程，程序的运行效率较高。像 Node.js、Nginx 和 Tornado 等现代高性能服务器均使用 I/O 多路复用实现。\nI/O 多路复用的缺点是编码十分复杂，并且无法充分利用多核处理器。\n使用线程实现并发 线程是在进程上下文中运行的逻辑控制流，它由内核自动调度。每个线程都有自己的线程上下文，包括一个唯一的线程 ID（TID）、栈、栈指针、程序计数器、通用寄存器和条件码寄存器。在同一个进程内运行的所有线程共享该进程全部的虚拟地址空间。\n线程执行模型 线程的执行模型与进程类似：\n如上图所示，主线程（Main Thread）是进程生命周期的开始，它在某一时刻创建了一个对等线程（Peer Thread）。两线程同时运行，控制权通过上下文切换传递。\n线程执行与进程的区别在于：\n线程上下文比进程上下文小得多，因此线程上下文切换比进程快； 属于同一进程的线程构成了一个对等池，它们没有父子层级结构。线程可以杀死任何对等线程或等待任何对等线程终止； 每个对等线程都可以读写相同的共享数据。 Posix 线程 Posix 线程（Pthread）是 C 程序操作线程的标准接口。它定义了大约六十个函数，允许程序创建线程、终止线程、回收线程、与对等线程安全地共享数据以及通知对等线程系统状态的变化等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \"csapp/csapp.h\" void *thread(void *vargp) /* thread routine */ { printf(\"Hello, world!\\n\"); return NULL; } int main() { pthread_t tid; Pthread_create(\u0026tid, NULL, thread, NULL); Pthread_join(tid, NULL); exit(0); } 示例程序中，主线程创建了一个对等线程并等待它终止，对等线程在打印Hello, world!\\n后返回。\n线程的代码和局部数据封装在线程例程（Thread Routine）中，它将通用指针void *作为输入并返回另一个通用指针（第 2 行）。如果需要向线程例程传递多个参数，则应将它们放入一个结构体中并传递指向该结构体的指针。同样，如果想让线程例程返回多个参数，则应返回一个指向包含多个参数的结构体指针。\n创建线程 线程调用函数pthread_create创建新线程：\n1 2 3 4 5 #include \u003cpthread.h\u003e typedef void *(func)(void *); int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *arg); // Returns: 0 if OK, nonzero on error 参数f是新线程在其上下文中运行的例程，参数arg是该例程的输入参数。参数attr可用于更改新线程的默认属性，一般设为NULL。该函数返回时，参数tid将变为新线程的线程 ID。线程还可以调用pthread_self函数确认自己的线程 ID：\n1 2 3 #include \u003cpthread.h\u003e pthread_t pthread_self(void); //Returns: thread ID of caller 终止线程 线程终止的方式包括：\n在其例程返回时隐式终止； 调用函数pthread_exit显式终止，参数thread_return用于函数 pthread_join： 1 2 3 #include \u003cpthread.h\u003e void pthread_exit(void *thread_return); // Never returns 调用 Linux 函数exit终止进程以及与该进程关联的所有线程； 调用函数pthread_cancel终止另一个线程 ID 为tid的对等线程： 1 2 3 #include \u003cpthread.h\u003e int pthread_cancel(pthread_t tid); // Returns: 0 if OK, nonzero on error 回收线程 线程调用pthread_join函数等待另一个线程tid终止：\n1 2 3 #include \u003cpthread.h\u003e int pthread_join(pthread_t tid, void **thread_return); // Returns: 0 if OK, nonzero on error 线程tid终止后，该函数将线程例程返回的通用指针分配到thread_return指向的位置，然后回收终止线程持有的所有内存资源。与 waitpid 不同，pthread_join只能等待某个特定线程终止。\n分离线程 在任意时刻，线程都是可连接的（Joinable）或分离的（Detached）。一个可连接的线程可以被其他线程回收或杀死，其内存资源（如栈）在它被另一个线程回收之前不会释放；相反，一个分离的线程无法被其他线程回收或杀死，其内存资源将在它终止时由系统自动释放。\n默认情况下，线程是可连接的。为了避免内存泄漏，每个可连接的线程都应当被另一个线程显式地回收，或者调用pthread_detach函数成为一个分离的线程：\n1 2 3 #include \u003cpthread.h\u003e int pthread_detach(pthread_t tid); // Returns: 0 if OK, nonzero on error 参数tid是被分离的线程 ID，线程可以将其设为pthread_self()来分离自己。\n初始化线程 线程调用pthread_once函数初始化与线程例程关联的状态：\n1 2 3 4 5 #include \u003cpthread.h\u003e pthread_once_t once_control = PTHREAD_ONCE_INIT; int pthread_once(pthread_once_t *once_control, void (*init_routine)(void)); // Always returns 0 参数once_control是一个全局变量或静态变量，它始终被初始化为PTHREAD_ONCE_INIT。该函数第一次被调用时会直接调用init_routine，随后使用相同once_control参数的调用不会起任何作用。如下示例程序将输出 1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u003cpthread.h\u003e #include \u003cstdio.h\u003e pthread_once_t once_control = PTHREAD_ONCE_INIT; int cnt; void init_routine(void) { cnt++; } int main() { pthread_once(\u0026once_control, *init_routine); pthread_once(\u0026once_control, *init_routine); printf(\"%d\", cnt); } 当我们需要动态初始化多个线程共享的全局变量时，该函数十分有用。\n基于线程的并发服务器 一个基于线程的并发服务器代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \"csapp.h\" void echo(int connfd); /* thread routine */ void *thread(void *vargp) { int connfd = *((int *)vargp); Pthread_detach(pthread_self()); Free(vargp); echo(connfd); Close(connfd); return NULL; } int main(int argc, char **argv) { int listenfd, *connfdp; socklen_t clientlen; struct sockaddr_storage clientaddr; pthread_t tid; if (argc != 2) { fprintf(stderr, \"usage: %s \u003cport\u003e\\n\", argv[0]); exit(0); } listenfd = Open_listenfd(argv[1]); while (1) { clientlen = sizeof(struct sockaddr_storage); connfdp = Malloc(sizeof(int)); *connfdp = Accept(listenfd, (SA *)\u0026clientaddr, \u0026clientlen); Pthread_create(\u0026tid, NULL, thread, connfdp); } } 程序的整体结构与基于进程的并发服务器类似，主线程反复等待客户端连接，然后创建对等线程处理请求。值得注意的是，该程序调用Malloc函数生成指向连接描述符的指针connfdp并将其传递给对等线程（第 32～34 行）。这是因为如果我们直接传递指针，如：\n1 2 3 4 5 6 7 connfd = Accept(listenfd, (SA *) \u0026clientaddr, \u0026clientlen); Pthread_create(\u0026tid, NULL, thread, \u0026connfd); void *thread(void *vargp) { int connfd = *((int *)vargp); . . . } 就会导致对等线程中的赋值语句与主线程中的Accpet调用产生竞争：若新客户端在赋值语句执行完毕前与服务器建立连接，则对等线程中的局部变量connfd会变成新客户端的连接描述符。由于Malloc可以将connfd动态分配到不同的堆内存 Block 中，这一问题便得到了解决。\n为了避免内存泄漏，我们必须分离每个线程（第 8 行）并释放主线程分配的堆内存（第 9 行）。进程中的所有线程共享描述符表，连接描述符的rfcnt始终为 1。因此我们只需在对等线程中关闭连接描述符，而不必像基于进程的并发服务器那样在主线程进行同样的操作。\n线程程序中的共享变量 在程序员看来，线程的最大优势在于多个线程可以轻松地共享相同的程序变量。然而，这种便利可能会带来一些问题。为了正确地编写线程程序，我们以如下程序为例说明共享变量的含义及工作原理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #include \"csapp.h\" #define N 2 void *thread(void *vargp); char **ptr; /* global variable */ int main() { int i; pthread_t tid; char *msgs[N] = { \"Hello from foo\", \"Hello from bar\"}; ptr = msgs; for (i = 0; i \u003c N; i++) Pthread_create(\u0026tid, NULL, thread, (void *)i); Pthread_exit(NULL); } void *thread(void *vargp) { int myid = (int)vargp; static int cnt = 0; printf(\"[%d]: %s (cnt=%d)\\n\", myid, ptr[myid], ++cnt); return NULL; } 线程内存模型 每个线程都有自己独立的线程上下文，因此多个线程之间共享同一进程上下文中的其余部分。它们包括：只读文本（代码）段、可读写数据段、堆、共享库和打开文件描述符等。\n线程无法读取或写入另一个线程的寄存器，但任何线程都能够访问共享虚拟内存中的任何位置。尽管栈属于线程上下文的一部分，但线程可以使用指针对另一个线程的栈内容读取和写入。示例程序第 25 行，对等线程通过全局变量ptr间接引用了主线程栈中的数组msgs[N]。\n将变量映射到内存 C 线程程序根据变量的存储类型将其映射到虚拟内存：\n全局变量：全局变量的唯一实例在运行时位于 可读写段，它可以被任意线程引用。示例程序第 5 行声明的全局变量ptr便是如此； 局部自动变量：局部自动变量在运行时位于每个线程的栈中，如示例程序中的变量tid和myid。为了区分不同线程中的相同变量，我们将它们分别表示为tid.m、myid.p0和myid.p1； 局部静态变量：与全局变量一样，局部静态变量的唯一实例在运行时位于可读写段。即使示例程序中的每个对等线程都声明了局部静态变量cnt（第 24 行），在运行时虚拟内存中也只有一个cnt实例。 共享变量 当一个变量的实例被多个线程引用时，我们就称它为共享的。在示例程序中，变量cnt是共享的，而myid则不是。对等线程均通过ptr间接引用了局部变量msgs，因此msgs也是共享的。\n使用信号量同步线程 以下程序badcnt.c创建了两个对等线程，每个线程都会将全局共享变量cnt递增niters次：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #include \"csapp.h\" void *thread(void *vargp); /* Thread routine prototype */ /* Global shared variable */ volatile long cnt = 0; /* Counter */ int main(int argc, char **argv) { long niters; pthread_t tid1, tid2; /* Check input argument */ if (argc != 2) { printf(\"usage: %s \u003cniters\u003e\\n\", argv[0]); exit(0); } niters = atoi(argv[1]); /* Create threads and wait for them to finish */ Pthread_create(\u0026tid1, NULL, thread, \u0026niters); Pthread_create(\u0026tid2, NULL, thread, \u0026niters); Pthread_join(tid1, NULL); Pthread_join(tid2, NULL); /* Check result */ if (cnt != (2 * niters)) printf(\"BOOM! cnt=%d\\n\", cnt); else printf(\"OK cnt=%d\\n\", cnt); exit(0); } /* Thread routine */ void *thread(void *vargp) { long i, niters = *((long *)vargp); for (i = 0; i \u003c niters; i++) cnt++; return NULL; } 理论上，该程序的输出结果应为2 * niters。然而当它在 Linux 系统上运行时，我们不但会得到错误的答案，并且每次的结果还不同：\n1 2 3 linux\u003e ./badcnt 1000000 BOOM! cnt=1445085 linux\u003e ./badcnt 1000000 BOOM! cnt=1915220 linux\u003e ./badcnt 1000000 BOOM! cnt=1404746 为了清楚地理解这一问题，我们需要研究一下计数器循环（第 40～41 行）的汇编代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 ; i in %rax, niters in %rcx, cnt in %rdx movq (%rdi), %rcx testq %rcx, %rcx jle .L2 movl $0, %eax .L3: movq cnt(%rip), %rdx addq $1, %rdx movq movq %rdx, cnt(%rip) addq $1, %rax cmpq %rcx, %rax jne .L3 .L2: 这段代码可以分为以下五个部分：\n$H_i$：循环头部的指令块（第 2～5 行）； $L_i$：将变量cnt加载到寄存器 %$rdx_i$（第 7 行）； $U_i$：将 %$rdx_i$ 加一（第 8 行）； $S_i$：将 %$rdx_i$ 更新后的值存回变量cnt（第 9 行）； $T_i$：循环尾部的指令块（第 10～13 行）。 上述指令在单核处理器上以某种顺序依次执行，不同的执行顺序将导致不同的结果。我们以第一次循环为例：\n如图（b）所示，线程 2 在第五步将变量cnt加载到 %$rdx_2$。此时线程 1 已经在第三步更新了 %$rdx_1$ 的值，但还未把它存回cnt。因此 %$rdx_2$ 的初始值为 0，线程 2 无法像图（a）那样将cnt从 1 递增到 2。\n进度图 进度图（Progress Graph）将 n 个并发线程建模为 n 维笛卡尔空间中的轨迹（Trajectory）。其中，每个坐标轴对应线程 $k$ 的进度，每个点代表线程 $k$ 已完成指令 $I_k$ 的状态。程序badcnt.c第一次循环的进度图如下，点 $(L_1, S_2)$ 代表线程 1 已完成 $L_1$，线程 2 则已完成 $S_2$：\n程序的执行历史可以用进度图中的轨迹表示。假设该程序第一次循环的指令执行顺序为：\n$$H_1, L_1, U_1, H_2, L_2, S_1, T_1, U_2, S_2, T_2$$\n则进度图轨迹为：\n对于线程 $i$，操作共享变量cnt的指令 $(L_i, U_i, S_i)$ 构成了一个临界区（Critical Section），它不应当与其他线程的临界区相交。在进度图上，两线程临界区的交集构成了不安全区（Unsafe Region）：\n不安全区不包括其边缘，例如状态 $(H_1, H_2)$ 和 $(S_1, U_2)$ 均不属于该区域。绕过不安全区的轨迹被称为安全轨迹，而触及了不安全区中任何部分的轨迹都是不安全的。\n信号量 信号量（Semaphore）s是一个具有非负整数值的全局变量，我们只能对它进行两种操作：\nP(s)：若s非零，则将其减一并立即返回；若s为零，则将线程暂停。当s变为非零且线程由V操作重启后，P再将s减一并把控制权返回给调用者； V(s)：将s加一。如果存在任何被P操作阻塞的线程，就随机重启它们中的一个。 P(s)和V(s)操作不可分割（具有原子性），因此它们不会被中断。其定义保证了正确初始化的信号量永远不会变为负值，我们将这种属性称为信号量的不变性（Semaphore Invariant）。\nPosix 标准定义了多种操作信号量的函数：\n1 2 3 4 5 #include \u003csemaphore.h\u003e int sem_init(sem_t *sem, int pshared, unsigned int value); int sem_wait(sem_t *s); /* P(s) */ int sem_post(sem_t *s); /* V(s) */ // Returns: 0 if OK, −1 on error 每个信号量都必须在使用前初始化，sem_init函数则将信号量sem初始化为参数value。在我们的应用场景中，参数pshared始终为 0。线程分别调用sem_wait和sem_post函数来执行P(s)和V(s)操作。为了简洁起见，我们使用以下等效的包装函数代替：\n1 2 3 4 #include \"csapp.h\" void P(sem_t *s); /* Wrapper function for sem_wait */ void V(sem_t *s); /* Wrapper function for sem_post */ // Returns: nothing 使用信号量实现互斥 信号量提供了一种便捷的方法来确保线程对共享变量的访问互斥（Mutually Exclusive）：将一个初始值为 1 的信号量与每个共享变量相关联，然后使用P和V操作包围临界区。\n在这种情况下，信号量的值始终为 0 或 1，因此我们将它称为二进制信号量。用于实现互斥的二进制信号量通常被称为互斥锁（Mutex），对其进行P和V操作则分别被称为加锁和解锁。一个已被锁定但互斥锁还未被解锁的线程被称为持有互斥锁。\n下图展示了我们如何使用二进制信号量正确同步程序badcnt.c，其中的每个状态都标注了该状态下信号量的值：\n图中信号量为 -1 的状态共同构成了禁止区（Forbidden Region）。由于信号量的不变性，任何可行的轨迹都无法进入该区域。禁止区完全包围了不安全区，因此轨迹也不会触及不安全区的任何部分。无论运行时指令执行的顺序如何，程序都会正确地递增cnt。\n综上，为了使用信号量实现互斥，我们需要首先声明一个信号量mutex：\n1 2 volatile long cnt = 0; /* Counter */ sem_t mutex; /* Semaphore that protects counter */ 然后在主线程中将其初始化：\n1 Sem_init(\u0026mutex, 0, 1); /* mutex = 1 */ 最终在对等线程中调用P和V包围对共享变量cnt的更新操作：\n1 2 3 4 5 for (i = 0; i \u003c niters; i++) { P(\u0026mutex); cnt++; V(\u0026mutex); } 使用信号量调度共享资源 除了实现互斥之外，信号量的另一个重要作用是调度对共享资源的访问。在这种情况下，线程使用信号量与其他线程通信。让我们来看看两个经典案例：生产者-消费者（Producer-Consumer）问题和读取者-写入者（Readers-Writers）问题。\n生产者-消费者问题 如上图所示，生产者和消费者线程共享一个有界缓冲区。生产者线程重复生成新项目并将它们插入缓冲区，消费者线程则不断从缓冲区中删除项目，然后消费（使用）它们。\n由于插入和删除项目涉及到更新共享变量，我们必须保证线程对缓冲区的访问是互斥的。但仅仅保证互斥是不够的，我们还需要调度线程对缓冲区的访问：若缓冲区已满（没有空位），则生产者必须等待空位；若缓冲区为空（没有可用的项目），则消费者必须等待项目可用。\n我们开发了一个名为 $S_{buf}$ 的简单包，它可以操作sbuf_t类型的缓冲区：\n1 2 3 4 5 6 7 8 9 typedef struct { int *buf; /* Buffer array */ int n; /* Maximum number of slots */ int front; /* buf[(front+1)%n] is first item */ int rear; /* buf[rear%n] is last item */ sem_t mutex; /* Protects accesses to buf */ sem_t slots; /* Counts available slots */ sem_t items; /* Counts available items */ } sbuf_t; 所有项目均存储在一个动态分配且包含n个空位的整型数组buf中，front和rear用于记录数组中的第一个项目和最后一个项目。信号量mutex实现了对缓冲区访问的互斥，slots和items则分别计算缓冲区中的空位和可用项目的数量。\n$S_{buf}$ 包的实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #include \"csapp.h\" #include \"sbuf.h\" /* Create an empty, bounded, shared FIFO buffer with n slots */ void sbuf_init(sbuf_t *sp, int n) { sp-\u003ebuf = Calloc(n, sizeof(int)); sp-\u003en = n; /* Buffer holds max of n items */ sp-\u003efront = sp-\u003erear = 0; /* Empty buffer iff front == rear */ Sem_init(\u0026sp-\u003emutex, 0, 1); /* Binary semaphore for locking */ Sem_init(\u0026sp-\u003eslots, 0, n); /* Initially, buf has n empty slots */ Sem_init(\u0026sp-\u003eitems, 0, 0); /* Initially, buf has zero data items */ } /* Clean up buffer sp */ void sbuf_deinit(sbuf_t *sp) { Free(sp-\u003ebuf); } /* Insert item onto the rear of shared buffer sp */ void sbuf_insert(sbuf_t *sp, int item) { P(\u0026sp-\u003eslots); /* Wait for available slot */ P(\u0026sp-\u003emutex); /* Lock the buffer */ sp-\u003ebuf[(++sp-\u003erear)%(sp-\u003en)] = item; /* Insert the item */ V(\u0026sp-\u003emutex); /* Unlock the buffer */ V(\u0026sp-\u003eitems); /* Announce available item */ } /* Remove and return the first item from buffer sp */ int sbuf_remove(sbuf_t *sp) { int item; P(\u0026sp-\u003eitems); /* Wait for available item */ P(\u0026sp-\u003emutex); /* Lock the buffer */ item = sp-\u003ebuf[(++sp-\u003efront)%(sp-\u003en)]; /* Remove the item */ V(\u0026sp-\u003emutex); /* Unlock the buffer */ V(\u0026sp-\u003eslots); /* Announce available slot */ return item; } sbuf_init函数为缓冲区分配堆内存，将front和rear设为 0，并为三个信号量分配初始值；sbuf_deinit函数在程序使用完缓冲区后释放它；sbuf_insert函数等待一个可用的空位，然后锁定mutex，将项目添加到缓冲区尾部并解锁mutex，最后通知消费者线程新项目可用；sbuf_remove函数与之对称：当缓冲区中有项目可用时，它锁定mutex，然后移除缓冲区头部的项目并解锁mutex，最后通知生产者有新的空位。\n读取者-写入者问题 读取者-写入者问题是互斥问题的一般化。假设并发线程集合正在访问一个共享对象，如主存中的数据结构或磁盘上的数据库。写入者必须拥有对该对象的独占访问权，但读取者却可以与其他读取者共享。\n我们可以根据读取者和写入者的优先级将这一问题分为两种情况：\n读取者优先：读取者不会因写入者在等待而等待； 写入者优先：一旦写入者准备好写入就尽快执行写入。 示例程序展示了一个读取者优先的解决方案：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /* Global variables */ int readcnt; /* Initially = 0 */ sem_t mutex, w; /* Both initially = 1 */ void reader(void) { while (1) { P(\u0026mutex); readcnt++; if (readcnt == 1) /* First in */ P(\u0026w); V(\u0026mutex); /* Critical section */ /* Reading happens */ P(\u0026mutex); readcnt--; if (readcnt == 0) /* Last out */ V(\u0026w); V(\u0026mutex); } } void writer(void) { while (1) { P(\u0026w); /* Critical section */ /* Writing happens */ V(\u0026w); } } 信号量w实现了对共享对象访问的互斥，mutex则保护了对共享变量readcnt（表示当前处于临界区的读取者数量）的访问。写入者每次进入临界区时都会锁定w并在离开时对其解锁。但只有第一个进入临界区的读取者才需要锁定w，只有最后一个离开临界区的读取者才需要解锁它。因此只要有一个读取者持有w（位于临界区），其他读取者就都可以畅通无阻地访问共享对象。\n所有此类问题的解决方案都会导致饥饿（Starvation），即线程被阻塞并无法取得任何进展。例如在上述程序中，当读取者线程批量到达时，写入者只能无限期等待。\n基于预线程的并发服务器 前文介绍的 基于线程的并发服务器 需要为每个客户端创建一个新线程，因此其成本较高。基于预线程（Prethreading）的并发服务器可以通过生产者-消费者模型减少这一开销：\n如上图所示，主线程不断地接受来自客户端连接请求并在有界缓冲区中插入连接描述符。每个工作线程重复地从缓冲区中移除一个描述符并为客户端提供服务，然后等待下一个描述符。\n我们使用 $S_{buf}$ 包实现这一模型：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 #include \"csapp.h\" #include \"sbuf.h\" #define NTHREADS 4 #define SBUFSIZE 16 void echo_cnt(int connfd); void *thread(void *vargp); sbuf_t sbuf; /* shared buffer of connected descriptors */ int main(int argc, char **argv) { int i, listenfd, connfd; socklen_t clientlen; struct sockaddr_storage clientaddr; pthread_t tid; if (argc != 2) { fprintf(stderr, \"usage: %s \u003cport\u003e\\n\", argv[0]); exit(0); } listenfd = Open_listenfd(argv[1]); sbuf_init(\u0026sbuf, SBUFSIZE); for (i = 0; i \u003c NTHREADS; i++) /* Create worker threads */ Pthread_create(\u0026tid, NULL, thread, NULL); while (1) { clientlen = sizeof(struct sockaddr_storage); connfd = Accept(listenfd, (SA *)\u0026clientaddr, \u0026clientlen); sbuf_insert(\u0026sbuf, connfd); /* Insert connfd in buffer */ } } void *thread(void *vargp) { Pthread_detach(pthread_self()); while (1) { int connfd = sbuf_remove(\u0026sbuf);/* Remove connfd from buffer */ echo_cnt(connfd); /* Service client */ Close(connfd); } } 在初始化缓冲区sbuf（第 25 行）之后，主线程创建了一组工作线程（第 26～27 行）。它进入无限循环，接受连接请求并将连接描述符插入到sbuf中。工作线程等待连接描述符可用后便将其从缓冲区中移除（第 42 行），然后调用echo_cnt函数为客户端提供服务。\necho_cnt是上文提到的echo函数的变体，它将服务器接收到的字节数记录在全局变量byte_cnt中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #include \"csapp.h\" static int byte_cnt; /* byte counter */ static sem_t mutex; /* and the mutex that protects it */ static void init_echo_cnt(void) { Sem_init(\u0026mutex, 0, 1); byte_cnt = 0; } void echo_cnt(int connfd) { int n; char buf[MAXLINE]; rio_t rio; static pthread_once_t once = PTHREAD_ONCE_INIT; Pthread_once(\u0026once, init_echo_cnt); Rio_readinitb(\u0026rio, connfd); while ((n = Rio_readlineb(\u0026rio, buf, MAXLINE)) != 0) { P(\u0026mutex); byte_cnt += n; printf(\"server received %d (%d total) bytes on fd %d\\n\", n, byte_cnt, connfd); V(\u0026mutex); Rio_writen(connfd, buf, n); } } 该函数使用Pthread_once（第 19 行）初始化信号量mutex和byte_cnt，于是我们便不必在主线程进行同样的操作了。这种方法使包更加易于使用，不过同时也增加了许多无用的工作（只有第一次调用Pthread_once是有意义的）。\n使用线程实现并行 到目前为止，我们对并发的研究仅局限于单核处理器。实际上并发程序往往在拥有多核处理器的机器上运行得更快，这是因为操作系统内核可以在多个 CPU 核心上并行调度线程。\n编写并行程序十分棘手，看似很小的代码更改却会对程序性能产生重大的影响。并行程序同步线程的开销非常高，因此我们需要尽量避免它，否则就可能出现线程数增加程序性能反而降低的问题。如果同步操作不可避免，则应当尽可能地增加有用计算以分摊其开销。\n由于在同一个核心上切换多个线程的上下文会产生额外的开销，并行程序的线程数通常与机器的 CPU 核心数相同。\n并行程序的性能指标 加速比（Speedup）被定义为：\n$$S_p = \\cfrac{T_1}{T_p}$$\n其中，$p$ 是处理器核心的数量，$T_p$ 是程序在 $p$ 个核心上运行的时间。这个公式也被称为强缩放（Strong Scaling）。当 $T_1$ 是并行程序的顺序执行版本的运行时间时，$S_p$ 被称为绝对加速比；当 $T_1$ 是并行程序在一个核心上的运行时间时，$S_p$ 被称为相对加速比。绝对加速比比相对加速比更能真实地反映程序的性能，然而它也更难测量。尤其是一些复杂的并行程序，为其创建一个顺序执行的版本非常困难。\n效率（Efficiency）被定义为：\n$$E_p = \\cfrac{S_p}{p} = \\cfrac{T_1}{pT_p}$$\n该指标能够衡量程序并行化的开销，效率高的程序用于线程同步和通信的时间较少。\n其他并发问题 线程安全 若一个函数被多个并发线程重复调用时总能生成正确的结果，我们就称它为线程安全的（Thread-safe）。反之，则为线程不安全函数。线程不安全函数可以分为以下四类：\n不保护共享变量的函数：上文提到的 badcnt 函数便属于此类。我们只需使用P和V等同步操作保护共享变量便可使函数线程安全，但同时也会增加程序的运行时间； 在多次调用中持续跟踪状态的函数：如伪随机数生成函数 rand，其当前调用的结果取决于上次迭代的中间结果。因此如果多个线程调用该函数，我们就无法确定返回的随机数序列。修改此类函数唯一的方法便是重写它们，使其不依赖任何static数据并让调用者通过参数来传递状态信息； 1 2 3 4 5 6 7 8 9 10 11 12 13 14 static unsigned int next_seed = 1; /* rand - return pseudo-random integer on 0..32767 */ int rand(void) { next_seed = next_seed*1103515245 + 12345; return (unsigned int)(next_seed/65536) % 32768; } /* srand - set seed for rand() */ void srand(unsigned int new_seed) { next_seed = new_seed; } 返回指向static变量指针的函数：一些函数，如ctime和gethostbyname，在static变量中计算结果并返回指向该变量的指针。如果并发线程调用此类函数，一个线程正在使用的变量就有可能被另一个线程返回的结果覆盖。我们可以直接重写它们，但也可以在源码不可用或难以修改时使用锁定和复制（Lock-and-Copy）技术来解决线程不安全问题； 1 2 3 4 5 6 7 8 9 10 char *ctime_ts(const time_t *timep, char *privatep) { char *sharedp; P(\u0026mutex); sharedp = ctime(timep); strcpy(privatep, sharedp); /* Copy string from shared to private */ V(\u0026mutex); return privatep; } 调用线程不安全函数的函数：如果函数f调用了第二类线程不安全函数g，那么f也是线程不安全的并且只能重写g；如果g是第一类或第三类函数，我们就可以使用互斥锁保护调用点和所有生成的共享数据以使f线程安全。在上面的例子中，虽然函数ctime_ts调用了线程不安全函数ctime，但它却是线程安全的。 可重入 可重入（Reentrant）函数是一种特殊的线程安全函数，它在被多个线程调用时不会引用任何共享数据。\n可重入函数不需要进行同步操作，因此通常比不可重入函数更高效。将第二类线程不安全函数重写为可重入函数是使其线程安全的唯一方法。我们可以将上节提到的函数rand修改为：\n1 2 3 4 5 6 /* rand_r - a reentrant pseudo-random integer on 0..32767 */ int rand_r(unsigned int *nextp) { *nextp = *nextp * 1103515245 + 12345; return (unsigned int)(*nextp / 65536) % 32768; } 其关键思想在于，rand_r使用被调用者传入的指针nextp代替了静态变量next_seed。\n如果函数的所有参数都按值传递且所有的数据引用都指向局部自动变量，那么我们就称该函数是显式可重入的。无论该函数被调用的方式如何，其可重入性都不变；如果函数的某些参数通过引用（指针）传递且调用者线程小心地将非共享数据传递给指针，那么我们就称该函数是隐式可重入的，函数rand_r便是如此。\n竞争 当多个线程的执行顺序会影响程序的正确性时就会发生竞争，如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 #include \"csapp.h\" #define N 4 void *thread(void *vargp); int main() { pthread_t tid[N]; int i; for (i = 0; i \u003c N; i++) Pthread_create(\u0026tid[i], NULL, thread, \u0026i); for (i = 0; i \u003c N; i++) Pthread_join(tid[i], NULL); exit(0); } /* thread routine */ void *thread(void *vargp) { int myid = *((int *)vargp); printf(\"Hello from thread %d\\n\", myid); return NULL; } 示例程序中，主线程创建了四个对等线程并将指向了唯一整数 ID 的指针\u0026i传递给它们。对等线程将参数传递的 ID 复制到局部变量（第 21 行），然后打印包含 ID 的消息。该程序看似简单，然而却输出了错误的结果：\n1 2 3 4 5 linux\u003e ./race Hello from thread 1 Hello from thread 3 Hello from thread 2 Hello from thread 3 出现这一问题的原因在于，主线程循环中变量i的自增（第 12 行）与对等线程中对参数的解引用和赋值（第 21 行）之间产生了竞争。如果对等线程在主线程变量i自增之后才执行第 22 行的代码，那么变量myid就变成了其他线程的 ID。\n为了消除竞争，我们需要为每个 ID 动态分配一个堆内存 Block，并向线程传递指向该 Block 的指针。实际上，前文介绍的 基于线程的并发服务器 便使用了这一方法。\n另一种方法是主线程直接向对等线程传递i而非其指针：\n1 2 for (i = 0; i \u003c N; i++) Pthread_create(\u0026tid[i], NULL, thread, (void *) i); 对等线程则将参数转换回int类型并赋给变量myid：\n1 int myid = (int)vargp; 相比于第一种方法，这种方法的好处是减少了调用malloc和free带来的开销。但在类型转换中，它假设指针至少与整型一样大，可能不适用于某些操作系统。\n死锁 信号量的引入可能会导致线程被永远阻塞，我们将这种运行时错误称为死锁（Deadlock）。进度图是理解死锁的重要工具：\n上图中的两个线程使用信号量s和t实现互斥，但程序员错误地对P和V操作排序。一旦某个轨迹进入了死锁状态d，两信号量重叠的禁止区域便阻止了它所有的可行路线。换言之，由于每个阻塞线程等待的V操作永远不会被执行，程序发生死锁。\n死锁是一个非常棘手的问题，因为它难以预测。程序可能正确地运行了上千次，但下一次便会出现死锁。更糟糕的是，并发程序每次执行的轨迹都有所不同，因此死锁还难以复现。\n对于二进制信号量，我们可以使用互斥锁排序规则来防止死锁：若每个线程以相同的顺序加锁（如上图中两线程均先执行P(s)，再执行P(t)），则程序无死锁。解锁的顺序并不重要，因为V操作不会阻塞线程。\n","description":"","tags":["OS","Concurrent"],"title":"CSAPP 读书笔记：并发编程","uri":"/posts/concurrent-programming-note/"},{"content":"所有的网络应用程序都基于相同的基本编程模型，具有相似的整体逻辑结构，并且依赖于相同的编程接口。\n客户端-服务器编程模型 每个网络应用程序都基于客户端-服务器模型（Client-Server Model），并由一个服务器进程和多个客户端进程组成。服务器管理资源，操作它们以向客户端提供服务。\n客户端-服务器模型中的基本操作是事务（Transaction），它由以下四个步骤组成：\n请注意，这里的客户端和服务器指的是进程而非机器或主机（Host）。单台主机能够同时运行多个不同的客户端和服务器，客户端和服务器事务也可以在相同或不同的主机上执行。\n网络 不过，客户端和服务器通常在不同的主机上运行，两者使用计算机网络的软硬件资源进行通信。对于主机来说，网络只是一种 I/O 设备。如下图所示，主机使用 DMA 技术将网络数据通过 I/O 总线和存储器总线从适配器复制到主存（反之亦然）：\n网络是按地理邻近度组织的分层系统，其最低层是覆盖一个建筑物或校园的局域网（Local Area Network，LAN）。迄今为止最流行的局域网技术是以太网（Ethernet）：\n在更高层，多个互不连通的局域网可以通过路由器连接为互联网（Interconnected Network，Internet），而多个路由器点对点连接便形成了广域网（Wide Area Network，WAN）：\n互联网可以由使用完全不同且不兼容技术的局域网和广域网组成，这是它的一个关键特性。因此，我们必须在每台主机和路由器上运行协议软件（Protocol Software）来消除不同网络之间的差异。该软件实现的协议将管理主机和路由器如何协作以传输数据，它必须提供两个基本功能：\n命名方案（Naming Scheme）：为主机地址定义统一的格式，并为每台主机分配至少一个唯一标识它的互联网地址； 交付机制（Delivery Mechanism）：定义一种统一的方式将数据位封装为若干个块，即数据包（Packet）。其大小和源/目的主机地址位于包的头部（Header），而源主机发送的数据位则在有效负载（Payload）之中。 全球 IP 互联网 几乎所有的现代计算机系统都支持 TCP/IP 协议（Transmission Control Protocol/Internet Protocol），因此每台互联网主机上均运行着实现了该协议的软件。客户端和服务器使用 Socket 接口函数和 Unix I/O 函数混合的方式进行通信。前者通常为系统调用，它们会请求内核（Trap into Kernel）调用 TCP/IP 中的各种内核态函数。\n在程序员看来，互联网是具有以下属性的主机集合：\n所有主机均映射到一组 32 位的 IP 地址； 所有 IP 地址均映射到一组标识符，即域名（Domain Name）； 一台主机上的进程可以通过连接（Connection）与其他任何主机上的进程通信。 IP 地址 IP 地址是一个无符号的 32 位整数。由于历史原因，网络程序将其存储在如下结构体中：\n1 2 3 4 /* IP address structure */ struct in_addr { uint32_t s_addr; /* Address in network byte order (big-endian) */ }; 互联网中主机存储字节的顺序可能不同，因此 TCP/IP 必须为整型数据项（如数据包头部的 IP 地址）定义一个统一的网络字节顺序（大端）。即使主机的字节顺序是小端，in_addr结构体中的 IP 地址也会以网络字节顺序存储。Unix 提供了用于转换字节顺序的函数：\n1 2 3 4 5 6 7 8 9 10 #include \u003carpa/inet.h\u003e // host to network uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); // Returns: value in network byte order // network to host uint32_t ntohl(uint32_t netlong); uint16_t ntohs(unit16_t netshort); // Returns: value in host byte order 为了便于人类阅读，IP 地址通常以点分十进制（Dotted-Decimal）的形式表示。应用程序可以使用函数inet_pton和inet_ntop对上述两种方式进行转换：\n1 2 3 4 5 6 7 #include \u003carpa/inet.h\u003e int inet_pton(AF_INET, const char *src, void *dst); // Returns: 1 if OK, 0 if src is invalid dotted decimal, −1 on error const char *inet_ntop(AF_INET, const void *src, char *dst, socklen_t size); // Returns: pointer to a dotted-decimal string if OK, NULL on error 域名 像 IP 地址这样较大的整数很难让人记住，因此互联网定义了一组更加人性化的域名集合并将其与 IP 地址映射。域名是由句点分隔的单词（字母、数字和破折号）序列，如whaleshark.ics.cs.cmu.edu。域名的层级结构如下图所示：\n连接 客户端和服务器通过连接来收发字节流并进行通信。连接是点对点，全双工（数据可以同时在两个方向上传输）且可靠的——除非发生一些灾难性的故障。\nSocket 是连接的端点，每个 Socket 都对应了一个 Socket 地址。该地址由 IP 地址和 16 位整型的端口（Port）组成，表示为：address:port。\n客户端 Socket 地址中的端口通常是其发起连接请求时由内核自动分配的，被称为临时端口（Ephemeral Port）；而服务器 Socket 地址中的端口则通常与服务永久关联，被称为知名端口（Well-known Port）。\n连接由两个端点的 Socket 地址（即 Socket Pair）唯一标识，可以用元组表示为：(cliaddr:cliport, servaddr:servport)。\nSocket 接口 上文提到，Socket 接口是一组函数，它们与 Unix I/O 函数一同用于构建网络应用程序：\nSocket 地址结构体 从 Linux 内核的角度来看，Socket 是连接的一个端点；而从 Linux 程序的角度来看，Socket 则是一个与描述符对应的打开文件。IPv4 Socket 地址存储在 sockaddr_in类型的 16 字节结构体中：\n1 2 3 4 5 6 7 /* IP socket address structure */ struct sockaddr_in { uint16_t sin_family; /* Protocol family (always AF_INET) */ uint16_t sin_port; /* Port number in network byte order */ struct in_addr sin_addr; /* IP address in network byte order */ unsigned char sin_zero[8]; /* Pad to sizeof(struct sockaddr) */ }; sin_family字段为AF_INET，sin_port字段为 16 位端口号，sin_addr字段中包含 32 位 IP 地址。IP 地址和端口号始终以网络字节顺序（大端）存储。\n在调用函数connect、bind和accept时，我们需要传入一个指向 Socket 地址结构体的指针。由于 Socket 有多种类型，不同协议的 Socket 地址结构体类型也有所不同。如 IPv6 Socket 地址存储在sockaddr_in6类型的结构体中，sin_family字段为AF_INET6；Unix Domain Socket 地址存储在sockaddr_un类型的结构体中，sin_family字段为AF_UNIX。然而在 Socket 接口设计者所处的时代，C 还并不支持使用void *指针。于是他们只好重新定义一个适用于所有协议的sockaddr结构体，然后要求应用程序将任何与协议有关的结构体指针转换为这种通用的结构体指针：\n1 2 3 4 5 /* Generic socket address structure (for connect, bind, and accept) */ struct sockaddr { uint16_t sa_family; /* Protocol family */ char sa_data[14]; /* Address data */ }; socket函数 客户端和服务器使用socket函数创建一个 Socket 文件描述符：\n1 2 3 4 #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e int socket(int domain, int type, int protocol); // Returns: nonnegative descriptor if OK, −1 on erro 如果我们希望 Socket 成为连接的端点，那么可以使用以下参数调用该函数：\n1 clientfd = Socket(AF_INET, SOCK_STREAM, 0); 其中，AF_INET代表使用 32 位 IP 地址，SOCK_STREAM表示 Socket 将成为连接的端点。该函数返回的描述符clientfd只是部分打开，还不能进行读写。\nconnect函数 客户端调用connect函数与服务器建立连接：\n1 2 3 4 #include \u003csys/socket.h\u003e int connect(int clientfd, const struct sockaddr *addr, socklen_t addrlen); //Returns: 0 if OK, −1 on error 该函数尝试连接 Socket 地址为addr的服务器，参数addrlen是结构体sockaddr_in的大小。connect函数在连接建立或发生错误前会一直阻塞，若建立成功则 Socket 描述符clientfd便可进行读写。\nbind函数 bind函数请求内核将参数addr中的服务器 Socket 地址与 Socket 描述符sockfd相关联，参数addrlen是结构体sockaddr_in的大小：\n1 2 3 4 #include \u003csys/socket.h\u003e int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); // Returns: 0 if OK, −1 on error listen函数 默认情况下，内核假定socket函数创建的描述符是用于客户端连接的。因此服务器需要调用listen函数告诉内核参数sockfd用于服务器而非客户端：\n1 2 3 #include \u003csys/socket.h\u003e int listen(int sockfd, int backlog); // Returns: 0 if OK, −1 on error 参数backlog是内核开始拒绝请求前应当排队的未完成连接请求数，通常设为 1024。\naccept函数 服务器调用accept函数等待客户端的连接请求到达监听描述符listenfd，然后将客户端 Socket 地址写入到addr中，最后返回一个可使用 Unix I/O 函数与客户端通信的连接描述符：\n1 2 3 #include \u003csys/socket.h\u003e int accept(int listenfd, struct sockaddr *addr, int *addrlen); // Returns: nonnegative connected descriptor if OK, −1 on error 监听描述符作为客户端发起连接请求的端点，通常只会创建一次，在服务器的生命周期内存在；连接描述符是客户端与服务器之间已建立的连接的端点，在每次服务器接受连接请求时创建，并且仅在服务器为客户端提供服务时存在：\n在连接建立之后，客户端和服务器可以分别通过读写clientfd和connfd来传输数据。\n主机和服务转换 我们可以将getaddrinfo和getnameinfo函数与 Socket 接口函数结合，编写适用于任何版本 IP 协议的网络程序。\ngetaddrinfo函数 getaddrinfo函数将主机名（或主机地址）和服务名（或端口号）转换为 Socket 地址结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 #include \u003csys/types.h\u003e #include \u003csys/socket.h\u003e #include \u003cnetdb.h\u003e struct addrinfo { int ai_flags; /* Hints argument flags */ int ai_family; /* First arg to socket function */ int ai_socktype; /* Second arg to socket function */ char ai_protocol; /* Third arg to socket function */ char *ai_canonname; /* Canonical hostname */ size_t ai_addrlen; /* Size of ai_addr struct */ struct sockaddr *ai_addr; /* Ptr to socket address structure */ struct addrinfo *ai_next; /* Ptr to next item in linked list */ } int getaddrinfo(const char *host, const char *service, const struct addrinfo *hints, struct addrinfo **result); // Returns: 0 if OK, nonzero error code on error 该函数会根据hints指定的规范分配并初始化一个addrinfo结构体链表，其中每个结构体的ai_addr字段都指向一个与host和service对应的 Socket 地址，result指向链表头部：\n参数host可以是域名，也可以是数字地址（如点分十进制 IP 地址）；参数service可以是服务名称（如 http），也可以是十进制端口号。如果我们不需要 Socket 地址中的主机名，就可以将host设为NULL。对于服务名来说也是如此，不过两者不能同时为NULL。\n客户端在调用该函数后会遍历上述链表，依次使用每个 Socket 地址作为参数调用socket和connect直至成功并建立连接；服务器在调用该函数后会遍历上述链表，依次使用每个 Socket 地址作为参数调用socket和bind直至成功且描述符被绑定到一个有效的 Socket 地址。\n细心的读者可能会疑惑为什么getaddrinfo会为同一个host和service初始化多个addrinfo结构体，这是因为：主机可能是多宿主的（Multihomed），可以通过多种协议（如 IPv4 和 IPv6）访问；客户端可以通过不同的 Socket 类型（如SOCK_STREAM和SOCK_DGRAM）访问相同的服务。因此通常我们会根据需求设置hints参数，以使函数生成我们期望的 Socket 地址。\n当hints作为参数传递时，只有ai_family、ai_socktype、ai_protocol和ai_flags字段可以被设置，其他字段必须为 0 或NULL。在实际使用中，我们调用 memset 函数将hints归零，然后设置以下字段：\nai_family为AF_INET时，该函数将生成 IPv4 Socket 地址；ai_family为AF_INET6时，该函数将生成 IPv6 Socket 地址； 对于面向连接的网络应用程序，ai_socktype应当设为SOCK_STREAM； ai_flags是能够修改函数默认行为的位掩码，主要包括： AI_ADDRCONFIG：仅当本地主机使用 IPv4 时生成 IPv4 Socket 地址； AI_CANONNAME：默认情况下，addrinfo结构体内的ai_canonname字段为NULL。若设置该掩码，函数会将链表中第一个addrinfo结构体内的ai_canonname字段指向主机的规范（官方）名称（如上图所示）； AI_NUMERICSERV：强制参数service使用端口号； AI_PASSIVE：服务器可以使用该函数生成的 Socket 地址创建监听描述符。在这种情况下，参数host应当设为NULL，表示服务器的所有 IP 地址均可用于连接（即INADDR_ANY或 0.0.0.0）； 当getaddrinfo初始化addrinfo结构体链表时，它会填充除ai_flags之外的所有字段。ai_family、ai_socktype和ai_protocol可以直接传递给socket函数，ai_addr和ai_addrlen可以直接传递给connect和bind函数。因此我们能够使用它编写适用于任何版本 IP 协议的客户端和服务器。\n为了避免内存泄漏，应用程序最终必须调用freeaddrinfo函数释放链表：\n1 2 void freeaddrinfo(struct addrinfo *result); // Returns: nothing getaddrinfo函数会返回非零错误码，应用程序可以调用gai_strerror函数将其转换为消息字符串：\n1 2 const char *gai_strerror(int errcode); // Returns: error message getnameinfo函数 getnameinfo函数是getaddrinfo的逆函数，它将 Socket 地址结构体转换为对应的主机名和服务名：\n1 2 3 4 5 6 #include \u003csys/socket.h\u003e #include \u003cnetdb.h\u003e int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, size_t hostlen, char *service, size_t servlen, int flags); // Returns: 0 if OK, nonzero error code on error 参数sa指向一个大小为salen字节的 Socket 地址结构体，host指向一个大小为hostlen字节的缓冲区，而service则指向一个大小为servlen字节的缓冲区。该函数将sa转换为主机名和服务名字符串，然后将它们复制到host和service指向的缓冲区。如果该函数返回非零错误代码，应用程序可以调用gai_strerror将其转换为消息字符串。\n如果我们不需要主机名，就可以将host设为NULL。对于服务名来说也是如此，不过两者不能同时为NULL。\n参数flags是修改函数默认行为的位掩码，包括：\nNI_NUMERICHOST：默认情况下，函数将在host指向的缓冲区中生成一个域名。若设置该掩码，函数会生成一个数字地址字符串； NI_NUMERICSERV：默认情况下，函数将在/etc/services文件中查找并生成服务名。若设置该掩码，函数会跳过查找并生成端口号。 如下示例程序使用getaddrinfo和getnameinfo函数实现域名解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #include \"csapp.h\" int main(int argc, char **argv) { struct addrinfo *p, *listp, hints; char buf[MAXLINE]; int rc, flags; if (argc != 2) { fprintf(stderr, \"usage: %s \u003cdomain name\u003e\\n\", argv[0]); exit(0); } /* Get a list of addrinfo records */ memset(\u0026hints, 0, sizeof(struct addrinfo)); hints.ai_family = AF_INET; /* IPv4 only */ hints.ai_socktype = SOCK_STREAM; /* Connections only */ if ((rc = getaddrinfo(argv[1], NULL, \u0026hints, \u0026listp)) != 0) { fprintf(stderr, \"getaddrinfo error: %s\\n\", gai_strerror(rc)); exit(1); } /* Walk the list and display each IP address */ flags = NI_NUMERICHOST; /* Display address string instead of domain name */ for (p = listp; p; p = p-\u003eai_next) { getnameinfo(p-\u003eai_addr, p-\u003eai_addrlen, buf, MAXLINE, NULL, 0, flags); printf(\"%s\\n\", buf); } /* Clean up */ freeaddrinfo(listp); exit(0); } Socket 接口的辅助函数 getaddrinfo和 Socket 接口函数并不易于使用，我们可以使用更高级的辅助函数open_clientfd和open_listenfd包装它们。\nopen_clientfd函数 客户端调用open_clientfd函数与服务器建立连接：\n1 2 3 #include \"csapp.h\" int open_clientfd(char *hostname, char *port); // Returns: descriptor if OK, −1 on error 参数hostname是服务器所在的主机名，参数port是服务器监听的端口号。函数返回一个打开的 Socket 描述符，客户端可以使用 Unix I/O 函数对其读写。该函数的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 int open_clientfd(char *hostname, char *port) { int clientfd; struct addrinfo hints, *listp, *p; /* Get a list of potential server addresses */ memset(\u0026hints, 0, sizeof(struct addrinfo)); hints.ai_socktype = SOCK_STREAM; /* Open a connection */ hints.ai_flags = AI_NUMERICSERV; /* ... using a numeric port arg. */ hints.ai_flags |= AI_ADDRCONFIG; /* Recommended for connections */ getaddrinfo(hostname, port, \u0026hints, \u0026listp); /* Walk the list for one that we can successfully connect to */ for (p = listp; p; p = p-\u003eai_next) { /* Create a socket descriptor */ if ((clientfd = socket(p-\u003eai_family, p-\u003eai_socktype, p-\u003eai_protocol)) \u003c 0) continue; /* Socket failed, try the next */ /* Connect to the server */ if (connect(clientfd, p-\u003eai_addr, p-\u003eai_addrlen) != -1) break; /* Success */ Close(clientfd); /* Connect failed, try another */ } /* Clean up */ freeaddrinfo(listp); if (!p) /* All connects failed */ return -1; else /* The last connect succeeded */ return clientfd; } open_clientfd中不存在任何依赖于特定版本协议的代码，调用socket和connect时使用的参数是由getaddrinfo自动生成的，因此该函数干净且可移植。\nopen_listenfd函数 服务器调用open_listenfd函数创建一个能够接受连接请求的监听描述符：\n1 2 3 #include \"csapp.h\" int open_listenfd(char *port); // Returns: descriptor if OK, −1 on error 参数port是服务器监听的端口号。该函数的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 int open_listenfd(char *port) { struct addrinfo hints, *listp, *p; int listenfd, optval = 1; /* Get a list of potential server addresses */ memset(\u0026hints, 0, sizeof(struct addrinfo)); hints.ai_socktype = SOCK_STREAM; /* Accept connections */ hints.ai_flags = AI_PASSIVE | AI_ADDRCONFIG; /* ... on any IP address */ hints.ai_flags |= AI_NUMERICSERV; /* ... using port number */ getaddrinfo(NULL, port, \u0026hints, \u0026listp); /* Walk the list for one that we can bind to */ for (p = listp; p; p = p-\u003eai_next) { /* Create a socket descriptor */ if ((listenfd = socket(p-\u003eai_family, p-\u003eai_socktype, p-\u003eai_protocol)) \u003c 0) continue; /* Socket failed, try the next */ /* Eliminates \"Address already in use\" error from bind */ Setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, (const void *)\u0026optval, sizeof(int)); /* Bind the descriptor to the address */ if (bind(listenfd, p-\u003eai_addr, p-\u003eai_addrlen) == 0) break; /* Success */ Close(listenfd); /* Bind failed, try the next */ } /* Clean up */ freeaddrinfo(listp); if (!p) /* No address worked */ return -1; /* Make it a listening socket ready to accept connection requests */ if (listen(listenfd, LISTENQ) \u003c 0) { Close(listenfd); return -1; } return listenfd; } 在第 20 行中我们使用Setsockopt函数（见 csapp.c）配置服务器，使其能够在重新启动后立即开始接受连接请求。默认情况下，重新启动的服务器会在大约 30 秒内拒绝来自客户端的连接，这将严重影响调试。\n示例 Echo 客户端和服务器 学习 Socket 接口函数的最佳方法便是阅读示例代码。一个简单的客户端程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 #include \"csapp.h\" int main(int argc, char **argv) { int clientfd; char *host, *port, buf[MAXLINE]; rio_t rio; if (argc != 3) { fprintf(stderr, \"usage: %s \u003chost\u003e \u003cport\u003e\\n\", argv[0]); exit(0); } host = argv[1]; port = argv[2]; clientfd = Open_clientfd(host, port); Rio_readinitb(\u0026rio, clientfd); while (Fgets(buf, MAXLINE, stdin) != NULL) { Rio_writen(clientfd, buf, strlen(buf)); Rio_readlineb(\u0026rio, buf, MAXLINE); Fputs(buf, stdout); } Close(clientfd); exit(0); } 在与服务器建立连接之后，客户端进入 While 循环。它不断从标准输入中读取文本行（Fgets），然后将文本行发送到服务器（Rio_writen）。接下来再读取服务器的返回（Rio_readlineb），最终将结果打印到标准输出（Fputs）。当用户键入 Ctrl+D 时，循环中止，客户端随后关闭描述符clientfd。\n该客户端连接的服务器代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \"csapp.h\" typedef struct sockaddr SA; void echo(int connfd) { size_t n; char buf[MAXLINE]; rio_t rio; Rio_readinitb(\u0026rio, connfd); while ((n = Rio_readlineb(\u0026rio, buf, MAXLINE)) != 0) { printf(\"server received %d bytes\\n\", (int)n); Rio_writen(connfd, buf, n); } } int main(int argc, char **argv) { int listenfd, connfd; socklen_t clientlen; struct sockaddr_storage clientaddr; /* Enough space for any address */ char client_hostname[MAXLINE], client_port[MAXLINE]; if (argc != 2) { fprintf(stderr, \"usage: %s \u003cport\u003e\\n\", argv[0]); exit(0); } listenfd = Open_listenfd(argv[1]); while (1) { clientlen = sizeof(struct sockaddr_storage); connfd = accept(listenfd, (SA *)\u0026clientaddr, \u0026clientlen); getnameinfo((SA *)\u0026clientaddr, clientlen, client_hostname, MAXLINE, client_port, MAXLINE, 0); printf(\"Connected to (%s, %s)\\n\", client_hostname, client_port); echo(connfd); Close(connfd); } exit(0); } 代码第 23 行声明的变量clientaddr是一个sockaddr_storage类型的 Socket 地址结构体，accept函数会在返回前将客户端的 Socket 地址填入其中。我们使用sockaddr_storage而非sockaddr_in的原因在于前者足够大，可以保存任何类型的 Socket 地址，从而使代码与协议独立（详见：Reasoning behind C sockets sockaddr and sockaddr_storage）。\n服务器打开监听描述符后进入无限循环。它等待来自客户端的连接请求，打印客户端的主机名和端口，然后调用echo函数。该函数重复读取并写入文本行，直到Rio_readlineb遇到 EOF（对于网络连接，当一端的进程关闭连接，另一端的进程尝试读取流中的最后一个字节时将检测到 EOF）。一旦客户端和服务器均关闭了各自的描述符，连接便会终止。\n请注意，示例的简单服务器一次只能处理一个客户端的连接请求，我们称这种类型的服务器为迭代服务器（Iterative Server）。更加复杂的并发服务器（Concurrent Server）则可以同时处理多个客户端的连接请求。\nWeb 服务器 Web 内容 对于 Web 客户端和服务器，内容（Content）是与某种 MIME（Multipurpose Internet Mail Extensions）类型关联的字节序列：\nWeb 服务器通过两种不同方式向客户端提供内容：\n获取磁盘文件（静态内容）并将其返回给客户端； 运行一个可执行文件并将其输出结果（动态内容）返回给客户端。 Web 服务器返回的每条内容都与其管理的某个文件相关联，每个文件都有一个唯一的名称，即 URL（Universal Resource Locator）。\nHTTP 事务 我们可以使用telnet命令与互联网上任意 Web 服务器建立事务：\n","description":"","tags":["Network"],"title":"CSAPP 读书笔记：网络编程","uri":"/posts/network-programming-note/"},{"content":"输入/输出 (I/O) 是在主存储器和外部设备（如磁盘驱动、终端和网络等）之间复制数据的过程。输入操作将数据从 I/O 设备复制到主存，输出操作则将数据从主存复制到设备。\nUnix I/O Linux 文件是由 m 个字节组成的序列：\n$$B_0, B_1, …, B_k, …, B_{m-1}$$\n所有的 I/O 设备均被建模为文件，输入和输出是通过读写对应的文件来完成的。Linux 内核基于这种设备与文件之间的优雅映射为我们提供了一个简单而低级的应用程序接口，即 Unix I/O，它使得所有的输入和输出都能以一致的方式执行：\n打开文件：应用程序通过向内核发起打开文件请求以访问 I/O 设备。内核将返回一个小的非负整数，即文件描述符（File Descriptor），它将在对文件的后续操作中标识该文件。内核跟踪与打开文件相关的所有信息，而应用程序则只跟踪描述符。每个由 Linux Shell 创建的进程都会打开三个文件：标准输入（STDIN_ FILENO，描述符 0）、标准输出（STDOUT_FILENO，描述符 1）和标准错误（STDERR_FILENO，描述符 2）； 改变当前文件位置：内核为每个打开文件维护一个文件位置（File Position）k，初始值为 0。文件位置是文件中下一个即将被读取或写入的字符到文件起始位置的字节偏移量，并非指该文件在文件系统中的位置。应用程序可以通过执行 Seek 操作来显式地设置当前文件位置 k； 读写文件：读取操作从当前文件位置 k 开始，复制 n 个字节到内存中，随后令 k 增加 n。当文件位置大于或等于文件大小时，读取操作会触发 EOF（End-of-File）。类似地，写入操作从当前文件位置 k 开始，复制 n 个字节到文件中并更新 k 的值； 关闭文件：当应用程序结束对文件的访问时，它会向内核发起关闭文件请求，内核释放打开文件时创建的数据结构并将描述符放回可用描述符池。若进程因某些原因终止，内核将关闭所有打开的文件并释放相应的内存资源。 文件 每个 Linux 文件都有一个表征其在系统中角色的类型：\n常规文件（Regular File）：对于应用程序来说，常规文件分为仅包含 ASCII 或 Unicode 字符的文本文件（Text File）和二进制文件（Binary File）；但对于内核而言，两者没有区别。Linux 文本文件由一系列文本行（Text Line）组成，其中每一行都以换行符\\n结尾； 目录（Directory）：目录是由链接（Link）数组构成的文件。链接将一个文件名映射到一个文件，该文件可能是另一个目录（如下图所示）。每个目录中至少包含两个链接：.指向目录本身，而..指向上级目录； Socket：用于通过网络与另一个进程通信的文件。 打开和关闭文件 进程可以调用函数open来打开一个已存在的文件或创建一个新文件：\n1 2 3 4 5 #include \u003csys/types.h\u003e #include \u003csys/stat.h\u003e #include \u003cfcntl.h\u003e int open(char *filename, int flags, mode_t mode); // Returns: new file descriptor if OK, −1 on error 返回的文件描述符是进程当前未打开的最小描述符。参数flags指示进程如何访问文件：\nO_RDONLY：只读 O_WRONLY：只写 O_RDWR：读写 该参数还可以与一个或多个位掩码进行或（OR）运算，这些位掩码提供写入的附加说明：\nO_CREAT：如果文件不存在，则创建一个空文件； O_TRUNC：如果文件已经存在，则清空文件内容； O_APPEND：在每次写入操作之前，将文件位置设置为文件末尾。 若文件已存在，参数mode应设为 0；反之，则设为新文件的访问权限位，可选项如下图所示：\n作为进程上下文的一部分，每个进程都有一个通过umask函数设置的umask掩码。当进程调用open函数创建新文件时，文件的访问权限位会被设置为mode \u0026 ~umask。如下示例程序将创建一个所有者拥有读写权限、其他用户都有读取权限的新文件：\n1 2 3 4 5 #define DEF_MODE S_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP|S_IROTH|S_IWOTH #define DEF_UMASK S_IWGRP|S_IWOTH umask(DEF_UMASK); fd = Open(\"foo.txt\", O_CREAT|O_TRUNC|O_WRONLY, DEF_MODE); 进程调用close函数来关闭一个打开的文件，若文件描述符已关闭将引发错误：\n1 2 3 #include \u003cunistd.h\u003e int close(int fd); // Returns: 0 if OK, −1 on error 读写文件 应用程序调用read和write函数来执行输入和输出：\n1 2 3 4 5 #include \u003cunistd.h\u003e ssize_t read(int fd, void *buf, size_t n); // Returns: number of bytes read if OK, 0 on EOF, −1 on error ssize_t write(int fd, const void *buf, size_t n); // Returns: number of bytes written if OK, −1 on error read函数从参数fd的当前文件位置复制最多n个字节到内存中buf指向的位置，write函数则从内存中buf指向的位置复制最多n个字节到参数fd的当前位置。示例程序使用上述两种函数将标准输入以字节为单位复制到标准输出：\n1 2 3 4 5 6 7 8 9 #include \"csapp.h\" int main(void) { char c; while(Read(STDIN_FILENO, \u0026c, 1) != 0) Write(STDOUT_FILENO, \u0026c, 1); exit(0); } 在某些情况下，读写操作传输的字节数小于应用程序请求的字节数。不足数（Short Count）的产生并不代表发生了错误，它可能由多种原因导致：\n读取时遇到 EOF：若我们对一个 20 字节的文件执行read(fd, *buf, 50)，那么第一次调用将返回一个 20 的不足数，第二次调用则返回 0（EOF）； 从终端读取文本行：若打开的文件是终端设备（即键盘和显示器），那么每次read调用都将传输一个文本行并返回一个与文本行大小相等的不足数； 读写 Socket：若打开的文件是 Socket，那么内部缓冲区限制和网络延迟将使读写操作返回不足数。 因此除遇到 EOF 外，读写磁盘文件不会导致不足数的产生。但如果我们想要构建健壮而可靠的网络应用程序，就必须重复调用read和write以保证所有请求的字节均已被传输。\n使用 $R_{IO}$ 包实现健壮读写 $R_{IO}$ 包为应用程序提供了方便、健壮且高效的 I/O，可以解决编写网络程序时遇到的不足数问题：\n无缓冲的输入/输入函数：直接在内存和文件之间传输数据，适用于从网络中读写二进制数据； 有缓冲的输入函数：从应用程序级别的缓冲区中读取文本行和二进制数据，与标准 I/O（如printf）函数类似。该函数是线程安全（Thread-safe）的，并且可以对同一描述符任意交错（Interleave）。例如，我们可以从描述符中读取一些文本行，然后读取一些二进制数据，最后再读取一些文本行。 无缓冲的输入/输入函数 1 2 3 4 #include \"csapp.h\" ssize_t rio_readn(int fd, void *usrbuf, size_t n); ssize_t rio_writen(int fd, void *usrbuf, size_t n); // Returns: number of bytes transferred if OK, 0 on EOF (rio_readn only), −1 on error rio_readn函数从参数fd的当前文件位置复制最多n个字节到内存中usrbuf指向的位置，rio_writen函数则从内存中usrbuf指向的位置复制最多n个字节到参数fd的当前位置。前者只有在遇到 EOF 时返回不足数，后者则从不返回不足数。\n若上述函数被应用程序的信号处理程序的返回中断，它们会重新调用read和write函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 ssize_t rio_readn(int fd, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nread; char *bufp = usrbuf; while (nleft \u003e 0) { if ((nread = read(fd, bufp, nleft)) \u003c 0) { if (errno == EINTR) /* Interrupted by sig handler return */ nread = 0; /* and call read() again */ else return -1; /* errno set by read() */ } else if (nread == 0) break; /* EOF */ nleft -= nread; bufp += nread; } return (n - nleft); /* Return \u003e= 0 */ } ssize_t rio_writen(int fd, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nwritten; char *bufp = usrbuf; while (nleft \u003e 0) { if ((nwritten = read(fd, bufp, nleft)) \u003c 0) { if (errno == EINTR) /* Interrupted by sig handler return */ nwritten = 0; /* and call write() again */ else return -1; /* errno set by write() */ } nleft -= nwritten; bufp += nwritten; } return n; } 有缓冲的输入函数 假设我们需要编写一个计算文本文件行数的程序，最简单的方法便是调用read函数每次读取一个字节并检查是否有换行符。但由于read是系统调用，频繁的上下文切换将导致程序效率低下。\n更好的方法是调用包装函数rio_readlineb从内部读取缓冲区（Read Buffer）复制文本行，只有当缓冲区为空时才调用read以重新填充缓冲区。$R_{IO}$ 包还为同时包含文本行和二进制数据的文件（如 HTTP 响应）提供了rio_readn函数的有缓冲版本，即rio_readnb：\n1 2 3 4 #include \"csapp.h\" ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen); ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n); // Returns: number of bytes read if OK, 0 on EOF, −1 on error 在调用上述两种有缓冲的输入函数前，我们需要为每个打开文件描述符调用一次rio_readinitb。该函数将描述符fd与地址rp处的读取缓冲区（类型为rio_t）相关联：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #define RIO_BUFSIZE 8192 typedef struct { int rio_fd; /* Descriptor for this internal buf */ int rio_cnt; /* Unread bytes in internal buf */ char *rio_bufptr; /* Next unread byte in internal buf */ char rio_buf[RIO_BUFSIZE]; /* Internal buffer */ } rio_t; void rio_readinitb(rio_t *rp, int fd) { rp-\u003erio_fd = fd; rp-\u003erio_cnt = 0; rp-\u003erio_bufptr = rp-\u003erio_buf; } $R_{IO}$ 包读取例程的核心是rio_read函数，它其实是read函数的有缓冲版本。若读取缓冲区中的未读字节数rp-\u003erio_cnt为 0，则在循环内调用read函数对其填充；若读取缓冲区非空，则调用memcpy函数将min(n, rp-\u003erio_cnt)字节从缓冲区复制到usrbuf指向的内存位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 static ssize_t rio_read(rio_t *rp, char *usrbuf, size_t n) { int cnt; while (rp-\u003erio_cnt \u003c= 0) { /* Refill if buf is empty */ rp-\u003erio_cnt = read(rp-\u003erio_fd, rp-\u003erio_buf, sizeof(rp-\u003erio_buf)); if (rp-\u003erio_cnt \u003c 0) { if (errno != EINTR) /* Interrupted by sig handler return */ return -1; } else if (rp-\u003erio_cnt == 0) /* EOF */ return 0; else rp-\u003erio_bufptr = rp-\u003erio_buf; /* Reset buffer ptr */ } /* Copy min(n, rp-\u003erio_cnt) bytes from internal buf to user buf */ cnt = n; if (rp-\u003erio_cnt \u003c n) cnt = rp-\u003erio_cnt; memcpy(usrbuf, rp-\u003erio_bufptr, cnt); rp-\u003erio_bufptr += cnt; rp-\u003erio_cnt -= cnt; return cnt; } 在应用程序看来，rio_read函数与read函数具有相同的语义：执行发生错误时，它返回 -1 并设置 errno；执行遇到 EOF 时，它返回 0；当请求的字节数大于读取缓冲区中的未读字节数时，它返回一个不足数。因此我们可以通过将read替换为rio_read来构建不同类型的有缓冲读取函数。\n实际上，rio_readnb与rio_readn具有完全相同的结构，只不过我们用rio_read替换了read：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ssize_t rio_readnb(rio_t *rp, void *usrbuf, size_t n) { size_t nleft = n; ssize_t nread; char *bufp = usrbuf; while (nleft \u003e 0) { if ((nread = rio_read(rp, bufp, nleft)) \u003c 0) return -1; /* errno set by read() */ else if (nread == 0) break; /* EOF */ nleft -= nread; bufp += nread; } return (n - nleft); /* return \u003e= 0 */ } 类似地，rio_readlineb函数从文件rp中读取一个文本行并将其复制到内存中usrbuf指向的位置。循环内每次对rio_read的调用都会把读取缓冲区中的一个字节复制到\u0026c，然后检查它是否是换行符：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 ssize_t rio_readlineb(rio_t *rp, void *usrbuf, size_t maxlen) { int n, rc; char c, *bufp = usrbuf; for (n = 1; n \u003c maxlen; n++) { if ((rc = rio_read(rp, \u0026c, 1)) == 1) { *bufp++ = c; /* Copy rp to user buf */ if (c == '\\n') { n++; break; } } else if (rc == 0) { if (n == 1) return 0; /* EOF, no data read */ else break; /* EOF, some data was read */ } else return -1; /* Error */ } *bufp = 0; return n - 1; } 读取文件元数据 应用程序调用stat和fstat函数获取一个文件的元数据：\n1 2 3 4 5 #include \u003cunistd.h\u003e #include \u003csys/stat.h\u003e int stat(const char *filename, struct stat *buf); int fstat(int fd, struct stat *buf); // Returns: 0 if OK, −1 on error 函数stat使用文件名*filename作为输入，将信息填写到stat结构体中。fstat与之类似，但它的参数是文件描述符fd。结构体stat如下图所示，我们只需关注字段st_mode和st_size：\nst_size包含了文件的大小，而st_mode则包含了文件的访问权限和类型。\n读取目录内容 应用程序调用opendir和readdir函数读取目录中的内容：\n1 2 3 4 5 6 7 #include \u003csys/types.h\u003e #include \u003cdirent.h\u003e DIR *opendir(const char *name); // Returns: pointer to handle if OK, NULL on error #include \u003cdirent.h\u003e struct dirent *readdir(DIR *dirp); // Returns: pointer to next directory entry if OK, NULL if no more entries or error 函数opendir以目录的路径名为参数，返回一个指向目录流（Directory Stream）的指针。流是对有序项目列表的抽象，此处指的是目录中条目的列表。函数readdir返回指向目录流中下一个条目的指针，每个条目都是一个dirent结构体：\n1 2 3 4 struct dirent { ino_t d_ino; /* inode number */ char d_name[256]; /* Filename */ }; d_name是文件名，d_ino是文件的 inode 数。当发生错误时，readdir返回NULL并设置errno。\n函数closedir关闭目录流并释放所有相关资源：\n1 2 3 #include \u003cdirent.h\u003e int closedir(DIR *dirp); // Returns: 0 on success, −1 on error 共享文件 内核使用三种数据结构来表示打开的文件：\n描述符表（Descriptor Table）：每个进程都有一个独立的描述符表，每个条目均指向打开文件表中的条目，其索引是进程打开的文件描述符； 打开文件表（Open File Table）：所有进程共享一个打开文件表，它表示了打开文件的集合。每个文件表条目由当前文件位置（下图中的“File pos”）、当前指向它的描述符表条目数量（下图中的“refcnt”）和一个指向 v-node 表条目的指针。只有当refcnt为 0 时，内核才会删除对应的文件表条目； v-node 表（V-node Table）：与打开文件表一样，v-node 表由所有进程共享。其中的每个条目都包含了stat结构体中的大部分信息，如st_mode和st_size等。v-node 与 i-node 的区别详见：Inode vs Vnode Difference。 如上图所示，描述符 1 和 4 通过不同的打开文件表条目引用不同的文件。这是最典型的情况，文件并未共享，每个描述符对应一个不同的文件。\n多个描述符也可以通过不同的打开文件表条目引用相同的文件，例如对同一文件多次调用open函数：\n描述符 1 和 4 指向不同的打开文件表条目，因此其文件位置不同。假设文件foobar.txt中包含 6 个 ASCII 字符foobar，那么如下示例程序的输出结果为f：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \"csapp.h\" int main() { int fd1, fd2; char c; fd1 = Open(\"foobar.txt\", O_RDONLY, 0); fd2 = Open(\"foobar.txt\", O_RDONLY, 0); Read(fd1, \u0026c, 1); Read(fd2, \u0026c, 1); printf(\"c = %c\\n\", c); exit(0); } 若父进程打开文件的数据结构如上图 10.12 所示，则父进程调用fork函数后情况变为：\n子进程得到父进程的描述符表副本，两者共享相同的打开文件表和文件位置，因此如下示例程序的输出结果为o：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \"csapp.h\" int main() { int fd; char c; fd = Open(\"foobar.txt\", O_RDONLY, 0); if (Fork() == 0) { Read(fd, \u0026c, 1); exit(0); } Wait(NULL); Read(fd, \u0026c, 1); printf(\"c = %c\\n\", c); exit(0); } I/O 重定向 dup2函数将描述符表条目oldfd复制到newfd并覆盖其原始内容。如果newfd已经打开，则该函数在复制oldfd之前会先关闭newfd：\n1 2 3 #include \u003cunistd.h\u003e int dup2(int oldfd, int newfd); // Returns: nonnegative descriptor if OK, −1 on error 假设某进程的打开文件数据结构如上图 10.12 所示。描述符 1（标准输出）指向文件 A（如终端），描述符 4 指向文件 B（如磁盘上的文件），文件 A 和 B 的refcnt均为 1。那么该进程调用函数dup2(4, 1)后情况变为：\n文件 A 被关闭，内核会删除其打开文件表和 v-node 表条目。两个描述符均指向文件 B，其refcnt已增加为 2。从现在开始，任何写入到标准输出的数据都会被重定向到文件 B。\n标准 I/O C 定义了一组更高级别的输入和输出函数，即标准 I/O 库，它为程序员提供了比 Unix I/O 更高级别的替代方案。libc库提供了用于打开和关闭文件（fopen和fclose）、读取和写入字节（fread和fwrite）、读取和写入字符串（fgets和fputs）以及复杂的格式化 I/O（scanf和printf）函数。\n标准 I/O 库将打开的文件建模为流。对于程序员来说，流是指向FILE类型结构体的指针。每个 ANSI C 程序都以三个打开的​​流stdin、stdout和stderr开头，分别与标准输入、标准输出和标准错误对应：\n1 2 3 4 #include \u003cstdio.h\u003e extern FILE *stdin; /* Standard input (descriptor 0) */ extern FILE *stdout; /* Standard output (descriptor 1) */ extern FILE *stderr; /* Standard error (descriptor 2) */ FILE类型的流是文件描述符和流缓冲区（Stream Buffer）的抽象。与 $R_{io}$ 读取缓冲区相同，流缓冲区可以最大限度地减少昂贵的 Linux I/O 系统调用的次数。\n我们应当使用哪种 I/O 函数？ Unix I/O、标准 I/O 和 $R_{io}$ 包函数之间的关系如下图所示：\n那么我们应当使用哪种 I/O 函数呢？以下是一些建议：\n尽可能使用标准 I/O 函数，它们是在磁盘和终端上执行 I/O 操作的最佳选择； 不要使用scanf或rio_readlineb函数读取二进制文件，它们是专门为读取文本文件设计的； 将标准 I/O 函数用于 Socket 时可能会出现一些令人讨厌的问题，因此我们应当在网络编程时使用 $R_{io}$ 包函数。 ","description":"","tags":["OS"],"title":"CSAPP 读书笔记：系统级 I/O","uri":"/posts/system-level-io-note/"},{"content":"为了更加有效地管理内存并减少错误的发生，现代系统提供了一种对主存储器的抽象，即虚拟内存（Virtual Memory，VM）。虚拟内存是硬件异常、硬件地址转换、主存储器、磁盘文件和内核软件之间的优雅交互，它为每个进程提供了一个大的、统一的和私有的地址空间。\n虚拟内存有以下三个重要功能：\n将主存储器作为磁盘的缓存，只保留主存中的活跃区域并根据需要不断地在两者之间传输数据； 为每个进程提供统一的地址空间，从而简化内存管理； 保护每个进程的地址空间不被其他进程所破坏。 物理寻址与虚拟寻址 主存中的每个字节都有一个唯一的物理地址（Physical Address，PA），CPU 使用物理地址访问内存的方式被称为物理寻址（Physical Addressing）：\n如上图所示，CPU 生成了一个有效的物理地址并通过存储器总线传递给主存储器，详见 访问主存储器。\nCPU 也可以通过虚拟地址（Virtual Address，VA）访问主存，只不过该地址在发送到主存之前需要被转换为适当的物理地址。这种寻址方式被称为虚拟寻址（Virtual Addressing）：\n地址转换（Address Translation ）需要 CPU 硬件和操作系统之间密切合作，位于 CPU 芯片上的内存管理单元（Memory Management Unit，MMU）根据 页表（Page Table) 动态地将虚拟地址转换为物理地址。页表存储在主存中，其内容由操作系统维护。\n地址空间 地址空间（Address Space）是一组有序的非负整数地址：\n$$\\lbrace0, 1, 2, . . .\\rbrace$$\n如果这些整数是连续的，我们就称其为线性地址空间（Linear Address Space）。在拥有虚拟内存的系统中，CPU 从 n 位线性地址空间中生成虚拟地址，该虚拟地址空间共有 N = $2^n$ 个地址：\n$$\\lbrace0,1,2,…,N -1\\rbrace$$\n现代系统通常支持 32 位或 64 位虚拟地址空间。同样地，系统也有一个物理地址空间：\n$$\\lbrace0,1,2,…,M -1\\rbrace$$\n与虚拟地址空间不同，M 不一定为 2 的幂。但为了简化讨论，我们假设 M = $2^m$。\n地址空间明确地将数据对象（字节）和其属性（地址）区分开来，因此每个数据对象都可以有多个独立的地址，这便是虚拟内存的基本思想。主存中的每个字节都有一个从物理地址空间中选择的物理地址，以及一个从虚拟地址空间中选择的虚拟地址。\n虚拟内存作为缓存的工具 与存储层级结构中的其他缓存一样，磁盘与主存之间以 Block 为单位传输数据。而在虚拟内存系统中，Block 被称为虚拟页面（Virtual Page，VP），其大小为 P = $2^p$。类似地，物理内存也可以被划分为多个大小为 P 的物理页面（Physical Page，PP)。\n虚拟页面有以下三种状态：\n未分配（Unallocated）：没有被进程申请使用的页面，不占用任何磁盘空间； 未缓存（Uncached）：仅加载到磁盘而未缓存到主存中的页面； 已缓存（Cached）：已缓存在主存中的页面。 DRAM 缓存 我们将 CPU 和主存之间的 L1、L2 和 L3 级缓存称为 SRAM 缓存，而将主存中用来缓存虚拟页面的缓存称为 DRAM 缓存。\n与 SRAM 缓存相比，DRAM 缓存发生缓存缺失的成本很高（需要从磁盘中加载数据），因此虚拟页面往往比较大——通常为 4 KB 到 2 MB。DRAM 缓存是 全关联型 的，这样任何一个虚拟页面都可以放在任何一个物理页面中。\nDue to the large miss penalty, DRAM caches are fully associative; that is, any virtual page can be placed in any physical page.\n页表 页表是由页表条目（Page Table Entries，PTEs）组成的数组。每个虚拟页面在页表都有一条 PTE，它在页表中的偏移量是固定的。每条 PTE 中都包含了一个表示该虚拟页面是否已缓存的有效位，以及一个 n 位的地址字段。若有效位为 1，则地址字段是缓存该页面的物理页面的起始地址；若有效位为 0 且地址字段为空，则代表该虚拟页面未分配；若有效位为 0 且地址字段非空，则地址字段是该页面在磁盘上的起始地址。\n如上图所示，系统中存在 8 个虚拟页面和 4 个物理页面：页面 1，2，4 和 7 缓存在 DRAM 中；页面 3 和 6 已分配但未缓存；页面 0 和 5 未分配。\n缺页故障 我们将访问 DRAM 缓存时发生的缓存缺失称为缺页故障（Page Fault）。若 CPU 引用上图页面 3 中的某个字，地址转换硬件会从主存中读取 PTE 3 ，然后根据其有效位判断出该页面未缓存。缺页故障异常将调用内核中的异常处理程序，选择受害者页面（Victim Page）逐出主存。\n在本例中，受害者页面为 VP 4，因此内核会先将 PTE 4 中的有效位重置为 0。如果该页面已发生更改，内核还需要将其复制回磁盘。接下来，内核把 VP 3 从磁盘复制到主存中的 PP 3，并更新 PTE 3 中的有效位。下图展示了异常处理程序返回后示例页表的状态：\n上述在磁盘和主存之间传输页面的活动被称为交换（Swapping）或者分页（Paging）。页面从磁盘传输到主存被称为换入（Swapping In 或 Paging In），反之则为换出（Swapping Out 或 Paging Out）。尽管我们可以试图预测缺页故障并在引用未缓存的页面前分页，但现代系统均在异常发生后分页，即按需分页（Demand Paging）。\n分配页面 上图展示了分配一个新的虚拟页面（如进程调用malloc）后页表的变化。操作系统先在磁盘上开辟空间，然后更新 PTE 5 使 VP 5 指向磁盘上新创建的页面。\n虚拟内存作为内存管理的工具 操作系统为每个进程都维护了一个单独的页表，因此所有进程都拥有自己的虚拟地址空间：\n如上图所示，进程 i 的页表将 VP 1 映射到 PP 2，将 VP 2 映射到 PP 7；进程 j 的页表将 VP 1 映射到 PP 7，将 VP 2 映射到 PP 10。多个虚拟页面可以映射到同一个共享物理页面。虚拟内存系统简化了链接、加载、代码和数据的共享以及应用程序的内存分配：\n简化链接：独立的虚拟地址空间允许每个进程使用相同的 内存结构，因此链接器无需考虑可执行文件的代码和数据在物理内存中的实际位置。这种统一性极大地简化了链接器的设计和实现； 简化加载：若要将目标文件的 .text 和 .data 段加载到一个新进程的地址空间中，加载器只需为它们分配虚拟页面，然后将其标记为未缓存，最后再将页表条目指向目标文件中对应的位置。实际上加载器从未将任何数据从磁盘复制到主存中，代码和数据只有在被第一次引用时才会按需分页； 简化共享：操作系统可以将不同进程中的不同虚拟页面映射到相同的物理页面，从而实现进程之间代码和数据的共享； 简化内存分配：当应用程序申请额外的内存时，操作系统会为其分配一定数量的连续虚拟页面，然后将它们映射到任意位置的物理页面。这些物理页面无需连续，并且可以在物理内存中随机分布。 虚拟内存作为内存保护的工具 我们可以在 PTE 中添加一些权限位来管理进程对页面的访问：\n如上图所示，SUP 表示是否只有在内核态运行的进程才能访问该页面，READ 和 WRITE 则分别表示页面是否可读写。例如，进程 i 在用户态中运行，那么它可以读取 VP 0，读取和写入 VP 1，但无法访问 VP 2。\n如果某条指令违反了上述权限，CPU 就会触发通用保护故障，并将控制权转移到内核中的异常处理程序。该处理程序会向问题进程发送一个 SIGSEGV 信号，Linux Shell 通常将此异常报告为分段故障（Segmentation Fault）。\n地址转换 CPU 中的页表基址寄存器（Page Table Base Register ，PTBR）指向当前页表，n 位的虚拟地址由 p 位的虚拟页面偏移量（Virtual Page Offset，VPO）和 n-p 位的虚拟页面编号（Virtual Page Number，VPN）组成。MMU 根据 VPN 的值选择对应的 PTE，如 VPN 0 选择 PTE 0，VPN 1 选择 PTE 1。由于物理页面和虚拟页面的大小相同，VPO 与物理页面偏移量（Physical Page Offset，PPO）也就相同，因此页表条目中的物理页面编号（Physical Page Number，PPN）与 VPO 共同组成了转换后的物理地址。\n上图展示了页面命中时的 CPU 硬件操作步骤：\n处理器生成一个虚拟地址 VA 并发送到 MMU； MMU 生成 PTE 地址 PTEA 并向高速缓存或主存发起请求； 高速缓存或主存将 PTE 返回给 MMU； MMU 构造物理地址 PA 并将其发送到高速缓存或主存； 高速缓存或主存将请求的数据返回给处理器。 上图展示了缺页故障时的 CPU 硬件操作步骤：\n处理器生成一个虚拟地址 VA 并发送到 MMU； MMU 生成 PTE 地址 PTEA 并向高速缓存或主存发起请求； 高速缓存或主存将 PTE 返回给 MMU； PTE 中的有效位为 0，因此 MMU 触发异常并将控制权转移给内核中的异常处理程序； 处理程序从物理内存中选取受害者页面换出。若该页面已被修改，则还要将其复制到磁盘中； 处理程序将新页面换入并更新 PTE； 处理程序返回到原来的进程，之前引发缺页故障的指令重新执行。此时进程请求的页面已缓存，因此 CPU 随后的操作与页面命中时相同。 高速缓存与虚拟内存 大部分同时使用虚拟内存和高速缓存（SRAM 缓存）的系统均采用物理寻址的方式访问高速缓存。下图展示了两者的集成方式：\n使用 TLB 加速地址转换 CPU 每次生成虚拟地址时，MMU 都必须引用 PTE 才能完成地址转换。如果 PTE 位于主存而非高速缓存中，那么地址转换的速度将大大下降。大多数系统的 MMU 中包含了一个被称为转换后备缓冲区（Translation Lookaside Buffer，TLB）的小型 PTE 缓存，其每个缓存行中都有一个由单条 PTE 组成的 Block。用于 集合选择和行匹配 的 Set Index 和 Tag 是从虚拟地址的 VPN 中提取的：\n如果 TLB 有 T = $2^t$ 个集合，则 Set Index（TLBI）由 VPN 中 t 个最低位组成，Tag（TLBT）由 VPN 中的剩余高位组成。\n上图展示了 TLB 命中时的 CPU 硬件操作步骤。由于地址转换均在 CPU 芯片上的 MMU 中执行，因此速度很快：\nCPU 生成一个虚拟地址 VA； MMU 向 TLB 发送 VPN 以请求 PTE； TLB 将 PTE 返回给 MMU； MMU 将虚拟地址转换为物理地址 PA 并发送到高速缓存或主存； 高速缓存或主存将请求的数据返回给处理器。 上图展示了 TLB 未命中时的 CPU 硬件操作步骤。MMU 必须从高速缓存或主存中获取 PTE 并将其存储在 TLB 中，这可能会覆盖现有条目。\n多级页表 在之前的讨论中，我们假设系统只使用单级页表进行地址转换。但如果地址空间有 32 位，一个页面 4 KB 并且一条 PTE 4 字节。那么即使应用程序只引用一小部分虚拟内存，我们也需要一个 4 MB 的页表常驻在内存中：\n$$n=32, P=4K=2^{12}, n(PTE)=2^{n-p}=2^{20}=1M$$\n我们可以通过对页表分级来压缩页表的大小：\n如上图所示，一级页表中有 1024 条 PTE，每条 PTE 都映射到一个包含 1024 个连续虚拟页面的地址空间块。每个地址空间块的大小为 1024 * 4 KB = 4 MB，因此 1024 条 PTE 就可以覆盖 32 位（4 MB * 1024 = 4 GB = $2^{32}$ B）地址空间。\n如果地址空间块中的所有页面均未分配，则一级页表中对应的 PTE 为空（如上图中的 PTE 2～7）；如果地址空间块中至少有一个页面已分配，那么一级页表中对应的 PTE 就指向二级页表中该块的起始位置（如上图中的 PTE 0～1）。二级页表中的每条 PTE 都映射到一个 4 KB 的物理内存页，这与我们之前查看的单级页表相同。\n若一级页表中的 PTE 为空，那么二级页表内对应的条目就无需存在。多数应用程序的虚拟地址空间中大部分页面是未分配的，因此这将显著地降低页表的内存占用。另外，我们只需在主存中维护一级页表和被调用最为频繁的二级页表，其它的二级页表可以由操作系统按需创建和分页。\n在 k 级页表中，虚拟地址被划分为 k 个 VPN 和一个 VPO，VPN i（1 ≤ i ≤ k）是第 i 级页表的索引。除第 k 级页表外，每个页表中的 PTE 均指向下一级页表的起始位置，而第 k 级表内的每条 PTE 则保存了对应物理页面的 PPN。与单级页表一样，PPO 与 VPO 相同。MMU 必须先请求 k 个 PTE，然后才能确定 PPN 以生成完整的物理地址。TLB 可以缓存多级页表中的 PTE，这使得多级页表的地址转换速度并不比单级页表慢很多。\nIntel Core i7/Linux 内存系统 尽管底层的 Haswell 微架构能够支持完整的 64 位虚拟和物理地址空间，但目前 Core i7 仅提供了 48 位 (256 TB) 的虚拟地址空间和 52 位 (4 PB ) 的物理地址空间，以及一个支持 32 位 (4 GB) 虚拟和物理地址空间的兼容模式。\nCore i7 地址转换 如上图所示，Core i7 使用四级页表结构。CR 3 控制寄存器中保存了一级 (L1) 页表的起始物理地址，其值是每个进程上下文的一部分并在上下文切换时恢复。48 位的虚拟地址包含了 36 位的 VPN 和 12 位（4 K = $2^{12}$）的 VPO，其中 VPN 又被划分为四个 9 位的地址空间块。\nLinux 虚拟内存系统 注：每个进程地址空间里的内核部分都是相同的，因此上图中的“Different for each process”有误。\nLinux 将虚拟内存划分为多个区域或段（Area 或 Segment），每个区域都是一些已分配且在某些方面相关的连续页面。例如，代码段、数据段、堆、共享库段和用户栈分别是不同的区域。每个已分配的页面都属于某个区域，因此不属于任何区域的页面不存在也无法被进程引用。区域概念的引入使得 Linux 允许虚拟地址空间存在间隙。\n如上图所示，Linux 内核为每个进程维护了一个独特的数据结构task_struct，其字段包含或指向内核运行该进程所需的全部信息（如 PID、用户栈指针、可执行目标文件名称和程序寄存器等）。其中，字段mm指向mm_struct，该结构体描述了虚拟内存的当前状态。mm_struct中的pgd字段指向一级页表的起始位置，它在进程运行时被内核存储在 CR 3 控制寄存器中。而mmap字段则指向一个由vm_area_structs组成的链表。描述区域信息的结构体vm_area_structs包含以下字段：\nvm_start：指向区域的起点； vm_end：指向区域的末端； vm_prot：描述该区域中所有页面的读/写权限； vm_flags：描述该区域中的页面是否与其他进程共享； vm_next：指向链表中下一个vm_area_structs。 异常处理程序可以将虚拟地址与vm_start和vm_end字段比较，从而判断它是否属于某个区域，如上图 ①。还可以根据vm_prot字段判断进程是否有权限访问目标区域中的页面，如上图 ②。\n内存映射 Linux 使用内存映射（Memory Mapping）技术初始化虚拟内存区域并将其与磁盘上的“对象”相关联。该“对象”有两种类型：\n文件系统中的常规文件（Regular File）：文件被分成多个与页面大小相同的片段，而每个片段都包含了一个虚拟页面的初始内容。由于操作系统采用按需分页的策略，因此页面在第一次被 CPU 引用前不会被换入到物理内存中。如果虚拟内存区域比文件大，则多余部分用零填充； 匿名文件（Anonymous File）：由内核创建，其内容全部为二进制零。当 CPU 第一次引用该区域内的虚拟页面时，内核会先在物理内存中选择一个合适的受害者页面（若该页面已被修改则需要将其换出）并用二进制零将其覆盖，然后更新页表使虚拟页面指向被覆盖后的物理页面。整个过程中没有数据被换入到物理内存，因此该区域内的页面又被称为零需求页面（Demand-zero Page）。 一旦我们使用内存映射初始化一个虚拟页面，它就会在由内核维护的交换文件（Swap File）与物理内存之间来回交换。交换文件又称交换区（Swap Area）或交换空间（Swap Space），它的大小限制了当前运行进程所能申请的虚拟页面总量。\n回看共享目标文件 如上图所示，两进程将相同的 共享目标文件 映射到各自虚拟地址空间中的不同区域，而物理内存中只需存在单个文件副本。进程 1 对该共享区域的任何写入操作都对进程 2 可见，并且这些更改还会同步到磁盘上的原始文件。\n如上图 (a) 所示，两进程将私有目标文件映射到各自虚拟地址空间的不同区域。进程 1 对该私有区域的任何写入操作都对进程 2 不可见，并且这些更改也不会同步到磁盘上的原始文件。如上图 (b) 所示，当进程 2 试图修改该区域中的内容时，内核会在物理内存中为页面创建一个新副本并更新页表条目使其指向它。由于页面复制发生在写入操作前，这种技术被称为写时复制（Copy-on-Write），这些区域则是私有写时复制的（Private Copy-on-Write）。\n回看 fork 函数 进程调用 fork 函数后，内核会为子进程分配一个唯一的 PID 并为其创建与父进程相同的mm_struct、vm_area_structs以及页表。当任意进程后续执行写入操作时，内核将使用写时复制技术创建新页面，这便保证了进程虚拟地址空间的私有性。\n回看 execve 函数 如果进程调用 execve 函数，如execve(\"a.out\", NULL, NULL)，则加载并运行a.out的步骤如下：\n删除当前进程虚拟地址空间中用户区域的vm_area_structs； 为新程序的代码、数据、bss 和堆栈区域创建vm_area_structs。这些区域都是私有写时复制的，代码和数据区域被映射到a.out文件中的 .text 和 .data，bss 区域则被映射到大小包含在a.out内的匿名文件。堆栈的初始长度均为 0，其页面是零需求的； 如果a.out文件链接了共享库，如 C 标准库libc.so，那么还需要把这些对象动态链接到程序中，并将其映射到虚拟地址空间中的共享区域内； 使当前进程上下文中的程序计数器指向新程序代码区域的入口点。 mmap 函数 1 2 3 4 5 #include \u003cunistd.h\u003e #include \u003csys/mman.h\u003e void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); // Returns: pointer to mapped area if OK, MAP_FAILED (−1) on error mmap函数请求内核创建一个起始地址为参数start的虚拟内存区域，该区域映射到文件描述符fd所指定的对象。连续对象的长度为参数length，其首部在文件中的偏移量为参数offset：\n参数prot中包含了描述虚拟内存区域访问权限的位，即vm_area_structs中的vm_prot：\nPROT_EXEC：该区域中的页面包含可执行指令； PROT_READ：可以阅读该区域中的页面； PROT_WRITE：可以写入该区域中的页面； PROT_NONE：无法访问该区域中的页面。 参数flag中包含了描述了映射对象类型的位：\nMAP_SHARED：共享对象； MAP_PRIVATE：私有写时复制对象； MAP_ANON：匿名对象，对应的虚拟页面是零需求页面。 munmap函数删除起始于虚拟地址start、长度为length的区域，后续对已删除区域的引用会引发分段故障。\n1 2 3 4 #include \u003cunistd.h\u003e #include \u003csys/mman.h\u003e int munmap(void *start, size_t length); // Returns: 0 if OK, −1 on error 动态内存分配 相比于低级别的mmap函数，C 程序员更倾向于在运行时调用动态内存分配器（Dynamic Memory Allocator）来创建虚拟内存区域。动态内存分配器为进程维护的虚拟内存区域被称为堆（Heap），其一般结构为：\n堆向上增长，内核为每个进程都维护了一个指向堆顶的变量brk。分配器将堆看作一个包含不同尺寸 Block 的集合，每个 Block 都是一个连续的虚拟内存块。Block 有两种状态，已分配（Allocated）和空闲（Free）。所有分配器均显式地为应用程序分配 Block，但负责释放已分配 Block 的实体可能有所不同：\n显式分配器：应用程序显式地释放已分配的 Block。C 和 C++ 程序分别调用malloc和new函数请求 Block，调用free和delete函数释放 Block； 隐式分配器：分配器自行释放程序不再使用的已分配 Block，该过程被称为垃圾回收（Garbage Collection）。Lisp、ML 和 Java 等高级语言均采用这种方法。 malloc 和 free 函数 1 2 3 #include \u003cstdlib.h\u003e void *malloc(size_t size); // Returns: pointer to allocated block if OK, NULL on error malloc函数请求堆中的一块 Block 并返回指向该 Block 的指针。Block 的大小至少为参数size，并可能根据其保存的数据对象类型进行适当对齐。在 32 位编译模式下，Block 的地址始终为 8 的倍数，而在 64 位中则为 16 的倍数。如果执行malloc遇到问题，如程序请求的 Block 大小超过了可用的虚拟内存，则函数返回NULL并设置 errno。我们还可以使用malloc的包装函数calloc，它会将分配的内存初始化为零。类似地，realloc函数可以更改已分配 Block 的大小。\n1 2 3 #include \u003cunistd.h\u003e void *sbrk(intptr_t incr); // Returns: old brk pointer on success, −1 on error sbrk函数将参数incr与内核中的brk指针相加以增大或缩小堆。若执行成功，则返回brk的旧值，否则将返回 -1 并将errno设置为ENOMEM。\n1 2 3 #include \u003cstdlib.h\u003e void free(void *ptr); // Returns: nothing free函数将参数ptr指向的 Block 释放，而这些 Block 必须是由malloc、calloc或realloc分配的。该函数没有返回值，因此很容易产生一些令人费解的运行时错误。\n上图展示了 C 程序如何使用malloc和free管理一个大小为 16 字（字长为 4 字节）的堆。图中的每个方框代表一个字，每个被粗线分隔的矩形代表一个 Block。有阴影的 Block 代表已分配，无阴影的 Block 则代表空闲。\n如上图 (a) 所示，程序请求一个 4 字的 Block，malloc从空闲块中切出一个 4 字的 Block 并返回指向该 Block 中第一个字的指针p1；如上图 (b) 所示，程序请求一个 5 字的 Block，malloc从空闲块中切出一个 6 字的 Block 以实现双字对齐；如上图 (c) 所示，程序请求一个 6 字的 Block，malloc从空闲块中切出一个 6 字的 Block；如上图 (d) 所示，程序释放图 (b) 中分配的 Block。free返回后，指针p2依然指向已释放的 Block，因此程序不应在重新初始化p2前继续使用它；如上图 (e) 所示，程序请求一个 2 字的 Block。malloc从上一步释放的 Block 中切出一部分并返回指向新 Block 的指针p4。\n动态内存分配的原因 在程序实际运行之前，我们可能并不知道某些数据结构的大小。示例 C 程序将n个 ASCII 整型从标准输入读取到数组array[MAXN]中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #include \"csapp.h\" #define MAXN 15213 int array[MAXN]; int main() { int i, n; scanf(\"%d\", \u0026n); if (n \u003e MAXN) app_error(\"Input file too big\"); for (i = 0; i \u003c n; i++) scanf(\"%d\", \u0026array[i]); exit(0); } 由于我们无法预测n的值，因此只能将数组大小写死为MAXN。MAXN的值是任意的，可能超出系统可用的虚拟内存量。另外，一旦程序想要读取一个比MAXN还大的文件，唯一的办法就是增大MAXN的值并重新编译程序。如果我们在运行时根据n的大小动态分配内存，以上问题便迎刃而解：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \"csapp.h\" int main() { int *array, i, n; scanf(\"%d\", \u0026n); array = (int *)Malloc(n * sizeof(int)); for (i = 0; i \u003c n; i++) scanf(\"%d\", \u0026array[i]); free(array); exit(0); } 对分配器的要求和目标 显式分配器必须在若干限制条件下运行：\n处理任意顺序的请求：分配器不能对malloc和free的请求顺序作出假设。例如，分配器不能假设所有的malloc都紧跟一个与之匹配的free； 立即响应请求：分配器不可以对请求重新排序或缓冲（Buffer）以提高性能； 仅使用堆：分配器使用的数据结构必须存储在堆中； 对齐 Block：分配器必须对齐 Block 以使其能够容纳任何类型的数据对象； 不修改已分配的 Block：分配器无法修改、移动或压缩已分配的 Block。 衡量分配器性能的指标有：\n吞吐量（Throughput）：单位时间内完成的请求数； 内存利用率（Memory Utilization）：即堆内存的使用率。 最大化吞吐量和最大化内存利用率之间存在矛盾，因此我们在设计分配器时需要找到二者的平衡。\n碎片 我们将空闲堆内存无法满足分配请求的现象称为碎片（Fragmentation），它是内存利用率低的主要原因。碎片有两种形式：\n内部碎片（Internal Fragmentation）：已分配的 Block 比进程请求的 Block（即 Payload）大，通常因分配器为满足对齐要求而产生； 外部碎片（External Fragmentation）：空闲内存充足但却没有空闲的 Block 能够满足分配请求。例如堆中有 4 个空闲的字且分布在两个不相邻的 Block 上，此时若进程申请一个 4 字的 Block 就会出现外部碎片。 内部碎片很容易量化，因为它只是已分配 Block 与 Payload 之间大小差异的总和，其数量仅取决于先前的请求模式和分配器的实现方式；外部碎片则难以量化，因为它还要受到未来请求模式的影响。为了减少外部碎片的产生，分配器力求维护少量较大的空闲 Block 而非大量较小的空闲 Block。\n分配器的实现难点 我们可以想象一个简单的分配器，它将堆看作一个大型的字节数组，指针p指向该数组的第一个字节。当进程请求size大小的 Block 时，malloc先把p的当前值保存在栈中，然后将其加上size，最后返回p的旧值。当进程想要释放 Block 时，free则只是简单地返回给调用者而不做任何事情。\n由于malloc和free仅由少量指令组成，这种分配器的吞吐量很大。然而malloc不会重用任何 Block，因此堆内存的利用率非常低。能够在吞吐量和内存利用率之间取得良好平衡的分配器必须考虑以下问题：\n组织（Organization）：如何跟踪空闲的 Block？ 放置（Placement）：如何从空闲的 Block 中选择合适的来放置新分配的 Block？ 分割（Splitting）：完成放置后，如何处理剩余的空闲 Block？ 合并（Coalescing）：如何处理刚刚被释放的 Block？ 隐式空闲链表 大多数分配器通过将一些数据结构嵌入到 Block 中以分辨其边界和状态，例如：\n如上图所示，Block 由一个单字（四字节）的头部（Header）、有效负载（Payload）和一些额外填充（Padding）组成，头部中包含了 Block 的大小（Block Size）和状态信息（Allocated or Free）。如果系统采用双字对齐策略，那么每个 Block 的大小始终为 8 的倍数，其二进制表达的后 3 位始终为 0。因此我们可以仅在头部中存储该字段的前 29 位，剩余 3 位用来存储其他信息。上图中的位“a”便指示了此 Block 是已分配的还是空闲的。填充的大小是任意的，它可能是分配器为了避免外部碎片产生而设置的，也可能是为了满足对齐要求而存在的。\n基于这种 Block 格式，我们可以将堆组织成一系列连续的已分配 Block 和空闲 Block：\nBlock 通过其头部中的大小字段隐式地链接起来（addr(next_block) = addr(current_block) + block_size），因此我们将这种堆组织方式称为隐式空闲链表（Implicit Free List），分配器必须遍历堆中所有的 Block 才能得到全部空闲的 Block。我们还需要一个特殊的 Block 以标记堆的结尾，如上图中的 “0/1”。隐式空闲链表的优点是简单，但任何搜索空闲 Block 的操作（如放置新分配的 Block）的成本都与堆中 Block 的总数成正比。\n放置新分配的 Block 当应用程序请求一个 Block 时，分配器需要在空闲链表中选取一个足够大的 Block 以响应。分配器搜索空闲 Block 的方式由放置策略（Placement Policy）所决定：\n第一次拟合（First Fit）：从头开始遍历空闲链表并选择第一个满足条件的 Block； 下一次拟合（Next Fit）：从上一次搜索停止的地方开始遍历空闲链表并选择第一个满足条件的 Block； 最佳拟合（Best Fit）：遍历所有 Block 并选择满足条件且最小的 Block。 第一次拟合的优点是较大的 Block 通常存留在链表末尾，但一些较小的 Block 也会散落在链表开头，这将增加搜索较大 Block 的时间。如果链表开头存在大量较小的 Block，下一次拟合就比第一次拟合快很多。然而研究表明，下一次拟合的内存利用率比第一次拟合低。最佳拟合的内存利用率通常比其他两种策略高，但对隐式空闲链表来说，其搜索时间显然要比它们慢很多。\n分割空闲的 Block 如果分配器找到了合适的 Block 并将整个 Block 分配给程序，就有可能产生内部碎片。为了避免这一问题，分配器可以将选取的 Block 分成一个已分配的 Block 和一个新的空闲 Block：\n如图 9.37 所示，程序请求一个 3 字的 Block，于是分配器将图 9.36 中 8 字的空闲 Block 拆分为两个 4 字的 Block 并将其中之一分配给它。\n获取额外的堆内存 如果分配器无法找到合适的 Block，它可以尝试将相邻的空闲 Block 合并以获取更大的 Block。但如果仍然无法满足请求，分配器便会调用sbrk函数向内核请求额外的堆内存并将其转换为一个新的空闲 Block。\n合并空闲的 Block 分配器释放 Block 后，可能会有其他空闲的 Block 与之相邻。此时内存中将产生一种特殊的外部碎片现象，我们称其为虚假碎片（False Fagmentation）。\n如图 9.38 所示，分配器将图 9.37 中第二个 4 字 Block 释放。尽管两个连续空闲 Block 中均有 3 字的有效负载，它们也无法满足一个 4 字的分配请求。因此，分配器必须将相邻空闲的 Block 合并。\n分配器可以在每次释放 Block 后立即合并 Block，也可以等到某个时刻，比如分配请求失败时才合并堆中所有空闲的 Block。立即合并很简单，但它也有可能造成“颠簸”，即某个 Block 在短时间内被多次合并和分割。\n使用边界标记合并 Block 我们把即将释放的 Block 称为当前（Current）Block，其头部指向下一个 Block 的头部（addr(next_block) = addr(current_block) + block_size）。因此我们很容易判断下一个 Block 是否空闲，并且只需将当前 Block 头部中的大小字段与之相加即可完成合并。\n但若要合并上一个 Block，我们只能遍历整个链表，并在到达当前 Block 前不断记下上一个 Block 的位置。因此对于隐式空闲链表，合并上一个 Block 的时间与堆内存的大小成正比。\n我们可以在每个 Block 末尾都添加一个头部的副本以使合并 Block 的时间变为常数，这种技术被称为边界标记（Boundary Tags）：\n上一个 Block 的尾部始终与当前 Block 的头部相距一个字长，因此分配器可以通过检查上一个 Block 的尾部来确定其位置和状态。下图展示了分配器是如何使用边界标记合并 Block 的：\n由于每个 Block 都包含头部和尾部，当 Block 数量较多时，边界标记显著地增加了内存的开销。考虑到分配器只有在上一个 Block 空闲时才需要获取其尾部内的 Block 大小，因此我们可以将上一个 Block 的状态存储在当前 Block 头部的多余低位中，这样已分配的 Block 便不需要尾部了。\n显式空闲链表 由于分配 Block 的时间与 Block 的总数成正比，隐式空闲链表不适用于通用分配器。我们可以在每个空闲 Block 中加入一个指向上一个空闲 Block 的前驱（Predecessor）指针和一个指向下一个空闲 Block 的后继（Successor）指针，这样堆的组织结构就变成了一个双向链表，我们称其为显式空闲链表（Explicit Free List）。\n如果采用第一次拟合策略，显式空闲链表分配 Block 的时间与空闲 Block 的数量成正比，而释放 Block 的时间则取决于空闲 Block 的排序方式：\n后进先出（Last-in First-out，LIFO）：将刚被释放的 Block 插入到链表开头，因此释放 Block 的时间为常数，并且可以通过边界标记使合并 Block 的时间也为常数； 按地址顺序（Address Order）：使链表中每个 Block 的地址均小于其后继 Block 的地址。在这种情况下，释放 Block 需要一定的时间来寻找合适的位置，但堆内存的利用率比后进先出高。 显式空闲链表的缺点在于指针的引入增加了空闲 Block 的大小，这将增大内部碎片发生的可能性。\n分离式空闲链表 我们可以将堆组织成多个空闲链表，每个链表中 Block 的大小都大致相同，这种结构被称为分离式空闲链表（Segregated Free List）。为了实现这一结构，我们需要把 Block 的大小划分为多个大小类（Size Class），如：\n$$\\lbrace1\\rbrace, \\lbrace2\\rbrace, \\lbrace3, 4\\rbrace, \\lbrace5–8\\rbrace,…, \\lbrace1025–2048\\rbrace, \\lbrace2049–4096\\rbrace, \\lbrace4097–∞\\rbrace$$\n也可以让每个较小的 Block 独自成为一个大小类，较大的 Block 依然按 2 的幂划分：\n$$\\lbrace1\\rbrace, \\lbrace2\\rbrace, \\lbrace3\\rbrace,…, \\lbrace1024\\rbrace, \\lbrace1025–2048\\rbrace, \\lbrace2049–4096\\rbrace, \\lbrace4097–∞\\rbrace$$\n每个空闲链表都属于某个大小类，因此我们可以将堆看成一个按大小类递增的空闲链表数组。当进程请求一个 Block 时，分配器会根据其大小在适当的空闲链表中搜索。如果找不到满足要求的 Block，它便会继续搜索下一个链表。\n不同的分离式空闲链表在定义大小类的方式、合并 Block 的时机以及是否允许分割 Block 等方面有所不同，其中最基本的两种类型为简单分离存储（Simple Segregated Storage）和分离拟合（Segregated Fits）。\n在简单分离存储中，空闲链表内每个 Block 的大小均等于其所属大小类中最大的元素。如某个大小类为 {17-32}，则其对应的空闲链表中 Block 的大小都是 32。\n当进程请求一个 Block 时，分配器选取满足请求的空闲链表并分配其中第一个 Block；当某个 Block 被释放后，分配器将其插入到合适的空闲链表前面。因此，简单分离存储分配和释放 Block 的时间均为常量。\n使用分离式空闲链表的分配器只会在堆中某个特定部分搜索空闲 Block，因此其吞吐量较大；对分离式空闲链表使用第一次拟合的内存利用率与对整个堆使用最佳拟合的内存利用率近似，因此其内存利用率较高。大多数高性能的分配器均采用分离式空闲链表，如 C 标准库提供的 GNU malloc。\n垃圾回收 垃圾回收器（Garbage Collector）是一种动态存储分配器，它会自动释放程序不再需要的 Block（垃圾）。\n基本思想 垃圾回收器将内存看作一个有向可达性图：\n图中的节点被分为一组根节点（Root Nodes）和一组堆节点（Heap Nodes），每个堆节点都对应于一个堆中已分配的 Block。有向边 $p \\rarr q$ 表示 Block $p$ 中的某个位置指向 Block $q$ 中的某个位置。根节点对应于不在堆中却包含了指向堆的指针的位置，这些位置可以是寄存器、栈中的变量或可读写数据区域中的全局变量。\n如果根节点与堆节点之间存在一条有向路径，我们就称该堆节点是可达的（Reachable）。在任何时刻，不可达的节点都与程序不再使用的 Block 对应。垃圾回收器定期释放不可达节点并将其返回到空闲链表。\nML 和 Java 等语言的垃圾回收器对应用程序使用指针的方式进行了严格的限制，因此它可以维护一个精确的可达性图，从而回收所有的垃圾。而 C 和 C++ 等语言的垃圾回收器则无法保证可达性图的精确性，一些不可达的节点可能被错误地识别为可达的，我们称其为保守垃圾回收器（Conservative Garbage Collector）。\n垃圾回收器可以按需提供服务，也可以作为单独的进程与应用程序并行运行，不断更新可达性图并回收垃圾：\nMark\u0026Sweep 算法 Mark\u0026Sweep 是常用的垃圾回收算法之一，它分为两个阶段：\n标记（Mark）阶段：标记所有可达的根节点后代。通常我们将 Block 头部的多余低位之一用于指示该 Block 是否被标记； 清除（Sweep）阶段：释放所有未标记且已分配的 Block。 为了更好地理解 Mark\u0026Sweep 算法，我们作出以下假设：\nptr：由typedef void *ptr定义的类型； ptr isPtr(ptr p)：若p指向已分配 Block 中的某个字，则返回指向该 Block 起始位置的指针b，否则返回NULL； int blockMarked(ptr b)：如果该 Block 已被标记则返回true； int blockAllocated(ptr b)：如果该 Block 已分配则返回true； void markBlock(ptr b)：标记 Block； int length(ptr b)：返回 Block 除头部外的字长； void unmarkBlock(ptr b)：将 Block 的状态从已标记转换为未标记； ptr nextBlock(ptr b)：返回指向下一个 Block 的指针。 那么此算法就可以用下图中的伪码表示：\n在标记阶段，垃圾回收器为每个根节点调用一次mark函数。若p未指向已分配且未标记的 Block，则该函数直接返回。否则，它标记该 Block 并将其中的每个字作为参数递归地调用自身（mark(b[i])）。此阶段结束时，任何未标记且已分配的 Block 都是不可达的；在扫描阶段，垃圾回收器只调用一次sweep函数。该函数遍历堆中的每一个 Block，释放所有已分配且未标记的 Block。\n上图中的每个方框代表一个字，每个被粗线分隔的矩形代表一个 Block，而每个 Block 都有一个单字的头部。最初，堆中有 6 个已分配且未标记的 Block。Block 3 中包含指向 Block 1 的指针，Block 4 中包含指向 Block 3 和 6 的指针。根节点指向 Block 4，因此 Block 1、3、4 和 6 从根节点可达，它们会被垃圾回收器标记。在扫描阶段完成后，剩余不可达的 Block 2 和 5 将被释放。\n","description":"","tags":["OS"],"title":"CSAPP 读书笔记：虚拟内存","uri":"/posts/virtual-memory-note/"},{"content":"链接（Linking）是将各部分代码和数据收集并组成单个文件的过程，该文件可以被加载（复制）到内存中执行。链接可以在编译时（即源代码被翻译成机器代码时）执行，也可以在加载时（即程序被加载到内存并由加载器执行时）执行，甚至还可以在运行时由应用程序执行。在现代系统中，能够自动执行链接的程序被称为链接器（Linker）。\n链接器支持单独编译（Separate Compilation），因此在软件开发中起着至关重要的作用。与其将大型应用程序组织为一个单一的大块源文件，不如将其分解为一些更小、更易于管理并且可以单独修改和编译的模块。一旦我们修改了其中的某个模块，只需重新编译该模块并将其链接到应用程序，不必再次编译其他文件。\n编译器驱动 大多数编译系统都提供了一个编译器驱动（Compiler Driver），它可以根据用户需求调用语言预处理器（Language Preprocessor）、编译器、汇编器和链接器等。例如要在 GNU 编译系统中构建下列程序，我们可以 使用命令gcc -Og -o prog main.c sum.c:\n编译器驱动将示例程序从 ASCII 源文件转换为可执行目标文件时的过程如下图所示：\n首先，驱动运行 C 预处理器（C Preprocessor，CPP），将源文件main.c转换为 ASCII 中间文件main.i；接下来，驱动运行 C 编译器 (C Compiler，CC)，将main.i转换为 ASCII 汇编语言文件main.s；然后，驱动运行汇编器，将main.s转换为二进制可重定位（Relocatable）目标文件main.o（sum.o的生成过程相同）；最后，驱动运行链接器，将main.o、sum.o和一些必要的系统目标文件组合，创建二进制可执行目标文件prog。\n静态链接 静态链接器（Static Linker）将可重定位目标文件和命令行参数作为输入，生成完全链接的可执行目标文件。可重定位目标文件由各种代码和数据组成，指令、初始化的全局变量和未初始化的变量分别处于不同部分。\n链接器需要完成两个主要任务：\n符号解析（Symbol Resolution）：目标文件定义并引用符号，每个符号对应一个函数、全局变量或静态变量（即使用static声明的任何变量）。符号解析的目的是将每个符号引用与一个符号定义相关联； 重定位（Relocation）：编译器和汇编器生成的代码和数据段是从地址 0 开始的，链接器会重定位所有的符号定义并修改其对应的符号引用。 目标文件只是字节块的集合，其中可能包含代码、数据或指导链接器和加载器的数据结构。链接器将各个块连接在一起，确定整个块的运行时位置，并修改代码和数据块中的不同位置。编译器和汇编器在生成目标文件时已经完成了大部分工作，因而链接器对目标机器的了解甚少。\n目标文件 目标文件（Object File）有三种形式：\n可重定位目标文件：包含二进制代码和数据，可以在编译时与其他可重定位目标文件组合以创建可执行目标文件； 可执行目标文件：包含二进制代码和数据形式，可直接被复制到内存中执行； 共享目标文件：一种特殊类型的可重定位目标文件，可以在加载时或运行时被加载到内存中并动态链接。 可重定位目标文件 典型的 ELF（Executable and Linkable Format）可重定位目标文件格式如下图所示：\nELF 头（ELF Header）：开头是一个表征系统字长（Word Size）和字节顺序（Byte Ordering）的 16 字节序列。其余部分包括 ELF 头的大小、目标文件的类型（如可重定位、可执行或共享）、机器类型（如 x86-64）、节头表（Section Header Table）的文件偏移量以及其中条目的大小和数量； 节头表：描述了目标文件中每个 Section 的位置和大小； Section：位于 ELF 头和节头表之间，包括： .text：编译后程序的机器码； .rodata：只读数据，例如printf中的格式字符串，Switch 语句的 跳转表 等； .data：已初始化的全局变量和静态变量。非静态局部变量在运行时位于栈中，不会出现在 .data 或 .bss 中； .bss：未初始化的静态变量，以及初始化为 0 的全局变量和静态变量。此 Section 只是一个占位符，在目标文件中不占用实际空间，因此可以提升空间效率。这些变量在运行时被分配到内存中，初始值为零； .symtab ：一个保存了在程序中被定义和引用的函数和全局变量信息的符号表（Symbol Table）。与编译器中的符号表不同，.symtab 中的符号表不包含任何局部变量； .rel.text：当链接器将目标文件与其他文件组合时，.text 中的许多位置都需要被修改，而 .rel.text 中则保存了与之相关的重定位信息。通常，任何调用外部函数或引用全局变量的指令都需要被修改，而调用局部函数的指令则不变。可执行目标文件一般不需要重定位信息，因此这部分可以省略； .rel.data：被引用或定义的任何全局变量的重定位信息。通常，所有初始值为全局变量地址或外部定义函数地址的已初始化全局变量都需要被修改； .debug：调试符号表，仅在使用-g选项调用编译器驱动时出现； .line：原始程序中行号与 .text 中机器代码指令之间的映射关系，仅在使用-g选项调用编译器驱动时出现； .strtab：一个以NULL结尾，包含 .symtab 和 .debug 中的符号表以及 Section 名称的字符串序列。 符号和符号表 每个目标文件都有一个符号表，其中包含了该文件所定义和引用的符号信息。符号有以下三种：\n全局符号（Global Symbols）：由该文件定义并且可以被其他文件引用的符号； 外部符号（Externals）：被该文件引用但由其他文件定义的符号； 局部符号（Local Symbols）：由该文件定义且无法被其他文件引用的符号，即使用static声明的函数和变量。 上节提到，非静态局部变量在运行时位于栈中，与链接器无关。而静态局部变量则保存在 .data 或 .bss 中，编译器会在符号表中为其创建名称唯一的局部符号。例如同一文件中的两个函数都定义了静态局部变量x：\n1 2 3 4 5 6 7 8 9 10 int f() { static int x = 0; return x; } int g() { static int x = 1; return x; } 那么编译器可能将x.1作为函数f()中的变量符号，将x.2作为函数g()中的变量符号发送给汇编器。汇编器使用接收到的.s文件中的符号构建符号表，其中每个条目的数据结构为：\nname：符号名在字符串表 .strtab 中的偏移量； value：对于可重定位目标文件是符号在其 Section 中的偏移量，对于可执行目标文件是符号的运行时地址； size：符号的大小； type：符号的类型； binding：符号是局部的还是全局的； section：符号所在的 Section 在节头表中的索引。 值得一提的是，有三个伪 Section 在节头表中没有条目：\nABS：不应重定位的符号； UNDEF：在此文件中引用但在其他文件中定义的符号； COMMON：未初始化的全局符号。 上述三个 Section 仅存在于可重定位目标文件，在可执行目标文件中并不存在。我们可以使用 READELF 工具阅读目标文件中的内容，示例程序 main.c 生成的目标文件符号表条目如下：\nREADELF 通过整数索引 Ndx 标识每个 Section，1 表示 .text，3 表示 .data。全局符号main和array分别位于上述两个 Section 首部，因此其偏移量value均为 0。外部符号sum未在本文件中定义，位于 UNDEF。\n符号解析 链接器将每个符号引用与符号表中的符号定义相关联以完成符号解析（Symbol Resolution）。当编译器遇到未在当前文件中定义的符号时，它会假设该符号已在其他文件中定义，然后生成对应的符号表条目。如果链接器无法在任何输入文件中找到该符号的定义，那么它就会终止链接。\n不同文件可能定义了相同名称的全局符号。对于这种情况，链接器要么直接报错，要么选取其中之一。\nC++ 和 Java 允许重载名称相同但参数列表不同的方法。编译器会将每个方法和参数列表组合为一个唯一的名称，这样链接器就可以区分它们。例如，Foo::bar(int, long)会被编码为bar__3Fooil。其中，3 代表类名 Foo 的字符数，i 和 l 则分别代表参数列表中的int和long。\n解析名称重复的符号 Linux 编译系统会在编译时将全局符号分为两种类型：函数和已初始化的全局变量是强符号，未初始化的全局变量是弱符号。汇编器将符号的强弱信息隐式地编码到目标文件的符号表中。\n链接器解析名称重复的符号的规则为：\n不允许多个强符号名称重复； 若一个强符号和多个弱符号名称重复，选择强符号； 若多个弱符号名称重复，从中任选其一。 注：最新版本的 GCC（如 GCC 10）默认使用标识位-fno-common，因此若程序包含多个名称重复的弱符号将引发链接错误。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /* foo3.c */ #include \u003cstdio.h\u003e void f(void); int x = 15213; int main() { f(); printf(\"x = %d\\n\", x); return 0; } /* bar3.c */ int x; void f() { x = 15212; } 示例程序中，文件bar3.c中的函数f是强符号，文件foo3.c中的函数f是弱符号，因此主函数的输出x的值为 15212。\n上文提到，未初始化的全局变量保存在 COMMON 中，而未初始化的静态变量，以及初始化为 0 的全局变量和静态变量保存在 .bss 中。这是因为前者是弱符号，编译器无法知晓其他文件中是否定义了相同名称的变量，必须将其分配到 COMMON 中并随后由链接器处理。已初始化为 0 的全局变量是强符号，根据第二条解析规则，该变量一定是唯一的，因此编译器可以安心地把它放到 .bss 中。静态变量无法被其他文件引用，自然也无需担心名称重复的问题。\n与静态库链接 编译系统将一些相关的目标模块打包到一个文件中，该文件被称为静态库（Static Library）。在构建可执行目标文件时，链接器仅复制静态库中被应用程序引用的目标模块，从而减小了磁盘和内存中可执行文件的大小。静态库为我们提供了 I/O、字符串操作和数学运算等标准函数。\n在 Linux 系统中，静态库以特定的文件格式（后缀为.a）存储在磁盘上。应用程序可以在命令行中指定文件名来使用静态库中定义的任何函数（实际上，C 编译器驱动总是将libc.a传递给链接器），如：\n1 linux\u003e gcc main.c /usr/lib/libm.a /usr/lib/libc.a 我们使用 AR 命令将下列程序打包为静态库文件libvector.a：\n1 2 linux\u003e gcc -c addvec.c multvec.c linux\u003e ar rcs libvector.a addvec.o multvec.o 接下来再编写一个程序main2.c调用该静态库，头文件vector.h定义了库文件中的函数原型：\n最后使用如下命令编译并链接main2.o和libvector.a：\n1 2 linux\u003e gcc -c main2.c linux\u003e gcc -static -o prog2c main2.o ./libvector.a -static参数表示链接器应当构建一个完全链接的可执行目标文件，该文件可以被加载到内存中运行而无需进一步地链接。完整的链接流程如下图所示：\n静态库的符号解析 符号解析时，链接器会按照从左到右的顺序依次扫描命令行中的目标文件和静态库。在这个过程中，E 为可重定位目标文件的集合，U 为被引用但还未找到定义的符号，D 为已扫描过的文件定义的符号，开始时三者均为空。\n若命令行中的输入文件为可重定位目标文件，则链接器将其添加到 E 中并更新 U 和 D 中的符号； 若命令行中的输入文件为静态库，则链接器会将 U 中的符号与该静态库中定义的符号相匹配。匹配成功的模块会被添加到 E 中，随后链接器更新 U 和 D 中的符号。当 U 和 D 中的符号不再改变时，匹配结束，任何不在 E 中的静态库模块都将被直接丢弃； 若扫描全部完成时 U 为空，则链接器合并并重定位 E 中所有的目标文件以构建可执行文件。否则，链接器将报错并终止。 链接器的这种行为限制了命令行中的文件顺序。如果定义符号的静态库出现在引用该符号的目标文件之前，链接就会失败。\n重定位 符号解析完成后，链接器会将代码中的每个符号引用与一个符号定义相关联。接下来，链接器开始对目标文件重定位：\n重定位 Section 和符号定义：链接器将所有输入模块中相同类型的 Section 合并为一个新的聚合 Section，然后将运行时地址分配给每个 Section 和符号； 在 Section 内重定位符号引用：链接器修改代码和数据段中的每个符号引用，使其指向正确的运行时地址。 重定位条目 汇编器在生成目标文件时，并不知晓代码、数据和引用的外部符号在内存中的最终位置。它只会为每个引用生成一个重定位条目（Relocation Entry），指导链接器如何修改它们。上文提到，代码的重定位条目放在 .rel.text 中，数据的重定位条目则放在 .rel.data 中。\nELF 重定位条目的数据结构为：\n1 2 3 4 5 6 typedef struct { long offset; /* Offset of the reference to relocate */ long type:32, /* Relocation type */ symbol:32; /* Symbol table index */ long addend; /* Constant part of relocation expression */ } Elf64_Rela; offset是被修改的引用在其 Section 中的偏移量；symbol是引用指向的符号在符号表中的索引；type告知链接器如何修改引用；addend是一个有符号常量，某些类型的重定位使用它来偏置被修改的引用值。\n最基本的两种重定位类型为：\nR_X86_64_PC32：使用 32 位 PC 相对地址重定位引用。当 CPU 执行一条使用 PC 相对地址的指令时，它会将指令中的目标地址与 PC 当前值（即下一条指令在内存中的地址）相加得到有效地址（在 跳转指令 一节中我们讨论过这一问题）； R_X86_64_32：使用 32 位绝对地址重定位引用。CPU 直接使用指令中的目标地址作为有效地址，无需进一步地修改。 重定位符号引用 重定位算法的伪码如下图所示：\n链接器遍历每个 Section（s）中的每个重定位条目（r），s是一个字节数组，r是上一节介绍的Elf64_Rela类型的结构体，*refptr是指令中的目标地址。假设该算法运行时，链接器已经为每个 Section 和每个符号选择了运行时地址ADDR(s)和ADDR(r.symbol)。\n我们使用命令objdump -dx main.o得到汇编器为 示例程序 main.c 生成的机器码和重定位条目：\n重定位条目（图中第 5 行和第 7 行）告知链接器对符号array的引用使用绝对地址重定位，而对符号sum()的引用则使用 PC 相对地址重定位。\nPC 相对地址重定位 如上图第 6 行所示：指令callq在其 Section 中的偏移量为 0xe，它包含一个一字节的指令码 0xe8 和一个用于指向sum()的 32 位 PC 相对引用的占位符。该引用对应的重定位条目为：\n1 2 3 4 r.offset = 0xf r.symbol = sum r.type = R_X86_64_PC32 r.addend = -4 上述字段告诉链接器需要修改从偏移量 0xf 开始的 32 位 PC 相对引用，使其在运行时指向sum()。 假设ADDR(s) = ADDR(.text) = 0x4004d0，ADDR(r.symbol) = ADDR(sum) = 0x4004e8，那么首先我们可以计算得到该引用的运行时地址为：\n1 2 3 refaddr = ADDR(s) + r.offset = 0x4004d0 + 0xf = 0x4004df 然后根据上节中的算法更新引用使其指向sum()：\n1 2 3 *refptr = (unsigned) (ADDR(r.symbol) + r.addend - refaddr) = (unsigned) (0x4004e8 + (-4) - 0x4004df) = (unsigned) (0x5) 指令callq的运行时地址为 0x4004de（0x4004df -1）。当 CPU 执行该指令时，PC 中的值为该指令的下一条指令的地址 0x4004e3（0x4004de + (0xe - 9)）。CPU 将该值压入栈中，然后加上 0x5（即*refptr），就得到了sum()的地址 0x4004e8。\n绝对地址重定位 如上图中的第四行所示：指令mov将数组地址拷贝到寄存器 %edi 中，它在 Section 中的偏移量为 0x9，包含一个一字节的指令码 0xbf 和一个用于指向array的 32 位绝对引用的占位符。该引用的重定位条目为：\n1 2 3 4 r.offset = 0xa r.symbol = array r.type = R_X86_64_32 r.addend = 0 上述字段告诉链接器需要修改从偏移量 0xa 开始的 32 位 PC 绝对引用，使其在运行时指向array。 假设ADDR(r.symbol) = ADDR(array) = 0x601018，那么我们可以根据上节中的算法更新该引用为：\n1 2 3 *refptr = (unsigned) (ADDR(r.symbol) + r.addend) = (unsigned) (0x601018 + 0) = (unsigned) (0x601018) 下图展示了最终生成的可执行目标文件中的 .text 和 .data：\n加载器在加载时将这些 Section 中的字节直接拷贝到内存中，无需任何修改便可以执行其中的指令。\n可执行目标文件 ELF 可执行目标文件的结构如下：\nELF 头描述了文件的整体格式，并包含了程序在运行时执行的第一条指令的地址。.init 定义了一个名为_init的函数，它将被程序的初始化代码所调用。其余 Section 与可重定位目标文件类似，只不过它们已被重定位到运行时的内存地址。正因如此，该文件中没有 .rel.text 和 .rel.data。\n可执行目标文件的连续块与连续内存段之间的映射关系由程序头表（Program Header Table）描述：\n第一个内存段具有读取和执行权限，从内存地址 0x400000 开始，大小为 0x69c 个字节。该内存段是由可执行目标文件的前 0x69c 个字节（偏移量为 0）初始化得到的，包含了 ELF 头、程序头表、.init、.text 和 .rodata。\n第二个内存段具有读取和写入权限，从内存地址 0x600df8 开始，大小为 0x230 个字节。该内存段对应了可执行目标文件中偏移量为 0xdf8 的 0x228 个字节，包含了 .data 和 .bss（两者大小之差的 8 个字节即保存在 .bss 并将在运行时初始化为 0 的数据）。\n对于每个内存段，链接器必须选择一个起始地址 vaddr，使得：\n$$vaddr\\space mod\\space align = off\\space mod\\space align$$\n其中，off 是该内存段中第一个 Section 在目标文件中的偏移量，align 是程序头表中指定的对齐方式。这种对齐要求是一种优化，它可以使目标文件被更加有效地加载到内存中。\n加载可执行目标文件 下图展示了 Linux 程序的运行时内存结构：\n加载器首先根据程序头表将可执行目标文件中的块复制到内存中的代码和数据段，然后跳转到程序入口，即_start_函数（在系统目标文件crt1.o中定义）的地址。该函数再调用libc.so中定义的系统启动函数__libc_start_main，由它初始化执行环境，调用用户级的主函数并处理其返回。\n使用共享库动态链接 静态库会被定期维护和更新，因此程序员需要知晓其变动并将重新链接程序。此外，几乎所有 C 程序都会使用一些标准 I/O 函数，例如printf。这些函数的代码将在运行时被复制到每个进程的代码段中，从而导致严重的内存浪费。\n共享库（Shared Libraries）可以解决上述静态库的缺点。它是一种可以在加载时或运行时于任意内存地址加载并与程序链接的目标模块，该过程被称为动态链接（Dynamic Linking）。共享库在 Linux 系统中以.so为后缀，而在 Windows 系统中则被称为 DLL（Dynamic Linking Libraries）。\n在任意文件系统中，每个共享库都只有一个.so文件。与静态库不同的是，该文件中的代码和数据可以被引用该库的所有可执行文件共享，而不需要复制到可执行文件中。示例程序 的动态链接过程如下图所示：\n我们使用如下指令将 addvec.c 和 multvec.c 构建为共享库文件libvector.so:\n1 linux\u003e gcc -shared -fpic -o libvector.so addvec.c multvec.c 其中，-fpic指示编译器生成 与位置无关代码（Position-Independent Code），而-shared则指示链接器创建共享目标文件。一旦共享库文件创建成功，就可以将其链接到示例程序中：\n1 inux\u003e gcc -o prog2l main2.c ./libvector.so 我们需要明确的是，libvector.so的任意代码和数据都没有被复制到可执行文件prog2l中。链接器只会复制一些重定位和符号表信息，它们将在加载时用于解析引用了共享库的符号。\n加载器随后读取可执行文件中包含的动态链接器路径，加载并运行它。动态链接器也是一个共享库文件，如 Linux 系统的ld-linux.so。它通过执行以下重定位操作来完成链接：\n将libc.so的代码和数据重定位到某个内存段； 将libvector.so中的代码和数据重定位到另一个内存段； 将prog2l中所有引用了共享库的符号重定位。 最终，动态链接器将控制权转移给应用程序，共享库的位置不会在程序执行期间改变。\n从应用程序中加载和链接共享库 应用程序还可以在运行时请求动态链接器加载和链接共享库，其应用场景包括：Windows 应用程序的开发人员使用共享库来分发软件更新；现代 Web 服务器使用动态链接有效地更新或添加功能。\nLinux 系统为应用程序提供了一些简单接口以实现上述功能：\n1 2 3 #include \u003cdlfcn.h\u003e void *dlopen(const char *filename, int flag); // Returns: pointer to handle if OK, NULL on error 函数dlopen加载并链接共享库文件filename，参数flag可以是RTLD_GLOBAL、RTLD_NOW和RTLD_LAZY中的一个或多个（详见 dlopen）。\n1 2 3 #include \u003cdlfcn.h\u003e void *dlsym(void *handle, char *symbol); // Returns: pointer to symbol if OK, NULL on error 类似的接口函数还有 dlsym、dlclose 和 dlerror。示例程序 展示了应用程序是如何调用它们来动态链接共享库的。\n与位置无关代码 现代系统在编译共享库时会生成一种无需重定位即可被加载到内存中任意位置的代码，即与位置无关代码（Position-Independent Code，PIC），这样共享库就能被多个正在运行的进程同时引用。\nPIC 数据引用 编译器在 PIC 数据段的开头创建了一个全局偏移量表（Global Offset Table，GOT），其中的每个条目都对应一个被目标模块引用的全局符号。编译器还会为这些条目生成重定位记录。加载时，动态链接器重定位每个 GOT 条目，使其包含被引用符号的绝对地址。每个引用了全局符号的目标模块都有自己的 GOT。\n下图展示了示例共享库libvector.so中的 GOT：\n无论我们在何处加载共享模块，其数据段与代码段之间的距离始终相同。因此，代码段中的addl与数据段中的 GOT[3] 之间的偏移量是一个运行时常量。当函数addvec引用全局变量addcnt时，先通过0x2008b9(%rip)计算得到 GOT[3] 的地址，然后从中读取加载时被动态链接器赋予的addcnt的绝对地址。\nPIC 函数调用 PIC 函数调用的运行时地址是在该函数第一次被调用时确定的，这种技术被称为延迟绑定（Lazy Binding）。当应用程序导入了一个包含成百上千个函数的共享库（如libc.so），却只调用其中一小部分的函数时，这种技术可以大大减少加载时不必要的重定位操作。\n延迟绑定是通过 GOT 和过程链接表（Procedure Linkage Table，PLT）共同实现的。只要目标模块调用了共享库中定义的函数，那么它就有自己的 GOT 和 PLT。上文提到，GOT 是数据段的一部分，而 PLT 则是代码段的一部分。\nGOT 和 PLT 在运行时协同工作解析函数地址的过程如下图所示：\n可执行文件中每个对共享库函数的调用都与 PLT 数组中的条目对应。其中，PLT[0] 是跳转到动态链接器的特殊条目，PLT[1] 对应系统启动函数__libc_start_main。从 PLT[2] 开始的条目对应用户代码调用的函数，如图中的addvec。\n当与 PLT 一起使用时，GOT [0] 和 GOT[1] 包含了动态连接器在解析函数地址时所需的信息，GOT[2] 是动态链接器的入口点。其余的每个条目均对应于一个在运行时需要被解析地址的调用函数，以及一个 PLT 条目。例如，GOT[4] 和 PLT[2] 与addvec对应。\n程序第一次调用addvec并解析其地址的过程如上图（a）所示：\nPLT[2] 是该函数的入口，程序首先调用它； PLT[2] 中的第一条指令间接跳转到 GOT[4]。由于最初每个 GOT 条目都指向对应 PLT 条目中的第二条指令，因此控制权将转移到 PLT[2] 中的第二条指令； PLT[2] 中的第二条指令将addvec的 ID 0x1 压入栈中，第三条指令跳转到 PLT[0]； PLT[0] 中的第一条指令将 *GOT[1] 压入栈中，第二条指令通过 GOT[2] 间接跳转到动态链接器。动态链接器根据被压入栈中的两个条目确定addvec的运行时地址并用它覆盖 GOT[4]，最终将控制权转移给addvec。 程序再次调用addvec的过程如上图（b）所示：\n程序依然首先调用 PLT[2]； 此时 GOT[4] 指向了addvec，因此控制权将被直接转移到该函数。 库插入 库插入（Library Interpositioning）能够拦截程序对共享库函数的调用，并执行用户自定义的代码。基于这项技术，我们可以计算库函数的调用次数，验证并跟踪其输入和输出的值，甚至将其替换为完全不同的函数。\n库插入的基本思想是创建一个与库函数原型相同的包装函数，然后“欺骗”系统调用包装函数而非库函数。通常，包装函数会执行自己的逻辑，调用库函数并将其返回值传递给调用者。\n库插入可以在编译时、链接时以及运行时使用。\n","description":"","tags":["OS"],"title":"CSAPP 读书笔记：链接","uri":"/posts/linking-note/"},{"content":"前言 Thanos 已成为目前 Kubernetes 集群监控的标准解决方案之一。它基于 Prometheus 之上，可以为我们提供：\n全局的指标查询视图 近乎无限的数据保留期限 包含 Prometheus 在内所有组件的高可用性 在拟定监控方案之前，阅读一些成熟的 用户案例 是十分必要的。这些博文首先分析了各自团队的集群现状以及当前监控方案难以解决的痛点，再对目前流行的几种技术栈进行对比，最后介绍投入生产使用的部署方案，因此非常值得一读。\n不过，由于 Thanos 的组件众多，且每种组件都有较多参数需要配置。对于刚接触 Thanos 的用户来说，可能难以快速上手。考虑到上述博文均未给出组件的具体配置信息，而官方提供的 部署清单 又稍显复杂并缺少详细说明。因此本文将介绍一个使用 Thanos 实现多集群（租户）监控的简单 Demo，希望能对试图尝鲜 Thanos 的用户有所帮助。它实现了以下功能：\n能够监控多个集群，并提供一个全局的指标查询视图； 每个集群都对应了一个唯一的租户 ID，可以通过租户标签区分不同集群的指标数据； 如果某个租户创建了新的集群，只需在新集群中部署 Prometheus 并配置远程写入； 简单的告警规则和告警消息推送。 Sidecar vs. Receiver Thanos 支持 Sidecar 和 Receiver 两种部署模式。它们各有利弊，需要我们根据实际情况进行取舍。\nSidecar 通常每隔 2 小时才会把 Prometheus 采集到的指标上传到对象存储中，因此 Query 查询近期数据时需要向所有 Sidecar 发起请求并合并返回结果。但这并非是 Thanos 团队引入 Receiver 的决定性因素。\nReceiver is only recommended for uses for whom pushing is the only viable solution, for example, analytics use cases or cases where the data ingestion must be client initiated, such as software as a service type environments.\n按照文档中的说法，Receiver 只推荐用于多租户以及 Prometheus 配置受限的场景下，比如：\n租户使用某些 SaaS 服务对集群进行监控，如 Openshift Operator 部署的 Prometheus； 由于安全或权限问题，监控团队无法在被监控集群中配置 Sidecar； 被监控集群部署的是非容器化部署的 Prometheus。 这是因为 Receiver 会暂存多个 Prometheus 实例的 TSDB，当数据量较大时可能会发生 OOM。另外根据 官方文档，开启远程写入还将增加 Prometheus 约 25% 的内存使用。\n我们并非一定要在 Receiver 和 Sidecar 之间做出抉择，比如 Lastpass 就采用了 Sidecar 与 Receiver 混合部署的方式：\n由于我们的 Demo 优先考虑实现的简单性以及对多租户的支持，对资源占用和性能的要求并不高，因此决定选用 Receiver 模式。\n快速开始 Thanos 版本：v0.24.0 Kubernetes 版本：v1.16.9-aliyun.1 环境：阿里云 ACK 1 2 3 git clone https://github.com/koktlzz/thanos-k8s-deployment.git cd thanos-k8s-deployment kubectl apply -k overlays/aliclound/ 部署 Prometheus 1 2 3 4 5 6 git clone https://github.com/coreos/kube-prometheus.git cd kube-prometheus kubectl create -f manifests/setup # wait for namespaces and CRDs to become available, then kubectl create -f manifests/ 在国内环境拉取 k8s.gcr.io 上的镜像可能会失败，需要将镜像名称改为 bitnami/kube-state-metrics:2.3.0 和 willdockerhub/prometheus-adapter:v0.9.0。\n为 Prometheus 实例配置远程写入 使用kubectl edit -n monitoring prometheus k8s命令开启 Prometheus 的远程写入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # local cluster spec: remoteWrite: - url: http://thanos-receiver.thanos.svc.cluster.local:19291/api/v1/receive # cluster kazusa spec: remoteWrite: - url: http://thanos-receiver.uuid.cn-shanghai.alicontainer.com/api/v1/receive headers: THANOS-TENANT: kazusa # cluster setsuna spec: remoteWrite: - url: http://thanos-receiver.uuid.cn-shanghai.alicontainer.com/api/v1/receive headers: THANOS-TENANT: setsuna 一段时间后将在 Query UI（kubectl get ingresses -n thanos | grep querier）中看到三个集群（租户）的实例：\n架构说明 指标数据流向 如上图所示，监控集群（Local）以及两个外部集群（Kazusa 和 Setsuna）中的 Prometheus 均将指标数据写入到软租户（soft-tenant）的 Receiver 中。而由于 Kazusa 和 Setsuna 的 Prometheus 还在远程写入中配置了 HTTP 头部，因此软租户 Receiver 会根据其中的租户 ID 将其转发到对应的硬租户 Receiver 中。\n我们可以在 Receiver 容器挂载的 Hashring 配置文件中找到每个租户 Receiver 的endpoints：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 [root@master1 thanos]# kubectl exec -n thanos thanos-receiver-default-0 -- cat /etc/prometheus/hashring-config/hashrings.json | jq [ { \"hashring\": \"hashring-setsuna\", \"tenants\": [ \"setsuna\" ], \"endpoints\": [ \"thanos-receiver-setsuna-0.thanos-receiver-setsuna.thanos.svc.cluster.local:10901\" ] }, { \"hashring\": \"hashring-kazusa\", \"tenants\": [ \"kazusa\" ], \"endpoints\": [ \"thanos-receiver-kazusa-0.thanos-receiver-kazusa.thanos.svc.cluster.local:10901\", \"thanos-receiver-kazusa-1.thanos-receiver-kazusa.thanos.svc.cluster.local:10901\", \"thanos-receiver-kazusa-2.thanos-receiver-kazusa.thanos.svc.cluster.local:10901\" ] }, { \"hashring\": \"default\", \"endpoints\": [ \"thanos-receiver-default-0.thanos-receiver-default.thanos.svc.cluster.local:10901\" ] } ] 实际上该文件来自于 Configmapthanos-receiver-hashring-generated-config，它是由 Thanos-Receive-Controller 读取当前集群中的 Receiver 实例并根据 Configmap thanos-receiver-hashring-config 动态生成的。\nReceiver 使用一致性哈希作为数据分发策略的原因详见：Thanos Receiver - why does it need consistent hashing?\nReceiver 的可扩展性和高可用性 假设 Kazusa 集群中的工作负载比较多，其指标数据量也比较大。为了防止接收 Kazusa 集群指标数据的 Receiver 发生 OOM，我们增加其 Statefulset 的 副本数。\n上一节提到，指标数据是软租户 Receiver 根据 Hashring 配置分发到硬租户 Receiver 的。这意味着即使我们将 Kazusa 的 Receiver 扩展到三个，数据也不会在某台 Receiver 宕机后分发到其他可用的 Receiver 中。因此我们还要为数据设置 副本，从而实现高可用。Receiver 的副本包含 receiver_replica 标签，Query 可以根据它来对数据 去重。\n关于 Receiver 的可扩展性和高可用性，详见 Turn It Up to a Million: Ingesting Millions of Metrics with Thanos Receive.\nHeadless Service 我们为每个租户的 Receiver 都创建了各自的 Headless Service，这样 Query 就可以通过 DNS 的 SRV 记录动态发现所有的 Receiver 实例：\n1 2 3 - --store=dnssrv+_grpc._tcp.thanos-receiver-default.thanos.svc.cluster.local - --store=dnssrv+_grpc._tcp.thanos-receiver-kazusa.thanos.svc.cluster.local - --store=dnssrv+_grpc._tcp.thanos-receiver-setsuna.thanos.svc.cluster.local 如果将其改为 ClusterIP 类型，Store API 的 grpc 请求将通过轮询发往其中一台 Receiver 实例。因此，同一时间内只有一台 Kazusa Receiver 可以被 Query 发现：\n值得注意的是，用于处理指标数据的写入请求的 Service 是 ClusterIP 类型的。\nFuture Work 本文介绍的 Demo 仅供读者参考，若想要将其投入生产使用，还需要考虑以下方面：\n为软租户 Receiver 向集群外部暴露的 Ingress 配置 TLS 证书校验； 上文提到，开启远程写入将增加 Prometheus 的内存使用，我们应当根据 Remote Write Tuning 和 How to troubleshoot remote write issues in Prometheus 中的建议对其参数进行调优； 默认情况下，Receiver 每隔两小时向对象存储上传一次 Block，应为其增加持久化以避免数据丢失； 持久化 Compactor 和 Storegateway 的数据目录可以减少其重启时间，存储空间的大小可以参考 Slack 中的 讨论； 部署前根据指标数据量评估 Receiver 的 Request、Limit 以及副本数，防止其因数据量过大而导致 OOM； 此 Demo 使用 Ruler 进行全局告警，可能因查询超时而发生 报警失效。 参考文献 Multi cluster monitoring with Thanos · Banzai Cloud\nThanos Remote Write\nAchieve Multi-tenancy in Monitoring with Prometheus \u0026 Thanos Receiver\nAdopting Thanos at Lastpass\n","description":"","tags":["Prometheus","Thanos"],"title":"使用 Thanos 实现多集群（租户）监控","uri":"/posts/thanos-receiver-deployment-demo/"},{"content":"在计算机的运行过程中，程序计数器依次指向一系列的值：$a_0, a_1, …, a_n$。其中，$a_k$ 是其对应指令 $I_k$ 的地址。从 $a_k$ 到 $a_{k+1}$ 的转换被称为控制转移（Control Transfer），一系列的控制转移则被称为处理器的控制流（Control Flow）。\n最简单的控制流便是程序中的指令按顺序执行，即 $I_k$ 与 $I_{k+1}$ 在内存中相邻。不过，这种“平滑”的控制流通常因指令的跳转、调用和返回而突然改变，此时 $I_k$ 便不再与 $I_{k+1}$ 相邻。\n程序内部的状态是由程序变量表示的，控制流使得程序可以对其更新做出反应。但系统还必须能够应对自身状态的变化，它们无法被内部程序变量捕获，甚至不一定与程序的执行有关。比如，数据包在到达网络适配器后需要被存储到内存中；程序请求磁盘中的数据时需要得知其何时可用；父进程必须在其子进程终止时收到通知等。\n现代系统通过异常控制流（Exceptional Control Flow，ECF）来处理上述情况，它应用于计算机系统的所有级别中。\n异常 异常（Exception）是为了响应处理器状态改变而在控制流中突然发生的变化，其基本思想如下图所示：\n处理器状态的变化被称为事件（Event），它可能与当前指令（$I_{curr}$）的执行直接相关，比如算术溢出或除数为零；也可能与当前指令的执行无关，比如系统计时器关闭或 I/O 请求完成。\n异常处理 异常处理涉及到软件和硬件的密切合作，因此很容易将不同组件执行的工作相混淆。系统中每种可能的异常都对应了一个唯一的非负整数，即异常数字（Exception Number）。当计算机系统启动时，操作系统会初始化一个跳转表，也称异常表（Exception Table）。异常数字是异常表的索引，其中的每个条目 k 均包含了异常 k 的处理程序地址：\n当处理器检测到事件的发生时，首先将确定异常数字，然后根据异常表调用对应的异常处理程序。\n异常与过程调用类似，但也有一些重要区别：\n异常的返回地址要么是当前指令（$I_{curr}$），要么是下一条指令（$I_{next}$）； 处理器还会将一些额外的处理器状态信息压入栈中。当处理程序返回后，这些信息是重启被中断程序所必需的； 异常处理程序在内核态运行，因此可以访问所有系统资源。 异常的分类 中断 中断（Interrupt）异步发生，因为它是由处理器外部的 I/O 设备发出的信号产生的。\n当前指令执行完毕后，处理器注意到中断引脚变高，于是从系统总线读取异常数字，然后调用对应的中断处理程序。当处理程序返回时，它将控制权返回给下一条指令。随后程序继续执行，就好像中断从未发生过一样。\n其余几种异常作为当前指令的执行结果同步发生，我们称之为故障指令（Faulting Instruction）。\n陷阱和系统调用 与中断处理程序一样，陷阱（Trap）处理程序也将控制返回给下一条指令。其最重要的用途是在用户程序和内核之间提供接口，即系统调用（System Call）。\n用户程序通过系统调用向内核请求服务，如读取文件（read）、创建新进程（fork）、加载新程序（execve）和终止当前进程（exit）等。\n在程序员看来，系统调用和常规函数没有什么区别。但常规函数运行在用户态，因此其可执行的指令类型受限，也只能访问用户栈。而系统调用运行在内核态，能够执行特权指令并访问内核栈。\n故障 故障（Faulting）是由一些错误状况引起的异常，而这些错误情况有可能被处理程序修正，否则将返回到内核中的中止例程（图中的“abort”）：\n中止 与故障相比，引发中止（Abort）的错误状况无法挽救。通常是硬件出现问题，如 RAM 位损坏引起的奇偶校验错误。中止处理程序永远不会将控制权返回给应用程序：\nLinux/x86-64 系统中的异常 Exception Number Description Exception Class 0 Divide Error Fault 13 General Protection Fault Fault 14 Page Fault Fault 18 Machine Check Abort 32-255 OS-defined Exception Interrupt or Trap 故障和中止 除法故障（Divide Error）：当应用程序尝试除以 0 或除法指令的结果对目标操作数来说太大时，就会发生除法故障。Unix 不会试图纠正除法故障，而是直接中止程序； 一般保护故障（General Protection Fault）：一般保护故障出现的原因有很多，通常是程序引用了未定义的虚拟内存区域，或试图向只读文本段写入。Linux 不会试图纠正该故障，而 Shell 一般将其报告为分段故障（Segmentation Faults）； 缺页故障（Page Fault）：程序引用不在内存而在磁盘上的虚拟页面会导致缺页故障。处理程序将磁盘上合适的虚拟内存页面映射到物理内存页面，然后重新执行故障指令； 机器检查（Machine Check）：一旦系统在执行指令期间检测到致命的硬件错误，便会发生机器检查。处理程序永远不会将控制权返回给应用程序。 系统调用 上图中的每个系统调用都有一个唯一的数字，对应了内核中跳转表的偏移量。注意，该跳转表与上文提到的异常表不同。\nC 标准库为大多数系统调用提供了一组包装函数（Wrapper Function），它们比直接使用系统调用更加方便。系统调用及其相关的包装函数被统称为系统级函数。举例来说，我们可以使用系统级函数write代替printf：\n1 2 3 4 5 int main() { write(1, \"hello, world\\n\", 13); _exit(0); } X86-64 系统通过syscall指令使用系统调用，其所有参数均通过寄存器传递。按照惯例，寄存器 %rax 保存系统调用编号，寄存器 %rdi、%rsi、%rdx、%r10、%r8 和 %r9 依次保存各参数的值。系统调用的返回值将写入到寄存器 %rax 中，若为负则表示发生了与负errno相关的错误。因此，上面的程序可以直接用汇编语言表示为：\n进程 进程是正在执行的程序的实例，系统中的每个程序都在进程的上下文中运行。上下文由程序正确运行所需的状态组成，包括存储在内存中的程序代码和数据、栈、通用寄存器中的内容、程序计数器、环境变量以及打开 文件描述符 。\n进程为应用提供了两个关键抽象：\n一个独立的逻辑控制流，让我们产生程序独占处理器的错觉； 一个私有的地址空间，让我们产生程序独占内存的错觉。 逻辑控制流 进程轮流使用处理器。每个进程执行其流程的一部分，然后在其他进程执行时被抢占（即暂时挂起）。\n并发流 执行时间重叠的两个逻辑控制流被称为并发流（Concurrent Flow），它们并发运行。如上图 8.12 所示，进程 A 和 进程 B 并发运行，但进程 B 和进程 C 则不是。\n并发流的概念与处理器的核数以及计算机的数量无关，只要两个逻辑控制流在时间上重叠，那么它们便是并发的。如果两个逻辑控制流在不同的处理器内核或计算机上同时运行，我们就称它们为并行流（Parallel Flow）。显然，并行流是并发流的子集。\n私有地址空间 进程为程序提供了独享的私有地址空间，与空间内特定地址相关的内存字节通常不能被其他任何进程读取或写入。尽管私有地址空间的内容不同，但其具有相同的组织结构（图中的“%esp”应为“%rsp”）：\n地址空间底部是为用户程序保留的，代码段总是从地址 0x400000 开始。地址空间顶部是为内核保留的，包含了内核为进程执行指令（如系统调用）时使用的代码、数据和栈。\n用户态和内核态 处理器通过保存在控制寄存器中的模式位（Mode Bit）来识别进程当前享有的特权。当模式位被设置时，进程运行在内核态（Kernel Mode），反之则运行在用户态（User Mode）。在内核态中运行的程序可以执行指令集中的任意指令，并且能够访问系统中的任意位置。而在用户态中运行的程序则受到限制，只能使用系统调用间接地访问内核代码和数据。\n应用程序的进程只能通过异常来从用户态切换到内核态。当异常发生且控制转移到异常处理程序时，处理器切换到内核态。随后异常处理程序在内核态中运行，处理器将在它返回时切换回用户态。\n上下文切换 在进程执行期间，内核可以暂时挂起当前进程并重启先前被抢占的进程，这一行为被称为调度（Scheduling）。内核调度新进程是通过上下文切换（Context Switch）机制来实现的，该机制：\n保存当前进程的上下文； 恢复之前被抢占进程的上下文； 将控制权转移给新进程。 程序执行系统调用时可能会发生上下文切换。比如系统调用read需要访问磁盘中的数据，内核可以通过上下文切换来调度另一个进程，这样就无需等待数据从磁盘加载到内存中。\n系统调用错误处理 当执行 Unix 系统级函数遇到错误时，它们会返回 -1 并设置全局整型变量errno的值。因此我们可以在程序中检查调用是否发生错误，如：\n1 2 3 4 5 if ((pid = fork()) \u003c 0) { fprintf(stderr, \"fork error: %s\\n\", strerror(errno)); exit(0); } 其中，strerror函数会根据errno的值返回相关的文本字符串。我们定义一个错误报告（Error-reporting）函数以简化上述代码：\n1 2 3 4 5 6 7 8 void unix_error(char *msg) /* Unix-style error */ { fprintf(stderr, \"%s: %s\\n\", msg, strerror(errno)); exit(0); } if ((pid = fork()) \u003c 0) unix_error(\"fork error\"); 当然还可以进一步地将代码简化为一个错误处理（Error-handling）函数：\n1 2 3 4 5 6 7 8 9 pid_t Fork(void) { pid_t pid; if ((pid = fork()) \u003c 0) unix_error(\"Fork error\"); return pid; } pid = Fork(); 这样我们便能够使用包装函数Fork代替fork及其错误检查代码。本书使用的包装函数均定义在 csapp.h 和 csapp.c 中。\n进程控制 获取进程 ID 每个进程都有一个唯一且大于 0 的进程 ID（PID）。函数getpid返回调用进程的 PID，而函数getppid则返回创建调用进程的进程（即父进程） 的 PID。\n1 2 3 4 #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e pid_t getpid(void); pid_t getppid(void); 二者返回值的类型均为pid_t，它在 Linux 系统的sys/types.h文件中被定义为int。\n创建和终止进程 在程序员看来，进程有三种状态：\n运行（Running）：该进程要么在 CPU 中执行，要么在等待内核调度； 停止（Stopped）：进程执行暂停，并且不会被调度； 终止（Terminated）：进程永久地停止。 函数exit会以参数status作为退出状态终止进程：\n1 2 #include \u003cstdlib.h\u003e void exit(int status); 父进程可以调用fork函数来创建一个新的子进程：\n1 2 3 #include \u003csys/types.h\u003e #include \u003cunistd.h\u003e pid_t fork(void); 子进程将获得一个与父进程相同但独立的用户级虚拟内存空间副本，包括代码、数据、堆、共享库和用户栈等。它还会得到与父进程相同的打开文件描述符副本，因此能够读写任意父进程打开的文件。父进程和子进程之间最显著的区别便是 PID 不同。\n函数fork执行一次却返回两次：在父进程中返回子进程的 PID，在子进程中返回 0。由于子进程的 PID 始终大于 0 ，我们可以通过返回值判断程序在哪个进程中执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #include \"csapp.h\" int main() { pid_t pid; int x = 1; pid = Fork(); if (pid == 0) { /* Child */ printf(\"child : x=%d\\n\", ++x); exit(0); } /* Parent */ printf(\"parent: x=%d\\n\", --x); exit(0); } 该程序编译后运行的可能结果为：\n1 2 3 linux\u003e ./fork parent: x=0 child : x=2 从结果我们可以看出：父进程和子进程并发执行，我们永远无法预测其执行顺序；子进程的地址空间是父进程的副本，因此当第六行的函数Fork返回时，两进程中的局部变量x均为 1；两进程对变量的更改互不影响，所以最终输出的值不同。\n绘制进程图（Process Graph）对理解fork函数很有帮助，如：\n回收子进程 进程终止后，内核不会立即将其移除。它需要被其父进程回收（Reap），否则将成为僵尸（Zombie）进程。当父进程回收其终止的子进程时，内核将子进程的退出状态传递给父进程，然后再丢弃它。\n如果父进程终止，内核会安排init进程（PID 为 1）“收养”孤儿进程；如果父进程在终止前没有回收僵尸子进程，那么则由init进程回收它们。\n进程通过调用函数waitpid等待其子进程终止或停止：\n1 2 3 4 #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e pid_t waitpid(pid_t pid, int *statusp, int options); // Returns: PID of child if OK, 0 (if WNOHANG), or −1 on error 默认情况下（参数options为 0 时），函数waitpid会暂停调用进程，直至其等待集（Wait Set）中的某个子进程终止。该函数始终返回第一个终止的子进程 PID。此时，终止的子进程已被回收，内核从系统中删除了它的所有痕迹。\n若参数pid_t大于 0 ，则等待集中只有一个 PID 与该参数相等的子进程。若参数pid_t等于 -1，则等待集包含调用进程的所有子进程。\n我们可以通过修改参数options的值来改变函数waitpid的行为：\nWNOHANG：如果等待集中的子进程还未终止，则立即返回 0； WUNTRACED：暂停调用进程执行，直到等待集中的进程终止或停止（默认情况下仅返回终止的子进程 PID）； WCONTINUED：暂停调用进程执行，直到等待集中的进程终止或等待集中停止的进程收到 SIGCONT 信号恢复。 若参数statusp不为NULL，那么waitpid还会将返回的子进程状态信息编码到status中（*statusp = status）。wait.h文件定义了几个用于解释参数status的宏：\nWIFEXITED(status)：如果子进程正常终止（比如调用exit或返回），则返回True； WEXITSTATUS(status)：如果WIFEXITED()返回True，则返回终止子进程的退出状态； WIFSIGNALED(status)：如果子进程由于未捕获的信号而终止，则返回True； WTERMSIG(status)：如果WIFSIGNALED()返回True，则返回导致子进程终止的信号编号； WIFSTOPPED(status)：如果返回的子进程当前已停止，则返回True； WSTOPSIG(status)：如果WIFSTOPPED()返回True，则返回导致子进程停止的信号编号； WIFCONTINUED(status)：如果子进程收到 SIGCONT 信号后恢复，则返回True。 如果调用进程没有子进程，waitpid将返回 -1 并将全局变量errno设为ECHILD；如果waitpid被信号中断，则返回 -1 并将全局变量errno设为EINTR。\n函数wait是waitpid的简化版本，wait(\u0026status)等效于waitpid(-1, \u0026status, 0)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 #include \"csapp.h\" #define N 2 int main() { int status, i; pid_t pid; /* Parent creates N children */ for (i = 0; i \u003c N; i++) if ((pid = Fork()) == 0) /* child */ exit(100 + i); /* Parent reaps N children in no particular order */ while ((pid = waitpid(-1, \u0026status, 0)) \u003e 0) { if (WIFEXITED(status)) printf(\"child %d terminated normally with exit status=%d\\n\", pid, WEXITSTATUS(status)); else printf(\"child %d terminated abnormally\\n\", pid); } /* The only normal termination is if there are no more children */ if (errno != ECHILD) unix_error(\"waitpid error\"); exit(0); } 如示例程序所示，父进程首先调用Fork创建了两个退出状态唯一的子进程（exit(100+i)）。 随后在 While 循环的测试条件中通过waitpid等待其所有的子进程终止，并打印子进程的退出状态。最终所有的子进程均被回收，waitpid返回 -1 且将全局变量errno设为ECHILD，函数执行完毕。\n在 Linux 系统上运行该程序时，它会产生以下输出：\n1 2 3 linux\u003e ./waitpid1 child 22966 terminated normally with exit status=100 child 22967 terminated normally with exit status=101 值得注意的是，父进程回收子进程的顺序是随机的。我们可以对上述程序进行一定 修改，从而使其按子进程的 PID 顺序输出。\n让进程休眠 函数sleep可以让进程暂停执行一段时间：\n1 2 3 #include \u003cunistd.h\u003e unsigned int sleep(unsigned int secs); // Returns: seconds left to sleep 如果请求的暂停时间已经过去，则函数返回 0；如果该进程被信号中断，则返回剩余的暂停时间。\n函数pause会使调用进程进入休眠状态，直至收到信号。该函数始终返回 -1:\n1 2 #include \u003cunistd.h\u003e int pause(void); 加载并运行程序 函数execve在当前进程的上下文中加载并运行一个新程序：\n1 2 #include \u003cunistd.h\u003e int execve(const char *filename, const char *argv[], const char *envp[]); 参数filename是加载并运行的可执行文件名称，argv和envp则分别是参数和环境变量列表。函数execve通常没有返回值，仅在出现错误时返回 -1。\n变量argv指向一个以NULL为结尾的指针数组，其中的每个元素都指向一个参数字符串。一般来说，argv[0]是可执行目标文件名称；变量envp也指向一个以NULL结尾的指针数组，其中的每个元素均指向一个环境变量字符串，每个字符串都是一个name=value形式的键值对。两者的数据结构如下：\nexecve加载文件名后，会调用启动代码。 启动代码设置栈并将控制权传递给新程序的main函数，其原型为：\n1 int main(int argc, char *argv[], char *envp[]); main函数执行时的用户栈结构如下图所示，从栈底到栈顶分别是：环境变量字符串、参数字符串、指向环境变量字符串的指针数组和指向参数字符串的指针数组。该函数的三个参数分别保存在不同的寄存器中：参数argc给出数组argv[]中的非空指针数量；参数argv指向数组argv[]中第一个元素；参数envp则指向数组envp[]中的第一个元素：\nLinux 提供了几个用于操作环境变量数组的函数：\n1 2 3 4 #include \u003cstdlib.h\u003e char *getenv(const char *name); int setenv(const char *name, const char *newvalue, int overwrite); void unsetenv(const char *name); 如果数组中包含以参数name为键的字符串，则函数getenv返回其对应的值，函数unsetenv删除该字符串，函数setenv将值替换为参数newvalue（overwrite非零时）；如果不存在以name为键的字符串，则函数setenv会将name=newvalue添加到数组中。\n使用 fork 和 execve 运行程序 Unix shell 和 Web 服务器等程序大量使用了fork和execve函数。本书提供了一个简单的 shell 程序，其缺陷在于没有回收任何后台运行的子进程。我们需要使用下一节介绍的信号来解决这一问题。\n信号 信号（Signal）是一种高级的异常控制流，它允许进程和内核将某些类型的系统事件通知给其他进程。Linux 支持的信号类型多达三十种：\n低级别的硬件异常由内核中的异常处理程序处理，通常不会对用户进程可见，而信号则可以将此类异常暴露给用户进程。如果一个进程试图除以 0，内核就会向它发送一个 SIGFPE（编号 8）信号。\n信号术语 发送信号到目标进程需要完成两个步骤：\n发送（传递）信号：内核通过更新目标进程上下文中的某些状态来向目标进程发送信号。发送信号的原因有两种：① 内核检测到系统事件的发生，如被 0 除错误或子进程终止等；② 进程调用了kill函数（将在下一节介绍）。进程可以向自己发送信号； 接收信号：当内核强制目标进程以某种方式对信号做出响应时，它便接收到了信号。该进程可以通过执行用户级别的信号处理程序（Signal Handler）来忽略、终止或捕获信号。 已发送但还未接收的信号被称为待处理信号（Pending Signal）。在任意时间点，相同类型的待处理信号最多只能有一个。这意味着如果一个进程已经有一个类型为 k 的待处理信号，那么后续所有发送给该进程的 k 类型信号都将被丢弃。进程还可以选择性地阻塞（Block）某些信号的接收。\n发送信号 进程组 每个进程都属于一个进程组（Process Group），它由一个正整数的进程组 ID 所标识。getpgrp函数返回当前进程的进程组 ID：\n1 2 #include \u003cunistd.h\u003e pid_t getpgrp(void); 默认情况下，子进程与其父进程属于同一个进程组。进程可以通过setpgid函数改变自己或另一个进程的进程组：\n1 2 #include \u003cunistd.h\u003e int setpgid(pid_t pid, pid_t pgid); 该函数会把进程pid的进程组更改为pgid。若将参数pid或pgid设为 0，则相当于使用调用进程的 PID 作为参数。举例来说，如果进程 15213 调用函数setpgid(0, 0)，那么将会创建一个进程组 ID 为 15213 的新进程组，并使该进程加入此组。\n从键盘发送信号 Unix Shell 使用任务（Job）表示单个命令行（如ls | sort）创建的进程，同一时间内只能有一个前台任务和多个后台任务。\n在键盘上输入 Ctrl+C 会使内核向前台进程组中的所有进程发送 SIGINT 信号，这将终止前台任务。同样，输入 Ctrl+Z 会使内核向前台进程组中的所有进程发送 SIGTSTP 信号，这将停止（挂起）前台任务。\n使用 kill 函数发送信号 进程可以调用kill函数向其他进程（包括其自身）发送信号：\n1 2 3 4 #include \u003csys/types.h\u003e #include \u003csignal.h\u003e int kill(pid_t pid, int sig); // Returns: 0 if OK, −1 on error 若参数pid大于 0，则该函数将编号为sig的信号发送给进程pid；若参数pid等于 0，则该函数将信号发送给调用进程所在进程组中的所有进程；如果参数pid小于 0，则该函数将信号发送给进程组 ID 为|pid|的进程组中的所有进程。\n使用 alarm 函数发送信号 进程可以调用alarm函数向自己发送 SIGALRM 信号：\n1 2 3 #include \u003cunistd.h\u003e unsigned int alarm(unsigned int secs); // Returns: remaining seconds of previous alarm, or 0 if no previous alarm 内核将在secs秒后向调用进程发送 SIGALRM 信号，取消所有之前设置的alarm，并返回其剩余的秒数。\n接收信号 当内核将进程 p 从内核态切换到用户态时，它会检查 p 未阻塞且未处理（Pending \u0026 ~Blocked）的信号集。通常该集合为空，内核将控制权转移给 p 的逻辑控制流中的下一条指令。但如果该集合非空，内核就会选择信号集中的某个信号 k 并强制 p 接收它。信号将触发进程完成一些动作（Action），预定义的默认动作有：\n进程终止； 进程终止并转储核心（Dump Core，即将代码和数据内存段的镜像写入磁盘）； 进程停止（暂停），直到接收 SIGCONT 信号重新启动； 进程忽略该信号。 每种信号的默认动作见 图 8.26。除 SIGSTOP 和 SIGKILL 信号外，进程还可以通过函数signal修改信号的默认动作：\n1 2 3 4 #include \u003csignal.h\u003e typedef void (*sighandler_t)(int); sighandler_t signal(int signum, sighandler_t handler); // Returns: pointer to previous handler if OK, SIG_ERR on error (does not set errno) 若参数handler为SIG_IGN，则signum类型的信号将会被忽略；若参数handler为SIG_DFL，则signum类型的信号的动作将恢复为默认；若参数handler为用户定义的信号处理程序地址，则进程接收到signum类型的信号后会调用该程序，这种方法被称为安装处理程序（Installing Handler）。在这种情况下，调用处理程序被称为捕获信号（Catching Signal），执行处理程序被称为处理信号（Handling Signal）。\n如果我们在示例程序运行时按下 Ctrl+C，该进程就不会直接终止而是输出一段信息后才终止：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #include \"csapp.h\" void handler(int sig) /* SIGINT handler */ { printf(\"Caught SIGINT\\n\"); exit(0); } int main() { /* Install the SIGINT handler */ if (signal(SIGINT, handler) == SIG_ERR) unix_error(\"signal error\"); Pause(); /* Wait for the receipt of a signal */ exit(0); } 信号处理程序还可以被其他处理程序中断（信号 $s \\ne t$）：\n阻塞信号 Linux 为阻塞信号提供了显式和隐式的实现机制：\n隐式：默认情况下，内核会阻塞任何与处理程序当前正在处理的信号类型相同的未处理信号。比如上图 8.31 中，若信号 $t$ 的类型与 $s$ 相同，则 $t$ 将在处理程序 $S$ 返回前持续挂起； 显式：应用程序可以调用sigprocmask等函数阻塞信号或解除信号的阻塞。 1 2 3 4 5 6 7 8 9 10 #include \u003csignal.h\u003e int sigprocmask(int how, const sigset_t *set, sigset_t *oldset); int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); int sigaddset(sigset_t *set, int signum); int sigdelset(sigset_t *set, int signum); // Returns: 0 if OK, −1 on error int sigismember(const sigset_t *set, int signum); // Returns: 1 if member, 0 if not, −1 on error sigprocmask函数可以改变当前阻塞信号的集合（设为blocked），具体行为取决于参数how的值：\nSIG_BLOCK：将参数set中的信号阻塞（blocked = blocked | set）； SIG_UNBLOCK：为set中的信号解除阻塞（blocked = blocked \u0026 ~set）； SIG_SETMASK：将阻塞信号集合设为set（blocked = set）。 如果参数oldset非空，则先前blocked的值会存储在oldset中。\n除此之外，函数sigemptyset将set初始化为空集；sigfillset将所有信号加入到set中；sigaddset将编号为signum的信号加入到set中；sigdelset将编号为signum的信号从set中删除；如果signum信号在set中，则函数sigismember返回 1，否则返回 0。\n示例程序暂时阻塞了 SIGINT 信号的接收：\n1 2 3 4 5 6 7 8 9 10 sigset_t mask, prev_mask; sigemptyset(\u0026mask); sigaddset(\u0026mask, SIGINT); /* Block SIGINT and save previous blocked set */ sigprocmask(SIG_BLOCK, \u0026mask, \u0026prev_mask); // Code region that will not be interrupted by SIGINT /* Restore previous blocked set, unblocking SIGINT */ sigprocmask(SIG_SETMASK, \u0026prev_mask, NULL); 编写信号处理程序 安全的信号处理 如果处理程序和主程序并发地访问同一个全局数据结构，就会发生不可预知的严重问题。因此我们在编写信号处理程序时应当遵循以下守则：\n使信号处理程序尽可能的简单； 仅调用异步信号安全（Async-Signal-Safe）的函数。这种函数一般只访问局部变量，或者不会被其他信号处理程序中断。值得注意的是，许多常用的函数，如printf、sprintf、malloc和exit等并非异步信号安全。调用write函数是信号处理程序生成输出的唯一安全方法； 保存并恢复变量errno：许多 Linux 异步信号安全函数返回错误时会设置变量errno的值，因此可能会干扰程序中其他依赖errno的部分。当处理程序有返回时，我们应当在调用前将errno保存到局部变量中，并在返回前恢复其值； 访问全局数据结构时阻塞所有信号； 假设主程序和信号处理程序共享全局变量g，处理程序更新g的值，主程序定期读取g的值。优化的编译器会从寄存器中读取已缓存的g，因此主函数中的g可能永远不变，并且每次对g的引用也都是安全的。若使用volatile声明全局变量，如volatile int g;，那么当代码引用g时，编译器就会从内存中读取其值。在这种情况下，我们应当临时阻塞信号以保护对g的访问； 在常见的设计中，处理程序通过写入全局标识（Flag）来记录信号的接收。若使用sig_atomic_t类型声明标识，如volatile sig_atomic_t flag;，那么便可以保证flag写入的原子性（Atomic/Uninterruptible）。 正确的信号处理 上文提到，父进程必须回收子进程以避免在系统中留下僵尸进程，但我们也希望父进程可以在子进程运行时自由地执行其他任务。因此我们使用 SIGCHILD 处理程序来回收子进程，而不是显式地调用waitpid等待子进程终止：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 #include \"csapp.h\" void handler1(int sig) { pid_t pid; if ((pid = waitpid(-1, NULL, 0)) \u003c 0) unix_error(\"waitpid error\"); printf(\"Handler reaped child %d\\n\", (int)pid); Sleep(2); return; } int main() { int i, n; char buf[MAXBUF]; if (signal(SIGCHLD, handler1) == SIG_ERR) unix_error(\"signal error\"); /* Parent creates children */ for (i = 0; i \u003c 3; i++) { if (Fork() == 0) { fprintf(\"Hello from child %d\\n\", (int)getpid()); Sleep(1); exit(0); } } /* Parent waits for terminal input and then processes it */ if ((n = read(STDIN_FILENO, buf, sizeof(buf))) \u003c 0) unix_error(\"read\"); printf(\"Parent processing input\\n\"); while (1) ; exit(0); } 示例程序中，父进程安装了处理程序handler1并创建三个子进程。它等待来自终端的输入，然后进入 While 循环。每当一个子进程终止时，内核将发送一个 SIGCHLD 信号通知父进程。父进程捕获信号后回收子进程，输出一段信息然后返回。\n在 Linux 上运行该程序得到的输出结果为：\n1 2 3 4 5 6 7 8 linux\u003e ./signal1 Hello from child 14073 Hello from child 14074 Hello from child 14075 Handler reaped child Handler reaped child CR Parent processing input 父进程创建了三个子进程，然而却只回收了两个，这是因为同一时间内相同类型的未处理信号最多只能有一个。信号处理程序在处理第一个信号时，第二个信号到达并被添加到未处理信号集中。由于已有一个未处理的 SIGCHLD 信号，此时若第三个信号到达便会被直接丢弃。当处理程序返回后，内核发现第二个信号还未处理，于是强制父进程接收该信号并重新执行处理程序。等到处理程序再次返回，父进程就不再有任何未处理的 SIGCHLD 信号了。\n我们可以让处理程序在被调用时尽可能多地回收子进程以解决这一问题：\n1 2 3 4 5 6 7 8 9 10 11 void handler2(int sig) { pid_t pid; while ((pid = waitpid(-1, NULL, WNOHANG)) \u003e 0) printf(\"Handler reaped child %d\\n\", (int)pid); if (errno != ECHILD) unix_error(\"waitpid error\"); Sleep(2); return; } 可移植的信号处理 不同的系统有着不同的信号处理语义，因此 Posix 标准定义了sigaction函数，它允许用户在安装信号处理程序时明确地指定他们想要的语义：\n1 2 3 4 #include \u003csignal.h\u003e int sigaction(int signum, struct sigaction *act, struct sigaction *oldact); // Returns: 0 if OK, −1 on error 然而sigaction函数十分笨重，因此我们常使用它的包装函数Signal：\n1 2 3 4 5 6 7 8 9 10 11 handler_t *Signal(int signum, handler_t *handler) { struct sigaction action, old_action; action.sa_handler = handler; sigemptyset(\u0026action.sa_mask); /* Block sigs of type being handled */ action.sa_flags = SA_RESTART; /* Restart syscalls if possible */ if (sigaction(signum, \u0026action, \u0026old_action) \u003c 0) unix_error(\"Signal error\"); return (old_action.sa_handler); } 避免并发错误 上文提到，我们永远无法预测两个同步（并发）运行的函数的调用顺序。如果调用顺序会影响结果的正确性，那么这种错误就被称为竞争（Race）。我们可以通过阻塞相关信号来避免这一问题。\n显式等待信号 有时候主程序需要显式等待某个信号处理程序运行完毕。例如 Linux Shell 创建前台任务后，必须等待任务终止并被 SIGCHLD 处理程序回收，然后才能接收下一条用户命令。示例程序展示了其基本思想：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #include \"csapp.h\" volatile sig_atomic_t pid; void sigchld_handler(int s) { int olderrno = errno; pid = waitpid(-1, NULL, 0); errno = olderrno; } void sigint_handler(int s) { } int main(int argc, char **argv) { sigset_t mask, prev; Signal(SIGCHLD, sigchld_handler); Signal(SIGINT, sigint_handler); Sigemptyset(\u0026mask); Sigaddset(\u0026mask, SIGCHLD); while (1) { Sigprocmask(SIG_BLOCK, \u0026mask, \u0026prev); /* Block SIGCHLD */ if (Fork() == 0) /* Child */ exit(0); /* Parent */ pid = 0; Sigprocmask(SIG_SETMASK, \u0026prev, NULL); /* Unblock SIGCHLD */ /* Wait for SIGCHLD to be received (wasteful) */ while (!pid) ; /* Do some work after receiving SIGCHLD */ printf(\".\"); } exit(0); } 父进程先为信号 SIGCHLD 和 SIGINT 安装处理程序，然后创建子进程并将全局变量pid设为 0，最后进入自旋循环（while (!pid)）。子进程终止后，pid变为非 0，于是父进程退出自旋循环。为了防止父进程进入自旋循环前接收到 SIGCHLD ，我们需要在创建子进程之前阻塞该信号。\n这段代码是正确的，但自旋循环会浪费处理器资源。我们可以将其改为：\n1 2 while (!pid) /* Race! */ pause(); 问题在于：如果父进程在 While 的条件测试之后而pause的执行之前接收到 SIGCHLD，那么程序就会永远休眠。我们还可以将pause改为sleep：\n1 2 while (!pid) /* Too slow! */ sleep(1); 这样虽然避免了竞争问题，但会增加程序的运行时间。正确的解决方案是调用函数sigsuspend：\n1 2 3 #include \u003csignal.h\u003e int sigsuspend(const sigset_t *mask); // Returns: -1 该函数使用参数mask替换当前的阻塞信号集合，然后暂停进程直至其接收信号。如果该信号的动作是终止进程，则进程终止且不从sigsuspend返回；如果该信号的动作是运行一个处理程序，则sigsuspend在处理程序返回后返回，并将阻塞信号集合的状态恢复。\n实际上它等效于下列函数组合的原子性（Atomic，即不可中断）版本：\n1 2 3 sigprocmask(SIG_SETMASK, \u0026mask, \u0026prev); pause(); sigprocmask(SIG_SETMASK, \u0026prev, NULL); 因此我们可以将示例函数修改为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 while (1) { Sigprocmask(SIG_BLOCK, \u0026mask, \u0026prev); /* Block SIGCHLD */ if (Fork() == 0) /* Child */ exit(0); /* Wait for SIGCHLD to be received */ pid = 0; while (!pid) sigsuspend(\u0026prev); /* Optionally unblock SIGCHLD */ Sigprocmask(SIG_SETMASK, \u0026prev, NULL); /* Do some work after receiving SIGCHLD */ printf(\".\"); } 非本地跳转 C 提供了一种用户级别的异常控制流，即非本地跳转（Nonlocal Jump）。它无需完成正常的调用/返回序列，就可以将控制权从一个函数直接转移到另一个当前正在执行的函数。非本地跳转是通过setjmp和longjmp函数实现的：\n1 2 3 4 5 6 7 8 #include \u003csetjmp.h\u003e int setjmp(jmp_buf env); int sigsetjmp(sigjmp_buf env, int savesigs); // Returns: 0 from setjmp, nonzero from longjmps void longjmp(jmp_buf env, int retval); void siglongjmp(sigjmp_buf env, int retval); // Never returns setjmp函数将当前调用环境（Calling Environment，包括程序计数器、栈指针和通用寄存器等），保存在参数env指定的缓冲区中并返回 0。longjmp函数会从env缓冲区恢复调用环境，然后触发最近调用的setjmp函数的返回。这种情况下，setjmp会返回一个非零值retval。在信号处理程序中，我们使用sigsetjmp和siglongjmp代替它们。\n非局部跳转的一个重要应用是可以在检测到某些错误条件时，从深度嵌套的函数调用中立即返回。我们使用非本地跳转直接返回到常见的错误处理程序，无需费力地展开栈（Unwind Stack）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #include \"csapp.h\" jmp_buf buf; int error1 = 0; int error2 = 1; void foo(void), bar(void); int main() { switch (setjmp(buf)) { case 0: foo(); break; case 1: printf(\"Detected an error1 condition in foo\\n\"); break; case 2: printf(\"Detected an error2 condition in foo\\n\"); break; default: printf(\"Unknown error condition in foo\\n\"); } exit(0); } /* Deeply nested function foo */ void foo(void) { if (error1) longjmp(buf, 1); bar(); } void bar(void) { if (error2) longjmp(buf, 2); } 示例程序中主函数首先调用setjmp保存当前调用环境，然后依次调用函数foo和bar。 一旦函数执行发生错误，它们会立即通过longjmp从setjmp返回。setjmp的非零返回值表示错误的类型，因此我们可以在代码中的某处对其进行处理。\n非局部跳转的另一个重要应用是从信号处理程序跳转到特定代码位置，而不是像往常那样返回到因信号中断的指令。\n","description":"","tags":["OS"],"title":"CSAPP 读书笔记：异常控制流","uri":"/posts/exception-control-flow-note/"},{"content":"存储系统（Memory System）包含多个层级（Hierarchy），每个层级的存储设备（Storage Device）具有不同的容量、成本和访问速度。层级越低，存储设备的容量就越大，成本也越低，但访问速度却越慢。存储系统的层级结构对应用性能有着显著的影响，其中最为重要的便是 CPU 与主存储器之间的高速缓存。\n存储技术 随机存取存储器 随机存取存储器（Random Access Memory，RAM）有两种，分别是静态（Static）的 SRAM 和 动态（Dynamic）的 DRAM。其中，SRAM 的访问速度比 DRAM 更快，不过其成本明显更高。SRAM 用于 CPU 芯片内外的缓存，而 DRAM 则用于主存储器和图形系统中的帧缓存（Frame Buffer）。\nSRAM SRAM 将每个位存储在一个双稳态（Bistable）的存储单元中，每个单元是由一个六晶体管电路实现的，其结构类似于下图中的倒转摆锤：\n该电路将永远处于两种电压配置（状态）之一。任何其他的状态都是不稳定的，将会快速地朝向其中一个稳定的状态移动。因此只要 SRAM 通电，就会永久地保存其值而不受一些扰动（如电噪声）的影响。\nDRAM DRAM 将每一位存储为一个电容上的电荷，其存储单元对任何扰动都十分敏感。电流泄露会导致 DRAM 单元在大约 10 到 100 毫秒的时间内失去电荷，因此存储系统必须定期地通过读取并重写来刷新其中的每一位。\n传统的 DRAM DRAM 芯片上的位可以被划分为 $d$ 个超级单元（Supercell），每个超级单元包含 $w$ 个 DRAM 单元，因此一个 $d \\times w$ 的 DRAM 能够存储 $dw$ 位的信息。下图展示了一个 16 $\\times$ 8 的 DRAM 芯片结构：\n16 个超级单元被排列成一个 4 $\\times$ 4 的矩阵，图中标为阴影的超级单元地址为 (2, 1)。信息通过外部连接器（也称 Pin）流入或流出芯片，每个 Pin 都可以携带一位信号。上图中包含了八个传输信息的dataPin，以及两个携带超级单元地址的addrPin。\n每个 DRAM 芯片都连接了一个被称为存储控制器（Memory Controller）的电路，它可以一次传输 $w$ 位的数据。为了读取超级单元 (i, j) 中的内容，存储控制器会向 DRAM 发送行地址 i 和 列地址 j 的寻址请求，分别被称为 RAS（Row Access Strobe）请求和 CAS（Column Access Strobe）请求。详细的读取过程如下图所示：\n存储控制器首先发送行地址请求，DRAM 会将整个第 2 行拷贝到内部的行缓冲区（图中的“Internal Row Buffer”）中。然后存储控制器再发送列地址请求，DRAM 将从行缓冲区中拷贝超级单元 (2, 1) 的值返回给存储控制器。\n只要对存储控制器读取 DRAM 的过程有所了解，我们就能明白超级单元的排列方式为什么是矩阵而非一维线性数组。在我们的例子中，DRAM 包含了 16 个超级单元。如果按一维数组排列，则超级单元的地址范围为 0 到 15，因此就需要四个 Pin（即四位）来进行寻址。当然，矩阵排列方式也有一定缺点。存储控制器读取超级单元需要分为两个步骤，从而增加了访问时间。\n存储模块 DRAM 芯片被封装在存储模块（Memory Modules）中，如下图所示：\n示例的存储模块包含 8 个 8M $\\times$ 8 DRAM 芯片，能够存储 64 MB 的数据。每个超级单元存储主存储器中的一字节（八位）信息，八个超级单元就可以表示一个地址为“A”的 64 位 Word。存储控制器首先将地址“A”转换为超级单元地址 (i, j)，然后将其发送到存储模块中。存储模块会向所有的 DRAM 广播地址 i 和 j，从而得到每个 DRAM 中超级单元 (i, j) 的内容。存储模块中的电路会将结果整合为一个 64 位的 Word，最终返回给存储控制器。\n改进的 DRAM 我们可以对传统的 DRAM 进行优化以提升其访问速度：\nFPM（Fast Page Mode）DRAM：传统 DRAM 将整行数据拷贝到缓冲区中，使用其中一个并丢弃剩余的超级单元。FPM DRAM 可以连续访问同一行的超级单元，因此速度更快。例如读取一行中的四个超级单元，传统 DRAM 需要发送四次 RAS 请求和四次 CAS 请求，而 FPM DRAM 则只需要一次 RAS 请求和四次 CAS 请求； EDO（Extended Data Out） DRAM：通过减少发送 CAS 信号的时间间隔来对 FPM DRAM 进行优化； SDRAM（Synchronous DRAM）：上文提及的所有 DRAM 都是异步（Asynchronous）地向存储控制器发送信号的，因此同步的 SDRAM 传输数据的速率更快； DDDR（Double Data-Rate Synchronous）DRAM：使用时钟边缘（Clock Edge）作为控制信号来将 SDRAM 的速度提升一倍； VRAM（Video RAM）：常用于图形系统的帧缓存，其本质与 FPM DRAM 类似。区别在于 VRAM 通过依次对内部缓冲区的内容移位来输出数据，并且可以并行地读写内存。 非易失性存储器 非易失性存储器（Nonvolatile Memory）在断电后还会继续保留其存储的信息。即使有些非易失性存储器是可读写的，但由于历史原因，它们被统一称为 ROM（Read-only Memory）。不同种类 ROM 的区别在于其能够被重新编程（写入）的最大次数，以及写入的实现机制。\nPROM（Programmable ROM）：只能被编程一次； EPROM（Erasable programmable ROM）：可以被擦除和重新编程约 1000 次； EEPROM（Electrically Erasable PROM）：与 EPROM 相比，不需要单独的物理编程设备，但只可以重新编程 105 次； 闪存（Flash Memory）：基于 EEPROM 的一项重要存储技术，SSD 就是通过闪存实现的。 存储在 ROM 中的程序通常称为固件（Firmware）。一些系统会在固件中提供简单的输入/输出功能，比如 PC 的 BIOS（Basic Input/Output System）。\n访问主存储器 数据通过共享的电气管道在 CPU 和 DRAM 主存储器之间流动，这些管道被称为总线（Bus）。数据传输的过程由一系列的总线事务（Bus Transaction）组成，其中读事务将数据从主存加载到 CPU 中，写事务则将数据从 CPU 传输到主存中。\n总线是一组可以传输地址、数据和控制信号的并行线的集合，其中控制总线负责同步事务并识别当前正在执行事务的类型。下图展示了计算机系统中的总线结构：\n图中的“I/O Bridge”是一组芯片的集合，包含了上文中提到的存储控制器。它会将系统总线（图中的“System bus”）的电信号转换为存储器总线（图中的“Memory bus”）的电信号，反之亦然。当 CPU 执行数据读取指令时，其芯片上的总线接口（Bus Interface）电路会在总线上初始化一个读事务，过程如下：\n写事务的过程与之类似：\n磁盘存储 磁盘（Disk）是主力存储设备，可以容纳成百上千 GB 的数据，但其读写速度却远远低于 RAM。本节中的磁盘主要指的是旋转磁盘，并不涉及 SSD。\n磁盘构造 磁盘是由盘片（Platter）组成的，每个盘片都有两个盘面（Surface）。下图 6.9(a) 展示了一个典型盘面的结构：\n每个盘面均由一组被称为磁道（Track）的同心环构成，每条磁道又可以被划分为多个扇区（Section）。每个扇区中都存储了数量相同的数据位（通常为 512 字节），它们之间的间隙（Gap）则只保存扇区的标识。\n如上图 6.9(b) 所示，柱面（Cylinder）是所有盘面上与主轴（Spindle）等距的磁道的集合。\n磁盘容量 磁盘的容量由以下三个参数决定：\n记录密度（$bits/in$）：一英寸长度的磁道中存储的位数； 轨道密度（$tracks/in$）：从主轴中心处延伸一英寸半径内的磁道数量； 面密度（$bits/in^2$）：记录密度和轨道密度的乘积。 在以前的磁盘中，每条磁道上的扇区数量是相同的。这样当面密度上升之后，间隙就会越来越大，从而造成浪费。因此现代大容量磁盘使用多区记录（Multiple Zone Recording）技术，令外部磁道包含的扇区数量大于内部磁道。\n磁盘操作 磁盘使用连接在传动臂（Actuator Arm）末端的读/写头来进行读写操作：\n传动臂沿自身旋转轴不断移动，可以将读/写头定位到任意磁道上，这一操作被称为寻道（Seek）。如上图 6.10(b) 所示，拥有多个盘片的磁盘的每个磁面都有其对应的读/写头。不过在任何时刻，所有的读/写头均处在相同的柱面上。传动臂的移动速度非常快，即使是微小的灰尘也会干扰到读/写头的寻道，因此磁盘需要被密封包装。\n磁盘以扇区大小的块为单元进行读写，其访问时间受三个主要因素的影响：\n寻道时间：即移动传动臂所需的时间； 旋转延时：当读/写头定位到目标磁道上时，磁盘还需要将目标扇区的首个位旋转到读/写头下，所需的时间被称为旋转延时； 传输时间：磁盘读写目标扇区内容所需的时间，由磁盘旋转速度和每条磁道中的扇区数量所决定。 相比其他两个因素，传输时间小到可以忽略。而寻道时间和旋转延时大致相等，因此可以用两倍的寻道时间来估算磁盘的访问时间。\n磁盘的逻辑块 为了向操作系统隐藏磁盘构造的复杂性，现代磁盘将自身简化为一个由 B 个逻辑块组成的序列。每个逻辑块的尺寸与扇区大小相同，编号为 0，1，… ，B - 1。磁盘控制器（Disk Controller）负责维护逻辑块编号与实际物理磁盘扇区之间的映射关系，它会将操作系统读取的目标逻辑块编号转换为唯一标识物理扇区的三元组（磁面，磁道和扇区）。读取到的信息将首先保存在磁盘控制器的缓冲区中，然后再拷贝到主存。\n连接的 I/O 设备 显卡、显示器、鼠标、键盘和磁盘等输入/输出 (I/O) 设备使用 I/O 总线连接到 CPU 和主存储器上：\n访问磁盘 CPU 从磁盘中读取数据的过程如下：\nCPU 使用 Memory-mapped I/O 技术向 I/O 设备发送指令，如上图中 (a) 所示。系统会在地址空间中保留一块地址区用于与 I/O 设备的通信，其中的地址被称为 I/O Port。每个连接到总线上的设备都会被映射到一个或多个 I/O Port。\nCPU 将发送三个指令到目标 I/O Port 来初始化读取操作：\n告知磁盘启动读取的命令 目标数据所在逻辑块的编号 数据存储的主存地址 在发出请求之后，CPU 通常会在磁盘读取时进行其他工作。如上图中 (b) 所示，设备自行执行读写总线事务，无需 CPU 的参与，这一过程被称为 DMA（Direct Memory Access ）。当数据存储在主存中之后，磁盘控制器便会向 CPU 发送中断信号以通知磁盘读取完成，如上图中 (c) 所示。\nSSD 固态硬盘（Solid State Disk，SSD）是一种基于闪存的存储技术，其基本理念如下：\nSSD 由一个或多个闪存芯片以及闪存转换层（Flash Translation Layer）组成，前者代替了旋转磁盘中的机械驱动器，后者则与磁盘控制器的作用相同。\n闪存中包含了 B 个 Block，每个 Block 又可以分成 P 个 Page。Page 的大小通常在 512 字节到 4 KB 之间，而一个 Block 一般由 32 到 128 个 Page 组成，因此 Block 的大小为 16 KB 到 512 KB。\nSSD 以 Page 为单位进行读写，并且只有当 Page 所在的整个 Block 被擦除（即所有位均置为 1）后才能向其写入。不过，只要一个 Block 被擦除，其中的每一个 Page 都可以被写入一次而无需再次擦除。Block 会在大约 100,000 次重复写入后发生磨损，无法再被使用。\nSSD 的随机写入速度比读取慢，这是因为擦除 Block 需要相对较长的时间。另外，如果写操作尝试修改已有数据的 Page，那么就必须先将同一 Block 中其他任何包含有用数据的 Page 复制到另一个已被擦除的 Block 中。\n相比于旋转磁盘，SSD 的随机访问速度更快，消耗的功率更低，同时也更加坚固。\n局部性 优秀的计算机程序通常表现出良好的局部性（Locality），即程序多次引用相同的数据或最近引用数据附近的数据。前者被称为时间局部性（Temporal Locality），后者则被称为空间局部性（Spatial Locality）。\n局部性在现代计算机系统的多个层级中都有着广泛的应用。如在硬件级别，我们引入高速缓存来加快对主存储器的访问速度。在操作系统级别，主存储器可以缓存磁盘文件系统中最近使用的 Block。在应用程序级别，Web 浏览器会将最近请求的文档缓存到本地磁盘上。\n引用程序数据的局部性 变量sum在每次循环中都被引用一次，因此上图中的两个函数都具有优秀的时间局部性。而对数组元素a[i][j]来说，第一个函数sumarrayrows会按照其在内存中存储的顺序依次读取，所以循环的空间局部性也十分良好。我们将每隔 k 个元素访问连续向量的模式称为 stride-k 引用，空间局部性随着 k 的增加而降低。显然，采用 stride-2 引用模式的函数sumarraycols的空间局部性较差。\n获取指令的局部性 我们还可以评估 CPU 读取内存中程序指令的局部性。循环体中的指令会按照存储顺序依次执行，因此循环具有良好的空间局部性。由于循环体中的指令会被多次迭代执行，所以程序的时间局部性也很优秀。与程序数据相比，指令在运行时很少被修改。\n存储系统层级 我们可以将存储在容量大而访问速度慢的设备中的数据对象暂存到容量相对较小但访问速度更快的区域中，这便是缓存（Cache）。下图展示了存储系统层级中的缓存概念：\n不同层级的设备之间以 Block 为单位传输数据，每个 Block 都有唯一的地址或名称。相邻层级设备之间的 Block 的大小一般是固定的，但也可以是变化的（如存储在 Web 服务器上的 HTML 文件）。不同层级使用的 Block 大小各不相同，如 L0 和 L1 之间的 Block 通常为一个 Word，而 L1 和 L2 之间的 Block 则为四到八个 Word。一般来说，层级越低的设备访问速度越慢，因此其使用的 Block 也会越大。\n缓存命中与缺失 当程序需要访问存储在第 k + 1 级设备中的数据对象 d 时，会首先从第 k 级设备中查找。如果 d 恰好缓存在第 k 级设备中，那么我们便称缓存命中（Cache Hits）。反之则为缓存缺失（Cache Misses），第 k 级设备会从第 k + 1 级设备中获取 d 所在的 Block。如果此时第 k 级设备已满，则现有的 Block 将会被覆盖（驱逐）。Block 的驱逐策略（Replacement Policy）有多种，比如随机替换和 LRU（Least Recently Used）。LRU 策略会将被访问时间据现在最久远的 Block 驱逐。\n缓存缺失有多种不同类型。如果缓存为空，则访问任何数据对象都将发生缓存缺失，我们称其为强制缺失（Compulsory Misses）或冷缺失（Cold Misses）。\n每当出现缓存缺失时，第 k 级缓存会根据其放置策略（Placement Policy）将第 k + 1 级缓存中的 Block 拷贝到指定位置处。Block 的放置策略同样有多种，最简单的便是随机放置。它的缺点十分明显，因为被随机放置的 Block 的寻址成本很高。我们可以将第 k + 1 级缓存中的 Block i 放置在第 k 级缓存中的 Block i mod n 处，该策略被称为映射放置。若 n 为 4，则上图中第 k + 1 级缓存中的 Block 0、4、8 和 12 将被映射到第 k 级缓存中的 Block 0，而第 k + 1 级缓存中的 Block 1、5、9 和 13 则将被映射到第 k 级缓存中的 Block 1。\n映射放置的缺点是容易导致冲突缺失（Conflict Misses）。如果程序依次请求第 k + 1 级缓存中的 Block 0、4、8 和 12，由于它们均被映射到第 k 级缓存中的 Block 0，因此即使缓存足以容纳四个 Block，也将连续发生缓存缺失。\n程序通常分多个阶段（如循环）运行，其中每个阶段都会访问一些恒定的 Block 集合（即工作集）。如果工作集（Working Set）超过了缓存的大小，那么就将发生容量缺失（Capacity Misses）。\n缓存管理 不同级别的缓存管理是由硬件、软件或两者的组合实现的，如下图所示：\n缓存的实现细节 假设存在一个简单的存储系统层级结构，在 CPU 和主存储器之间只有一个 L1 级的高速缓存。我们将通过该模型介绍缓存的具体实现细节。\n通用缓存管理 假设我们模型中的每个内存地址都有 $m$ 位，则共有 $M = 2^m$ 个唯一地址。如下图所示，缓存是一个包含了 $S = 2^s$ 个缓存集（Cache Set）的数组，每个缓存集由 E 个缓存行（Cache Line）组成。每个缓存行中都有一个包含了 $B = 2^b$ 字节数据的 Block，一个标识该行是否存储了有效信息的有效位（图中的“Valid”），以及 $t$ 位（$t = m -(b + s)$）唯一标识行内 Block 的标记位（图中的“Tag”）。\n缓存的结构通常可以用元祖 (S, E, B, m) 来表征，其容量为 $C = S \\times E \\times B$。\n直接映射缓存 缓存可以根据 E 的数量进行分类，E 为 1 的缓存被称为直接映射缓存。当 CPU 想要读取内存中的某个 Word 时，直接映射缓存将通过以下步骤确定缓存是否命中以及提取请求的 Word：\n集合选择（Set Selection） 行匹配（Line Matching） 字提取（Word Extraction） 我们可以将缓存看成一个以 Set Index 为索引的缓存集数组，示例中的 Set Index 为 $0001_2$，因此将选择缓存集 1。\n如果有效位为 1 且缓存行中的标记位与地址中的标记位相匹配，则缓存命中。同样，我们可以将 Block 看作一个以 Block Offset 为索引的字节数组。示例中的 Block Offset 为 $100_2$，因此目标 Word 的起始字节为 4，即上图中的“$w_0$”。\n如果出现缓存缺失，则缓存将从以下一级设备中检索请求的 Block，然后存储在其 Set Index 指定的缓存集中。若当前缓存已满，考虑到直接映射缓存的缓存集中只有一个缓存行，因此对应的缓存行将被替换。\n缓存实现示例 假设一个直接映射缓存有四个缓存集，每个 Block 两个字节。地址均为四位，每个 Word 都只有一个字节：\n索引位（图中的“Index Bits”）和标记位唯一标识了内存中的每个 Block； 不同的 Block 可以被映射到相同的缓存集，如 Block 0 和 4； 与相同缓存集映射的 Block 是通过标记位进行区分的，如 Block 0 的标记位为 0，而 Block 1 的标记位为 1。 若 CPU 想要读取内存中的某些 Word，上述缓存将会开展一系列的工作。不过在开始时，缓存是空的：\nSet Valid tag block[0] Block[1] 0 0 1 0 2 0 3 0 当 CPU 读取地址 0 处的 Word 时，缓存将从主存储器中获取 Block 0 并把它存储在 Set 0 中：\nSet Valid tag block[0] Block[1] 0 1 0 m[0] m[1] 1 0 2 0 3 0 此后如果 CPU 想要读取地址 1 处的 Word，就显然会发生缓存命中。而当 CPU 读取地址 13 处的 Word 时，缓存将从主存储器中获取 Block 6 并把它存储在 Set 2 中：\nSet Valid tag block[0] Block[1] 0 1 0 m[0] m[1] 1 0 2 0 m[12] m[13] 3 0 当 CPU 读取地址 8 处的 Word 时，即使 Set 0 中的有效位为 1，但 Tag 并不匹配，因此将发生缓存缺失。缓存从主存储器中获取 Block 4 并覆盖之前的缓存行，一旦 CPU 想要再次读取地址 0 处的 Word 就会出现冲突缺失。\nSet Valid tag block[0] Block[1] 0 1 0 m[8] m[9] 1 0 2 0 m[12] m[13] 3 0 冲突缺失 直接映射缓存的冲突缺失在程序访问长度为 2 的幂的数组时经常出现，如：\n1 2 3 4 5 6 7 8 float dotprod(float x[8], float y[8]) { float sum = 0.0; int i; for (i = 0; i \u003c 8; i++) sum += x[i] * y[i]; return sum; } 该程序具有良好的局部性，但在直接映射缓存中却很容易发生冲突缺失。假设缓存有两个缓存集，每个 Block 存储 16 字节的数据。那么缓存的容量便为 32 字节，可以完整地保存整个数组。数组x[8]和y[8]中的元素与缓存集的映射关系如下：\n由于两数组中索引相同的元素均被映射到相同的缓存集，因此每当循环中的指令读取数组元素时就会发生冲突缺失。我们将这种情况称为颠簸（Thrashing），即缓存重复加载并驱逐相同缓存集中的 Block。\n一种简单的解决方案是在每个数组末尾填充若干字节。如将数组x[8]重新声明为x[12]，则映射关系就变成了：\n显然，此时x[i]与y[i]被映射到了不同的缓存集，颠簸将不再出现。\n细心的读者可能会想到，为什么 Set index 在地址的中间位而非高位？如下图所示，若 Set index 位于地址的高位，那么一些连续的 Block 将被映射到相同的缓存集。因此只要程序按顺序读取数组中的元素，缓存就会发生颠簸。\n集关联型缓存 集关联型缓存（Set Associative Caches）中的每个缓存集可以包含多个缓存行。我们通常将包含 E （1 \u003c E \u003c C/B）个缓存行的缓存称为 E-路（E-way）集关联型缓存，下图则是一个二路集关联型缓存的结构：\n其读取 Word 的步骤与直接映射缓存类似，区别主要在于行匹配上。集关联型缓存必须检查多行的有效位和标记位是否与请求的 Word 相匹配：\n一旦发生缓存缺失，缓存将首先从主存储器中提取所需的 Block。如果此时缓存中没有空行，则必须根据策略替换已有的缓存行。最简单的方法便是随机替换，但我们应当利用局部性尽可能地减小被替换的行未来再次被使用的可能。除了上文提到的 LRU 以外，我们还可以采用 LFU（Least Frequently Used）策略，替换过去某个时间段内被引用次数最少的行。\n全关联型缓存 全关联型缓存（Fully Associative Caches）只有一个缓存集，其中包含多个缓存行（E = C/B）：\n其读取 Word 的步骤与其他两种缓存类似，不过 Word 的地址将不包含 Set Index：\n对于全关联型缓存，缓存电路必须并行地匹配多行标记位。因此实现一个容量大且速度快的全关联型缓存是十分困难而又昂贵的，它仅适用于小型缓存。\n缓存的写入 相比于读取，写入的情况要更加复杂，因为我们还要考虑如何更新低级别缓存中的副本。最简单的方法便是直接写入（Write-through），但这样每次写入操作都会消耗总线的流量。另一种方法被称为回写（Write-back），即只有当更新的 Block 被驱逐时才向低级别写入。不过回写也会增加系统的复杂性，缓存必须为每个缓存行维护一个脏位（Dirty Bit），以标识该 Block 是否已被修改。\n还有一个问题是如何处理写入时的缓存缺失。一种方法是将目标 Block 从低级别加载到缓存中后再进行更新，被称为写分配（Write-allocate）。该方法试图利用写入的空间局部性，但缺点是只要发生缓存缺失就必须传输 Block。另一种方法会绕过缓存直接在低级别中修改目标 Block，被称为无写分配（No-write-allocate）。直接写入通常使用无写分配，而回写则使用写分配。\n对于试图编写缓存友好型代码的程序员来说，我们推荐采用回写和写分配的处理方式。尤其是在低级别的缓存（如虚拟内存）中，传输数据的时间较长，因此更容易体现出回写的优势。\n真实缓存层级剖析 上图中的“i-cache”代表保存指令的缓存，“d-cache”代表保存程序数据的缓存，而“unified cache”则代表既存储指令又存储数据的缓存。有趣的是，所有的 SRAM 缓存都在 CPU 芯片中。\n缓存参数对性能的影响 缓存的性能指标主要有：\n缺失率（Miss Rate）：# missed / # references 命中率（Hit Rate）：1 - Miss Rate 命中时间（Hit Time）：CPU 从缓存中读取一个 Word 所需的时间 缺失惩罚（Miss Penalty）：因为缓存缺失而增加的读取时间 缓存的不同参数对其性能的影响为：\n缓存容量：更大的缓存可以增加命中率，但也会增加命中时间； Block 的大小：我们可以利用空间局部性，通过增大 Block 来提升命中率。但在缓存容量一定的情况下，Block 越大，缓存行的数量就越少。此外，更大的 Block 还会增加数据传输的时间； 关联性（缓存行的数量）：更多的缓存行可以避免因冲突缺失而导致的颠簸，但维护更多的缓存行也需要大量成本。 编写缓存友好型代码 编写缓存友好型代码的两个基本准则如下：\n关注核心程序的内部循环并忽略其他部分； 减少每个内部循环中缓存缺失的数量。 其中第二个准则又可以根据局部性分为两方面：\n最大化空间局部性：采用 stride-1 模式，按数据对象在内存中存储的顺序依次读取； 最大化时间局部性：一旦从内存中读取了某个数据对象，就尽可能多地使用它。 缓存对程序性能的影响 ","description":"","tags":["OS"],"title":"CSAPP 读书笔记：存储系统的层级结构","uri":"/posts/the-memory-hierarchy-note/"},{"content":"我们将处理器支持的指令及其对应的字节编码方式称为指令集架构（Instruction Set Architecture，ISA）。不同的处理器系列，例如 Intel IA32/x86-64，IBM/Freescale Power 和 ARM 等，均使用不同的 ISA。为一种机器编译得到的程序，无法在 ISA 不同的机器上运行。\nISA 在编译器的编写者和处理器的设计者之间提供了一个抽象层。编译器的编写者只需要知道允许使用哪些指令以及它们是如何编码的，而处理器的设计者则需要创建能够执行这些指令的机器。\n在传统的 ISA 模型中，每条指令顺序执行。而现代处理器则会同时执行多条指令的不同部分，从而获得比每次只执行一条指令更高的性能。不过我们还需要引入一个特殊机制，确保处理器的计算结果与顺序执行相同。\n在本章中，我们仿照 x86-64 创建了一个简单的指令集，称其为“Y86-64”。同时使用 HCL（Hardware Control Language）来描述硬件系统的控制部分和处理器设计，它的作用类似于 Verilog HDL（Hardware Description Language）。\nY86-64 指令集架构 程序员可见状态 Y86-64 程序中的每条指令都可以读取和修改处理器状态的某些部分，即程序员可见状态。此处的“程序员”既指用汇编代码编写程序的人，又指生成机器代码的编译器。如下图所示：\nY86-64 中的程序员可见状态包括 15 个能够存储 64 位数据的寄存器、3 个单位（Singel Bit）条件码、程序计数器、虚拟内存和表示程序执行整体状态的状态码（图中的“Stat”）。\nY86-64 指令 Y86-64 指令是 x86-64 指令的子集，仅包含了 8 字节的整数运算，以及更少的寻址和运算模式。由于我们的数据均为 8 字节，因此可以无歧义地将它们称为字（Word）。\nx86-64 中的movq指令被分成了四个不同的 Y86-64 指令：irmovq、rrmovq、mrmovq和rmmovq。其中，i代表立即数，r代表寄存器，m代表内存。\n上图还缺少了部分信息，比如整型操作指令OPq实际上包含了四个指令：addq、subq、andq和xorq，它们会根据计算结果改变三个条件码的值。另外，该类指令和条件分支指令jXX以及条件移动指令cmovXX编码中的 $f_n$ 将随指令的具体名称变化：\ncall、ret、nop、pushq和popq指令的作用和 x86-64 中的类似，而halt指令则对应了 x86-64 中的hlt。x86-64 不允许程序使用htl指令，因为它会使整个系统暂停操作。不过在 Y86-64 中，halt指令会使处理器停止并将状态码置为 HLT。\n指令编码 上一节的图中还展示了不同指令的字节编码，其长度范围在一到十字节之间，其中的首个字节标识了其类型。寄存器存储在 CPU 中的寄存器文件（一个小型的 RAM）中，下图中的寄存器 ID 就是它们的地址：\n寄存器 ID 将替换指令编码中的 $r_A$ 和 $r_B$。x86-64 中条件分支和跳转指令的目的地址是相对于程序计数器（PC-Relative）的，这样可以使程序编码更加紧凑，同时代码在内存中移动时也无需更改所有分支目标的地址。由于我们更加关心设计的简洁性，因此 Y86-64 采用绝对地址。\n举例来说，在一台小端法机器上，指令rmmovq %rsp, 0x123456789abcd(%rdx)的字节编码为4042cdab896745230100。其中，指令类型rmmovq对应的字节为40，寄存器 %rsp 和 %rdx 分别对应4和2。剩下的立即数将首先填充为八字节的000123456789abcd，然后反向追加到指令尾部。\n任何指令集中的字节编码都必须与指令序列唯一对应。也就是说，只要我们知道了指令字节编码中的首个字节，就能确定完整的指令序列。反之如果我们无法得知字节序列的起始位置，那么也就无法将其拆分为多个单独的指令。\nY86-64 异常 Y86-64 中的状态码 Stat 如下：\n我们没有引入异常处理程序（Exception Handler），只是简单地让处理器在遇到任何异常时停止执行指令。\nY86-64 程序 示例 C 程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 long sum(long *start, long count) { long sum = 0; while (count) { sum += *start; start++; count--; } return sum; } int main() { long array[4] = {0x000d000d000d, 0x00c000c000c0, 0x0b000b000b00, 0xa000a000a000}; sum(array, 4); return 0; } 与之对应的 Y86-64 汇编代码为：\n从中我们可以看出它与 x86-64 汇编代码的区别：\n由于我们的算术运算无法直接使用立即数，因此需要先将其拷贝到寄存器中（第 24～25 行）； 我们需要先从内存中读取值（第 30 行），然后再将其与寄存器中的值相加（第 31 行）。而 x86-64 中只需要使用一个addq指令； 我们的subq指令（第 33 行）在执行减法运算的同时还会修改条件码，因此我们可以在不引入testq的情况下直接使用条件跳转指令jne（第 35 行）。不过为了实现这一点，我们必须在进入循环之前使用andq指令初始化条件码的值（第 27 行）。 汇编器会根据上图中以.开头的指令调整其生成的代码地址，如指令.pos 0（第 2 行）表示代码的起始地址为 0。指令irmovq stack, %rsp会初始化栈指针，其地址是由最后两行指令声明的。运行时栈将从0x200开始向较低的地址处增长，因此我们需要保证它不会覆盖到其他的程序数据。程序的第 8 到 13 行声明了一个四字数组，.align 8指令将使它在 8 字节边界上对齐。\n一些 Y86-64 指令细节 指令pushq %rsp压入栈的值可能是寄存器 %rsp 的原始值，也有可能是栈指针减少后的值。而指令popq %rsp从栈中弹出的值可能是直接从内存中读取的，也有可能是栈指针增加后再读取的。为了避免混淆，我们需要规定上述两个指令均采用前者的方式。\n逻辑设计和 HCL 在硬件设计中，电子电路用于计算位函数（Function on Bits）并将位存储在不同的存储器元素（Memory Element）中。我们可以使用高电压（约 1.0 V）来表示逻辑值 1，使用低电压（约 0.0 V）来表示逻辑值 0。\n数字系统主要由以下三个部分构成：\n计算位函数的组合逻辑（Combinational Logic） 存储位的存储器元素 控制存储元素更新的时钟信号（Clock Signal） 逻辑门 逻辑门是数字电路的基本计算元素，其输出等于输入的位进行布尔运算后的结果。上图展示了用于布尔函数AND、OR和NOT的标准符号，逻辑门的下方则是对应的 HCL 表达式\u0026\u0026、||和!。逻辑门只对单个位进行操作而非整个字，因此我们不使用 C 中的位级运算符\u0026、|和~。\n组合电路和 HCL 布尔表达式 多个逻辑门组成的网络被称为组合电路，其构建方式有以下要求：\n每个逻辑门的输入必须是： 整个系统的输入之一（即主输入） 某个存储器元素的输出 某个逻辑门的输出 两个或多个逻辑门的输出不能连接到一起 网络不能是一个回路（Acyclic） 下图展示了一个多路复用器（Multiplexor，MUX）的组合电路：\n输入的数据信号是位 a 和 b，控制信号是位 s。当 s 为 1 时，输出将等于 a。而当 s 为 0 时，输出则为 b。输出信号的 HCL 表达式为：bool out = (s \u0026\u0026 a) || (!s \u0026\u0026 b);\nHCL 表达式和 C 中的逻辑表达式之间存在一些差异：\n逻辑门和 HCL 的输出会动态地随输入的变化而变化，而 C 中的表达式只会在程序执行过程中运算； C 中的逻辑表达式允许使用任意整型参数，而 HCL 表达式只能对位值 0 和 1 进行运算； C 中的逻辑表达式可能只会执行部分运算。例如表达式(a \u0026\u0026 !a) \u0026\u0026 func(b,c)，由于(a \u0026\u0026 !a)一定为 0，整个表达式的值也为 0，因此不会计算func(b,c)的值。相比之下，HCL 没有任何的部分评估规则。 To be continued …\n","description":"","tags":["ISA"],"title":"CSAPP 读书笔记：处理器架构","uri":"/posts/processor-architecture-note/"},{"content":" 原文链接：Fabian Reinartz. Writing a Time Series Database from Scratch. fabxc.org, 2017.\nPrometheus 是一个包含了自定义时间序列数据库的监控系统，其查询语言、操作模型以及一些概念性决策使得它易于与 Kubernetes 集成。然而，Kubernetes 集群中的工作负载是动态变化的，有可能给它带来一定的压力。因此，我们致力于提高 Prometheus 在这些运行着高度动态或瞬态服务的环境中的性能。\n过去，单台 Prometheus 服务器每秒能够拉取多达一百万个样本（Sample），并且只占用非常少的磁盘空间。虽然它的性能十分卓越，但仍有改进空间。因此我提出了一种全新的存储系统设计，它可以解决当前方案的痛点，让 Prometheus 具备处理更大规模数据的能力。\n问题，问题和问题空间 首先，我们简要介绍 Prometheus 需要完成的任务及其引发的关键问题。对于每个方面，我们都会讨论当前方案做得好的地方，以及做得不好亟待新方案解决的地方。\n时间序列数据 Prometheus 随时间不断采集数据点：\n1 identifier -\u003e (t0, v0), (t1, v1), (t2, v2), (t3, v3), .... 每个数据点都是一个由时间戳和数值组成的元组。其中，时间戳是一个整型，而数值则是 64 位浮点数。一系列带有严格单调递增时间戳的数据点被称为 Series，它可以由含有指标名称和标签字典的标识符（Identifier）来寻址。一组典型的 Series 标识符如下：\n1 2 3 requests_total{path=\"/status\", method=\"GET\", instance=”10.0.0.1:80”} requests_total{path=\"/status\", method=\"POST\", instance=”10.0.0.3:80”} requests_total{path=\"/\", method=\"GET\", instance=”10.0.0.2:80”} 指标名称也可以被视为一个标签，如_name_，因此我们可以对这种表达方式进行简化。在查询时它可能会被特殊处理，但存储时则与其他标签无异。\n1 2 3 {__name__=\"requests_total\", path=\"/status\", method=\"GET\", instance=”10.0.0.1:80”} {__name__=\"requests_total\", path=\"/status\", method=\"POST\", instance=”10.0.0.3:80”} {__name__=\"requests_total\", path=\"/\", method=\"GET\", instance=”10.0.0.2:80”} 当查询时间序列数据时，我们通常会根据标签选择所需的 Series。一个最简单的例子，{__name__=\"requests_total\"}会查询属于requests_total指标的所有 Series，Prometheus 将拉取指定时间窗口内的数据点。\n有时候我们还希望一次查询能够选取满足多个标签选择器的 Series，或者在标签匹配中使用比等式更加复杂的条件。例如，否定(method!=\"GET\")或正则表达式匹配(method=\"PUT|POST\")。\n本节介绍的内容在很大程度上定义了 Prometheus 存储和调用数据的方式。\n垂直和水平 在简化的视图中，所有数据点都分布在一个二维平面上。其中，水平维度代表时间，垂直维度代表 Series 的标识符：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 series ^ │ . . . . . . . . . . . . . . . . . . . . . . {__name__=\"request_total\", method=\"GET\"} │ . . . . . . . . . . . . . . . . . . . . . . {__name__=\"request_total\", method=\"POST\"} │ . . . . . . . │ . . . . . . . . . . . . . . . . . . . ... │ . . . . . . . . . . . . . . . . . . . . . │ . . . . . . . . . . . . . . . . . . . . . {__name__=\"errors_total\", method=\"POST\"} │ . . . . . . . . . . . . . . . . . {__name__=\"errors_total\", method=\"GET\"} │ . . . . . . . . . . . . . . │ . . . . . . . . . . . . . . . . . . . ... │ . . . . . . . . . . . . . . . . . . . . v \u003c-------------------- time ---------------------\u003e 这些数据点是由 Prometheus 周期性地拉取一组 Series 的当前值而得到的。由于该操作对每个数据源实体（即 Target）均独立完成，因此 Prometheus 的写入模式是完全垂直且高度并发的。\n假设我们的数据规模为：单个 Prometheus 实例从数万个 Target 中采集数据点，而每个 Target 又暴露成百上千个不同的 Series。在这种数据量达到百万级别的情况下，批量写入是必需的。\n对于旋转磁盘来说，随机写入数据非常缓慢，因为它需要不断移动磁头来寻址。而对于 SSD，尽管其随机写操作很快，但是它只能以 4KiB 或更大的 Page 为单位写入。也就是说，写入一个 16 字节的样本其实相当于写入一个完整的 4KiB Page。这种现象属于写放大（Write Amplification）的一部分，将会导致 SSD 的磨损和性能下降，甚至在几天或几周内摧毁你的磁盘。有关该问题的详细信息，可以参考系列文章 Coding for SSDs。综上所述，无论对于旋转磁盘还是 SSD，顺序写入和批量写入均是最理想的模式，这是我们必须坚持的原则。\n查询模式则与写入模式完全不同。我们可以查询一个 Series 中的单个数据点，一万个 Series 中的单个数据点，一个 Series 中一周内的数据点以及一万个 Series 中一周内的数据点等等。在二维数据平面中，查询的数据点既不是完全垂直或完全水平的，而是两者的矩形组合。\n我们可以使用 Recording rules 来改善执行常用查询语句时遇到的性能问题，但它对临时性的查询并不起作用。\n译者注：关于 Recording rules，除了原文给出的文档链接外，还可以参阅 Today I Learned: Prometheus Recording Rules 一文。\n当 Prometheus 批量写入时，每个批次（Batch）的数据点分布在垂直方向上的多个 Series 中。而如果我们查询某个时间窗口内的某个 Series 的数据点时，不仅很难找出每个点在磁盘上的位置，还必须从磁盘上随机读取数据。每次查询可能涉及到数百万个样本，即使在最快的 SSD 上进行也很慢。虽然每次查询请求的样本大小可能只有 16 字节，但读取操作会从磁盘上检索更多的数据。对于 SSD 是一个 Page，而对于 HDD 则是整个扇区。无论如何，我们都在浪费宝贵的吞吐量。\n因此在理想情况下，同一个 Series 中的样本按顺序存储。这样只要我们知道某个 Series 的起始位置，就可以快速访问它所有的数据点，从而减少读取操作的次数。\n将数据写入磁盘的理想模式和能够显著提升查询效率的设计之间显然存在着强烈的矛盾，这是我们的时序数据库必须解决的根本问题。\n译者注：原文为：“There’s obviously a strong tension between the ideal pattern for writing collected data to disk and the layout that would be significantly more efficient for serving queries. It is the fundamental problem our TSDB has to solve.” 译者不确定此处的 tension 该如何翻译，猜测原文作者可能是想表达一种类似 trade-off 的概念。因为上文提到，在理想的写入模式中，数据点是垂直分布的。而通常查询得到数据点却是水平，甚至是矩形的。\n当前解决方案 是时候看看 Prometheus 当前的存储系统（我们称之为 “V2”）是如何解决这一问题的。我们为每个 Series 创建一个文件，其中所有的样本均按时间顺序排列。由于每隔几秒就将样本追加写入到这些文件末尾的成本很高，我们先将样本缓存到内存中的 Chunk。每个 Series 都有一个对应的 Chunk，待 Chunk 被写满（即大小达到 1 KiB）之后再添加到文件尾部。这种方案既实现了批量写入，又将样本按顺序存储，解决了很多问题。一般来说，同一个 Series 中相邻样本的数值变化较小，因此可以使用非常高效的数据压缩格式。一篇关于 Gorilla TSDB 的 论文 介绍了一种类似基于 Chunk 的方法和压缩格式，能够将 16 字节的样本数据压缩到平均 1.37 字节。V2 版本的存储系统使用多种压缩格式，其中就包括 Gorilla 的变体。\n尽管基于 Chunk 的方法很棒，但为每个 Series 维护一个独立文件将给 V2 存储系统带来很多麻烦：\n实际上我们所需的文件数量远比当前收集到的 Series 多得多，原因参见 Series Churn 章节。上百万个文件迟早会耗尽我们文件系统上所有的 inodes，只能通过重新格式化磁盘来恢复。 即使我们引入了 Chunk，每秒也会有数千个 Chunk 被写满并准备持久化，这意味着每秒发生数千次独立的磁盘写入。虽然可以通过将一个 Series 中几个已完成的 Chunk 批量落盘来改善这一问题，但这样做反而增加了等待持久化的 Chunk 数量，因此会占用更多的内存。 为了读写而保持所有文件均处于打开状态是不可行的。尽管约 99%的数据在 24 小时后就不再被查询，但只要查询到已持久化的样本，就必须打开数千个文件然后将结果读入内存中，最后再关闭它们。因为这种操作极大地提高了查询的延时，Prometheus 将缓存更多的 Chunk ，从而导致 资源消耗 章节中提到的问题。 最后我们必须删除旧数据。它们存储在数百万个文件的头部中，因此删除其实是一种写入密集型操作。此外，遍历数百万个文件并对其进行分析通常需要数个小时，可能刚一完成就不得不重新开始。没错，删除旧文件还将进一步地导致 SSD 的写放大。 当前累积的 Chunk 均存储在内存中，如果 Prometheus 发生崩溃数据就会丢失。为了避免这一情况，内存状态将周期性地保存（Checkpoint）到磁盘中。然而，完成 Checkpoint 的所需时间可能远比我们能够接受的数据丢失时间窗口还长。同时恢复 Checkpoint 一般长达几分钟，使 Prometheus 的重启周期变得非常漫长。 现有设计的关键概念是 Chunk，我们当然希望保留它。将最新的 Chunk 始终保持在内存中也是一个很好的设计，毕竟近期的数据查询频率最高。不过，为每个 Series 都创建一个文件的方案看起来并不合理，我们希望能够找到新的方案代替它。\nSeries Churn 在 Prometheus 中，Series Churn 表示一组 Series 变得不活跃。即新的数据点不再由它们接收，而是关联到一组新出现的 Series。例如，一个微服务暴露的所有 Series 都有一个对应的“实例”标签。如果我们对该微服务进行滚动更新并将每个实例替换为新版本，Series Churn 就会发生。在更加动态的环境中，这种现象甚至可能每小时就出现一次。集群编排系统（如 Kubernetes）允许应用连续地自动扩展和频繁地滚动更新，因此每天可能将有上万个实例以及相关的 Series 被创建。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 series ^ │ . . . . . . │ . . . . . . │ . . . . . . │ . . . . . . . │ . . . . . . . │ . . . . . . . │ . . . . . . │ . . . . . . │ . . . . . │ . . . . . │ . . . . . v \u003c-------------------- time ---------------------\u003e 由于 Series Churn 的存在，即使整个基础架构的规模保持不变，Series 数量也会随时间线性增长。虽然 Prometheus 能够收集多达 1000 万个 Series 的数据，但要让它从十亿个 Series 中查找数据还是十分困难的。\n当前解决方案 V2 存储系统为当前存储的所有 Series 分配了一个基于 LevelDB 的索引。它允许查询包含给定标签对的 Series，但缺少一种可扩展的方式来对不同标签选择的结果进行组合。\n例如，通过标签__name__=\"requests_total\"选取所有的 Series 十分高效，但使用instance=\"A\" AND __name__=\"requests_total\"就会遇到扩展能力的问题。稍后我们将再次讨论导致这种现象的原因，以及想要改善查询性能所必须做出的调整。\n这个问题实际上是我们寻找更好的存储系统的最初原因，Prometheus 需要一种更加完善的索引方法以从数亿个 Series 中快速搜索数据。\n资源消耗 当尝试扩展 Prometheus（或其他任何东西）时，资源消耗是贯穿始终的主题之一。但是，真正困扰用户的并非是绝对的资源不足。实际上，Prometheus 通常能够满足用户所需的吞吐量，问题在于其面对变化时的不稳定性和不可预知性。V2 存储系统为样本数据缓慢地创建 Chunk，内存使用量随时间的推移而持续上升。待 Chunk 写满后，它们会被写入磁盘并从内存中驱逐。最终，Prometheus 的内存使用量将达到一个稳定的状态。但是一旦监控的环境发生变化——扩展应用或滚动更新时，Series Churn 就会增加内存、CPU 和磁盘的使用。\n如果变化持续进行，资源消耗将再次达到一个稳定的状态，不过明显要比静态环境中的高。过渡周期通常长达数个小时，因此我们很难确定最大的资源使用量。\n为每个 Series 维护一个文件的方案也会使单个查询操作很容易终止 Prometheus 的进程。当查询未被缓存的数据时，与之关联的 Series 文件需要被打开并将包含相关数据点的 Chunk 读入内存。如果数据量超过了内存配额，Prometheus 就会因 OOM 而相当不雅地退出。加载的数据可以在查询结束后释放，但为了后续能够更快地查询相同数据，通常要缓存更长的时间。\n我们在上文中提到了 SSD 的写放大，以及 Prometheus 是如何通过批量写入来解决这一问题的。尽管如此，在一些场景中——如写入的批次太小或者数据没有与 Page 的边界精确对齐，写放大还是会产生。我们已经在一些规模较大的 Prometheus 服务器上观测到了硬件寿命缩短的现象，虽然这对写入吞吐量较高的数据库应用来说是正常的，但还是应当思考如何缓解它。\n重新开始 到目前为止，我们已经对 Prometheus 需要解决的问题、V2 存储系统的设计方案及其缺点有了充分的了解。许多 V2 存储系统存在的不足可以通过一些优化和部分重新设计来改善，但为了让事情变得更有趣（当然也经过了仔细评估），我决定从零开始编写一个完整的时序数据库。\n存储模式将直接影响到 Prometheus 的性能和资源消耗等关键问题，因此我们必须为数据找到正确的算法集和磁盘设计方案。这就是我能够免走弯路而直接找到解决方案的原因。\nV3——宏观设计 当我们在 Prometheus 的数据目录下使用tree命令时，就可以看到 V3 存储系统的宏观层级结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 $ tree ./data ./data ├── b-000001 │ ├── chunks │ │ ├── 000001 │ │ ├── 000002 │ │ └── 000003 │ ├── index │ └── meta.json ├── b-000004 │ ├── chunks │ │ └── 000001 │ ├── index │ └── meta.json ├── b-000005 │ ├── chunks │ │ └── 000001 │ ├── index │ └── meta.json └── b-000006 ├── meta.json └── wal ├── 000001 ├── 000002 └── 000003 最上层目录是一系列经过编号的 Block，其前缀均为b-。每个 Block 中都有一个索引文件index和一个包含若干编号文件的chunks目录，该目录中保存了多个 Series 数据点的原始 Chunk。和 V2 存储系统一样，这种设计可以减少读取一个时间窗口内的 Series 数据的性能开销，并支持使用相同的高效压缩算法。基于 Chunk 的理念已经被证明是行之有效的，因此我们将沿用下去。不过，现在的存储系统不再是每个文件对应一个 Series，而是由几个文件保存多个 Series 的 Chunk。\n索引文件index的存在不足为奇。让我们假设它拥有诸多黑魔法，可以用于查找标签及其可能的值、整个时间序列以及存储数据点的 Chunk。\n但为什么要设计成若干个包含索引和多个 Chunk 文件的目录？为什么最后一个 Block 中还存在一个wal目录？只要理解了这两点，就能解决我们 90%的问题。\n多个小型数据库 我们将二维数据平面在水平维度（即时间）上划分为多个互不重叠的 Block，每个 Block 均表现为一个包含其时间窗口内所有 Series 数据的独立数据库。因此，Block 中存在自身的索引和多个 Chunk 文件。\n每个已持久化的 Block 都是不可改变的，但我们还需要一个可变的 Block（即上图中的“Mutable Block”）来接收新的样本数据。该 Block 是一个能够高效更新数据结构的内存数据库，并有着与已持久化的 Block 相同的查询特性。为了防止数据丢失，所有刚采集到的数据都会另外写入临时的预写日志（Write Ahead Log）中。它实际上就是wal目录中的一组文件，可以在 Prometheus 重启时恢复原有的内存数据库。\n现在我们可以根据每个 Block 对应的时间范围将查询请求分发到各个 Block 中，最终的查询结果是由每个 Block 的返回值合并而成的。\n这种设计的优势在于：\n当查询某一时间范围内的数据时，我们可以轻易地忽略该时间范围外的所有 Block。随着查询开始时检索的数据集数量的减少， Series Churn 带来的问题迎刃而解； 当一个 Block 写满后，我们可以通过顺序写多个大文件的方式从内存数据库中持久化数据。这样 Prometheus 就避免了任何的写放大问题，并且能在 SSD 和 HDD 上表现得同样出色； 我们保留了 V2 存储系统中的优点，即查询最为频繁的 Chunk 始终保存在内存中； 我们不再需要为了数据对齐而限制 Chunk 的大小为固定的 1KiB，现在可以选择对于单个数据点和所选压缩格式最合适的任意大小； 删除旧数据的开销变得很小并且能够快速完成，因为我们只需要简单地删除一个目录。要知道在 V2 存储系统中，我们必须分析和重写多达数亿个文件，可能需要花费数个小时。 每个 Block 中还存有一个meta.json文件，它只保存一些与 Block 相关的可读信息，因此我们便可以轻松了解存储状态以及 Block 中包含的数据。\n译者注：从 Prometheus v2.19.0 开始，Mutable Block 便不再全部存储在内存中，详见：Prometheus TSDB (Part 1): The Head Block。\nmmap 既然已持久化的数据从数百万个小文件变成了若干个大文件，那么我们就能够以很低的开销保持所有文件均处于打开状态。在这种情况下，我们可以引入系统调用 mmap，将文件内容透明地映射到虚拟内存区域中。mmap 有些类似于交换分区（Swap Space），只不过我们所有的数据都已经在磁盘上了，在数据换出内存时不会发生写入。\n这意味着我们可以把数据库中的所有内容都视为在内存中，而实际上却没有占用任何物理内存（RAM）。只有我们访问数据库文件中指定的字节范围时，操作系统才会从磁盘中懒加载 Page。我们让操作系统来负责所有已持久化数据的内存管理，因为它对整个机器和其中的进程有着全面的了解。为了处理查询请求，更多的数据将被缓存到内存中，但它们会在内存压力较大时被操作系统驱逐。如果机器中还有内存未被使用，Prometheus 甚至可以把整个数据库缓存到内存中。而一旦另一个应用需要使用这部分内存，Prometheus 便会立刻返还给它。\n因此，查询比 RAM 容量更多的已持久化数据很容易导致进程的 OOM。内存中缓存的大小变得完全自适应，只有在需要响应查询请求时才会加载数据。\n据我所知，如今大多数的数据库均采用这种设计。如果磁盘格式允许，这是一种理想的工作模式——除非有人有信心在管理进程方面胜过操作系统。\n压缩 存储系统必须定期“切割”出一个新的 Block，然后将前一个 Block 写入到磁盘中。只有当它成功持久化后，对应的预写日志文件才能被删除。\n每个 Block 覆盖的时间范围不能太长（默认设置为两小时），否则将占用过多内存。但查询多个 Block 时，我们必须把每个返回结果合并到一起。这种操作显然会消耗性能，因此 Block 覆盖的时间范围也不能太短。一般来说，查询一周内数据所需要合并的 Block 数量不应超过 80 个。\n为了同时实现这两点，我们对 Block 进行压缩，即将一个或多个 Block 中的数据写入到一个有可能更大的 Block 中。Prometheus 在压缩过程中还会修改现有数据，比如删除已被标记为即将删除的数据，或者为了提高查询性能而重新构建样本的 Chunk。\n在上图中，几个 Block 被顺序编号为 [1, 2, 3, 4]。Block 1、2 和 3 可以被压缩到一起，变成 [1, 4]。也可以将它们两两压缩，变成 [1, 3]。所有时间序列数据仍然存在，但现在 Block 的总数减少了。这样查询时需要被合并的返回结果就更少，从而显着地降低了合并操作的开销。\n保留 在 V2 存储系统中，删除旧数据是一个非常缓慢的过程，并且会花费大量的 CPU、内存和磁盘资源。而现在，我们只需要删除那些在指定保留时间窗口内没有数据的 Block 目录即可。下方示例中，Block 1 可以被安全地删除，Block 2 则必须等到它完全超出保留边界（Retention Boundary）后才能被删除：\n随着旧数据的不断积累，压缩后的 Block 会变得越来越大。我们必须为其最大值设置上限，否则它将增长到包含整个数据库，从而很难被删除。对于像上图中 Block 2 这样的跨越保留边界的 Block，这种做法也限制了维护它们所需的磁盘开销。当 Block 的最大尺寸被设为保留时间窗口的 10%时，维护 Block 2 的成本也会受到同样的限制。\n总之，删除旧数据的开销从非常昂贵变成了几乎免费。\n如果你已经读到这里并掌握一些数据库知识，可能会有这样的疑问：“这些设计是全新的吗？”——实际上并非如此，甚至可能做得更好。\n在内存中批量处理数据、在预写日志中记录操作以及周期性地将数据落盘的设计模式在如今无处不在，使用这种方案的知名开源项目有 LevelDB、Cassandra、InfluxDB 以及 HBase 等。关键在于不要发明劣质的轮子，而是对已被证明有效的方法深入研究，并以正确的方式应用它们。\n当然，我们还有机会在 Prometheus 中加入自己的“魔法”。\n索引 我们改进存储系统的初衷是希望解决 Series Churn 带来的问题，而基于 Block 的设计则减少了查询时涉及的 Series 数量（设为 n）。然而对于时间复杂度为 $O(n^2)$ 的查询操作，减少 n 的数量没有什么意义。如果以前查询性能很差，那么现在依然会很糟糕。\n实际上，大多数查询操作的响应都很快。可一旦时间跨度较大，即使只查询几个 Series 也会很慢。在开展所有工作前，我最初的想法便是为这个问题找到一个解决方案。我们需要一个更加强大的 倒排索引。\n倒排索引可以基于数据内容的子集来为我们提供快速查找的能力。简而言之，我们可以在不遍历全部 Series 的情况下，找到所有包含标签app=\"nginx\"的 Series。\n为此，我们需要为每个 Series 分配一个独有的 ID。它可以在常量时间，即 $O(1)$ 内被检索出来。在这种情况下，ID 是我们的正排索引（Forward Index）。\n示例：如果包含标签app=\"nginx\"的 Series ID 为 10、29 和 10，那么标签“nginx”的倒排索引就是一个简单的数组 [10, 29, 9]，我们可以用它来快速检索所有包含该标签的 Series。即使还有其他 200 亿个 Series，也不会影响这次查询的速度。\n简单来说，如果 n 是 Series 总数，m 是给定查询结果的大小，那么查询的时间复杂度就从 $O(n)$ 变成了 $O(m)$。通常 m 要比 n 小很多，因此查询性能将显著提升。\n实际上，这一设计与 V2 存储系统中所采用的倒排索引几乎相同，也是在数百万个 Series 中实现高性能查询的最低要求。敏锐的读者可能已经发现，在最坏的情况下，一个标签存在于所有的 Series 中，那么复杂度又变成了 $O(n)$。其实这是合理的，因为如果查询涉及到全部数据，自然需要更长的时间。不过，一旦我们使用更加复杂的查询语句，就会面临一些新的问题。\n标签的组合 一个标签与数百万个 Series 关联是很常见的。假设一个微服务\"foo\"水平扩展为数百个实例，其中每个实例又有数千个包含标签app=\"foo\"的 Series。通常我们不会查询所有的 Series，而是使用多个标签的组合来对返回结果进行一定的限制。例如，我们可以通过__name__=\"requests_total\" AND app=\"foo\"来获取服务实例接收的请求数。\n为了找到满足两个标签选择器的所有 Series，我们需要计算两个标签对应的倒排索引数组的交集，其结果通常比单独的倒排索引数组小几个数量级。在最坏的情况下，每个倒排索引数组的长度均为 n，那么在两个数组中通过嵌套迭代取交集的时间复杂度就为 $O(n^2)$。其他类似的查询操作，如app=\"foo\" OR app=\"bar\"，也会花费同样的开销。当我们向查询语句中添加更多的标签选择器时，时间复杂度会呈指数增长：$O(n^3)$、$O(n^4)$、$O(n^5)$ … $O(n^k)$。\n幸运的是，只需要一个小小的改动就可以解决我们的问题。如果倒排索引数组中的 ID 都已被排序，那么会发生什么呢？\n1 2 3 4 __name__=\"requests_total\" -\u003e [ 999, 1000, 1001, 2000000, 2000001, 2000002, 2000003 ] app=\"foo\" -\u003e [ 1, 3, 10, 11, 12, 100, 311, 320, 1000, 1001, 10002 ] intersection =\u003e [ 1000, 1001 ] 我们在每个数组的起始元素处放置一个游标，其中数字较小的会不断前进。当两个游标对应的数字相等时，我们就把它添加到结果中并同时推进两个游标。由于游标只会在其所在的数组中移动，因此其遍历全部数组的时间复杂度为 $O(2n) = O(n)$。\n对两个以上的倒排索引数组取交集的过程与之类似。当标签增长到 k 个时，时间复杂度只会变为 $O(n * k)$，而不是 $O(n^k)$。这是一个非常大的改进。\n本文介绍的是典型搜索索引的一个简化版本，几乎所有的 全文搜索引擎 都在使用它。每个 Series 的标识符都被视为一个简短的“document”，而每个标签（名称加上固定的值）则是其中的一个“word”。我们可以忽略一些搜索引擎中常用的的索引附加数据，比如 word 的位置和频率。\n实际上还有很多技术可以对倒排索引进行压缩，但它们各有优缺点。考虑到我们的 document 很小，并且 word 在各个 Series 中的重复率很高，因此压缩其实无关紧要。例如，一个真实世界的数据集中大约有 440 万个 Series，每个 Series 大约有 12 个标签，但其中唯一的标签却不超过 5000 个。最初版本的存储系统没有采用压缩，只是做了一些简单优化以跳过大范围没有交集的 ID。\n让 ID 始终按顺序排列并非看起来那么简单。例如，V2 存储系统将哈希值作为 ID 分配给新的 Series，这样我们就无法有效地对倒排索引进行排序。\n另一个艰巨的任务是在数据被删除或更新时修改索引。通常最简单的方法就是在保证数据库可查询且一致的同时，重新计算并重写它们。V3 存储系统为每个 Block 都分配了一个独立的索引。对于已持久化的 Block，其索引只有在压缩时才会被重写。而对于内存中可变的 Block，其索引则需要被持续更新。\n基准测试 我们使用 测试工具 将 Prometheus 部署在 AWS 上的 Kubernetes 集群中，其中包含两个 1.5.2 版本（V2 存储系统）和两个 2.0 版本（V3 存储系统）的实例。为了模拟 Series Churn，微服务会定期移除旧的 Pod 并创建新的 Pod 以生成更多新的 Series。服务扩展频率和查询负载远远超过了如今生产环境中的真实情况，因此可以确保 V3 存储系统能够应对未来的数据规模。例如，在我们的测试环境中微服务每隔 15 分钟就要更换自身 60% 的实例。而在实际的生产环境中，这种情况每天只会发生一到五次。Prometheus 每秒从 850 个 Target 中采集约 110000 个样本，每次涉及多达 50 万个 Series。基准测试的结果如下：\n$$Heap \\space memory \\space usage \\space in \\space GB$$\n我们可以发现被查询的 Prometheus 实例消耗更多的内存，并且 2.0 版本的堆内存使用量比 1.5 版本减少了三到四倍之多。在测试开始后 6 小时左右，1.5 版本的 Prometheus 实例达到了峰值。这是因为我们将数据的保留期限设置为了 6 小时，而 V2 存储系统中删除数据的巨大开销导致了资源消耗的上升。\n$$CPU \\space usage \\space in \\space cores/second$$\nCPU 使用率的状况与内存类似，只不过查询操作对其的影响更大。总体来看，新的存储系统中 CPU 的使用率比原来减少了三到十倍。\n$$Disk \\space writes \\space in \\space MB/second$$\n我们可以通过这张图清楚地看到 Prometheus 1.5 是如何导致 SSD 磨损的。每当一个 Chunk 被持久化到 Series 对应的文件中，或删除旧数据并重写文件时，磁盘的写入速率就会大幅上升。而 Prometheus 2.0 每秒只会向预写日志中写入约 1MB 字节，写入速率只有在 Block 被持久化时才会出现峰值。新的设计方案成功地减少了约 97%～99%的磁盘写入。\n$$Disk \\space size \\space in \\space GB$$\n虽然两个版本的 Prometheus 使用的压缩算法近乎相同，但 Series Churn 的存在导致了两者占用磁盘空间的巨大差异。\n$$99th \\space percentile \\space query \\space latency \\space in \\space seconds$$\n在 Prometheus 1.5 中，查询延迟随着 Series 数量的不断上升越来越高。当数据达到保留期限并开始删除旧的 Series 时，查询延迟便又会趋于平稳。相比之下，Prometheus 2.0 的查询延迟从一开始就保持不变。\n$$Ingested \\space samples/second$$\n两个 Prometheus 2.0 实例的样本采集率完全吻合，并在数小时后开始变得不稳定。这并非是 Prometheus 自身的问题，而是集群中节点的负载过高而导致的。对于 Prometheus 1.5，即使节点仍有可用的 CPU 和内存资源，它的样本采集率也会因 Series Churn 而大大降低。\n基准测试的结果表明，Prometheus 2.0 在云服务器上的表现远远超出了最初设计时的预期。不过其成功与否还是要取决于用户的反馈，而非基准测试中的数字。\n总结 对于 Prometheus 来说，处理大规模 Series（即 High Cardinality）和独立样本的吞吐量是一项颇为艰巨的任务。不过，新的存储系统似乎已经准备好应对未来的挑战。\n使用 V3 存储系统的 Prometheus 2.0 的第一个 Alpha 版本 已经可供测试，预计会出现一些崩溃、死锁和其他 Bug。\n存储系统自身的代码可以在一个独立的 项目 中找到。它其实与 Prometheus 无关，因此可以广泛用于其他需要高效本地存储的时序数据库应用中。\n译者注：本文从宏观的角度介绍了 Prometheus 需要解决的问题，以及 1.X 版本（V2 存储系统）和 2.X 版本（V3 存储系统）的设计理念。想要了解其实现细节，除了阅读源码外还可以参考以下内容：\n关于 Prometheus 中的内存数据库：Prometheus TSDB (Part 1): The Head Block；\n关于预写日志和 Checkpoint：Prometheus TSDB (Part 2): WAL and Checkpoint；Write-Ahead Log；\n关于 mmap：Prometheus TSDB (Part 3): Memory Mapping of Head Chunks from Disk；Why mmap is faster than system calls；\n关于索引：Prometheus TSDB (Part 4): Persistent Block and its Index；\n关于查询：Prometheus TSDB (Part 5): Queries；\n关于压缩和保留：Prometheus TSDB (Part 6): Compaction and Retention；Time-series compression algorithms, explained；\n一些视频：PromCon 2017: Storing 16 Bytes at Scale - Fabian Reinartz；技术分享：Prometheus 是怎么存储数据的（陈皓）；\n","description":"","tags":["Prometheus","TSDB"],"title":"【译】从零开始编写一个时序数据库","uri":"/posts/writing-a-time-series-database-from-scratch/"},{"content":"前言 OpenShift 4.X 版本要求安装在操作系统为 CoreOS 的机器上，因此 官方文档 给出了使用 PXE 或 IPXE 引导 CoreOS 系统的方法。我们可以参考其操作流程，将一台 CentOS 7.X 的机器改写为 CoreOS 系统，步骤如下：\n从 镜像下载页 下载安装所需版本的 kernel、initramfs 和 rootfs 文件，并将 rootfs 和点火文件（*.ign）上传到自建的 HTTP 服务器上； 将 kernel 和 initramfs 文件拷贝到 CentOS 7.X 机器的 /boot 目录下； 根据需求修改 /boot/grub2 目录下的 grub.cfg 文件； 重启机器。 对于操作系统初学者（比如我）来说，很难想象仅依靠添加和修改文件就能改变一台计算机的操作系统。为了解其实现原理，我们将对 Linux 的启动流程进行讨论，并从中说明上述操作是如何影响操作系统的。\nLinux 启动流程 启动一台 Linux 机器的过程可以分为两个部分：Boot 和 Startup。其中，Boot 起始于计算机启动，在内核初始化完成且 systemd 进程开始加载后结束。紧接着， Startup 接管任务，使计算机达到一个用户可操作的状态。\nBoot 阶段 如上图所示，Boot 阶段又可以细分为三个部分：\nBIOS POST Boot Loader 内核初始化 BIOS POST 开机自检（Power On Self Test，POST）是 基本输入输出系统（Basic I/O System，BIOS）的一部分，也是启动 Linux 机器的第一个步骤。其工作对象是计算机硬件，因此对于任何操作系统都是相同的。POST 检查硬件的基本可操作性，若失败则 Boot 过程将会被终止。\nPOST 检查完毕后会发出一个 BIOS 中断调用 INT 13H，它将在任何可连接且可引导的磁盘上搜索含有有效引导记录的引导扇区（Boot Sector），通常是 主引导扇区。引导扇区中的主引导记录（Master Boot Record，MBR）将被加载到 RAM 中，然后控制权就会转移到其手中。\nBoot Loader 大多数 Linux 发行版使用三种 Boot Loader 程序：GRUB1、GRUB2 和 LILO，其中 GRUB2 是最新且使用最为广泛的。GRUB2 代表“GRand Unified Bootloader, version 2”，它能够定位操作系统内核并将其加载到内存中。GRUB2 还允许用户选择从几种不同的内核中引导计算机，如果更新的内核版本出现兼容性问题，我们就可以恢复到先前内核版本。\nGRUB1 的引导过程可以分为三个阶段：stage 1、stage 1.5 和 stage 2。虽然 GRUB2 中并没有 stage 的概念，但两者的工作方式基本相同。为了方便说明，我们在讨论 GRUB2 时将沿用 GRUB1 中 stage 的说法。\nstage 1 上文提到，BIOS 中断调用会定位主引导扇区，其结构如下图所示：\n主引导记录首部的引导代码便是 stage 1 文件 boot.img，它和 stage 1.5 文件 core.img 均位于 /boot/grub2/i386-pc 目录下：\n1 2 3 [root@bastion ~]# du -b /boot/grub2/i386-pc/*.img 512 /boot/grub2/i386-pc/boot.img 26664 /boot/grub2/i386-pc/core.img 它的作用是检查分区表是否正确，然后定位和加载 stage 1.5 文件。446 字节的 boot.img 放不下能够识别文件系统的代码，只能通过计算扇区的偏移量来寻找，因此 core.img 必须位于主引导记录和驱动器的第一个分区（Partition）之间。第一个分区从扇区 63 开始，与位于扇区 0 的主引导记录之间有 62 个扇区（每个 512 字节），有足够的空间存储大小不足 30000 字节的 core.img 文件。当 core.img 文件加载到 RAM 后，控制权也随之转移。\nstage 1.5 相比于只能读取原始扇区的 LILO，GRUB1 和 GRUB2 均可识别文件系统，这依赖于 stage 1.5 文件中内置的文件系统驱动程序。如果你拥有一台仍然使用 GRUB1 引导的 CentOS 6.X 机器，那么便可以在 /boot/grub/ 目录下找到这些适配不同文件系统的 stage 1.5 文件：\n1 2 3 4 5 6 7 8 9 10 11 [root@centos6.5 ~]# du -b /boot/grub/* | grep stage1_5 13380 /boot/grub/e2fs_stage1_5 12620 /boot/grub/fat_stage1_5 11748 /boot/grub/ffs_stage1_5 11756 /boot/grub/iso9660_stage1_5 13268 /boot/grub/jfs_stage1_5 11956 /boot/grub/minix_stage1_5 14412 /boot/grub/reiserfs_stage1_5 12024 /boot/grub/ufs2_stage1_5 11364 /boot/grub/vstafs_stage1_5 13964 /boot/grub/xfs_stage1_5 GRUB2 中的 core.img 不仅整合了上述文件系统驱动，还新增了菜单处理等模块，这也是其优于 GRUB1 的地方。我们可以在 GNU GRUB Manual 2.06: Images 中找到对各种 GRUB 镜像文件的详细介绍。\n既然 core.img 文件可以识别文件系统，那么它就能够根据安装时确定的系统路径定位和加载 stage 2 文件。同样，当 stage 2 文件加载到 RAM 后，控制权也随之转移。\nstage 2 stage 2 文件并非是一个 .img 的镜像，而是一些运行时内核模块：\n1 2 3 4 5 6 7 8 9 10 11 [root@bastion ~]# ls /boot/grub2/i386-pc/ | grep .mod | head acpi.mod adler32.mod affs.mod afs.mod ahci.mod all_video.mod aout.mod appendedsig.mod appended_signature_test.mod archelp.mod 它们的任务是根据 grub.cfg 文件的配置定位和加载内核文件，然后将控制权转交给 Linux 内核。grub.cfg 文件存放在 /boot/grub2 目录下：\n1 2 3 4 5 6 [root@bastion ~]# head /boot/grub2/grub.cfg -n 5 # # DO NOT EDIT THIS FILE # # It is automatically generated by grub2-mkconfig using templates # from /etc/grub.d and settings from /etc/default/grub 通过该文件的注释我们可以知道，它实际上是由 grub2-mkconfig 命令使用 /etc/grub.d 目录下的一些模板文件并根据 /etc/default/grub 文件中的设置生成的：\n1 2 [root@bastion ~]# ls /etc/grub.d/ 00_header 00_tuned 01_users 10_linux 20_linux_xen 20_ppc_terminfo 30_os-prober 40_custom 41_custom README 40_custom 和 41_custom 文件常用于用户对 GRUB2 配置的修改，实际上我们对机器的操作也是从这里开始的。为了让 GRUB2 在机器启动时选择 CoreOS 系统内核而非默认的 CentOS，需要在原始 40_custom 文件末尾添加如下内容：\n1 2 3 4 5 menuentry 'coreos' { set root='hd0,msdos1' linux16 /rhcos-live-kernel-x86_64 coreos.inst=yes coreos.inst.install_dev=vda rd.neednet=1 console=tty0 console=ttyS0 coreos.live.rootfs_url=http://{{HTTP-Server-Path}}/rhcos-live-rootfs.x86_64.img coreos.inst.ignition_url=http://{{HTTP-Server-Path}}/master.ign ip=dhcp initrd16 /rhcos-live-initramfs.x86_64.img } 所示的 Menuentry 由三条 Shell 命令组成：\nset root='hd0,msdos1' linux16 /rhcos-live-kernel-x86_64 ... initrd16 /rhcos-live-initramfs.x86_64.img 第一条命令指定了 GRUB2 的根目录，也就是 /boot 所在分区在计算机硬件上的位置。既然我们已经将内核文件拷贝到了 /boot 目录下，那么能够识别文件系统的 GRUB2 便可以定位和加载它。本例中hd代表硬盘（Hard Drive），0代表第一块硬盘，mosdos代表分区格式，1代表第一个分区。详细的硬件命名规范见 Naming Convention。\n第二条命令将从rhcos-live-kernel-x86_64（CoreOS 系统的内核文件）中以 16 位模式加载 Linux 内核映像，并通过coreos.live.rootfs_url和coreos.inst.ignition_url参数指定根文件系统（Rootfs）的镜像文件和点火文件的下载链接。ip=dhcp代表该计算机网络将由 DHCP 服务器动态配置，也可以按ip={{HostIP}}::{{Gateway}}:{{Genmask}}:{{Hostname}}::none nameserver={{DNSServer}}的格式写入静态配置。\n第三条命令将从rhcos-live-initramfs.x86_64.img中加载 RAM Filesystem。GRUB2 读取的内核文件实际上只包含了内核的核心模块，缺少硬件驱动模块的它无法完成 rootfs 的挂载。然而这些硬件驱动模块位于 /lib/modules/$(uname -r)/kernel/ 目录下，必须在 rootfs 挂载完毕后才能被识别和加载。为了解决这一问题，initramfs（前身为 initrd）应运而生。它是一个包含了必要驱动模块的临时 rootfs，内核可以从中加载所需的驱动程序。待真正的 rootfs 挂载完毕后，它便会从内存中移除。\n除此之外我们还需要将 /etc/default/grub 文件中的 GRUB_DEFAULT=saved 修改为 GRUB_DEFAULT=“coreos”，使其与 40_custom 文件中的menuentry 'coreos'对应。最后使用命令grub2-mkconfig -o /boot/grub2/grub.cfg来重新生成一份 grub.cfg 文件，这样计算机重启后 GRUB2 就会根据我们的配置去加载 CoreOS 系统的内核了。\n至此我们已经明白了为什么“仅依靠添加和修改文件就能改变一台计算机的操作系统”，但计算机想要达到用户可操作状态还远不止于此。让我们再来看看内核被加载到内存后发生了什么。\n内核初始化 不同内核及其相关文件位于 /boot 目录中，均以 vmlinuz 开头：\n1 2 3 4 [root@bastion ~]# ls /boot/ | grep vmlinuz vmlinuz-0-rescue-20210623110808105647395700239158 vmlinuz-4.18.0-305.12.1.el8_4.x86_64 vmlinuz-4.18.0-305.3.1.el8.x86_64 内核通过压缩自身来节省存储空间，所以当选定的内核被加载到内存中后，它首先需要进行解压缩（Extracting）。一旦解压完成，内核便会开始加载 systemd 并将控制权移交给它。\nStartup 阶段 systemd 是所有进程之父，它负责使计算机达到可以完成生产工作的状态。其功能比过去的 init 程序要丰富得多，包括挂载文件系统、启动和管理计算机所需的系统服务。当然你也可以将一些应用（如 Docker）以 systemd 的方式启动，但它们与 Linux 的启动无关，因此不在本文的讨论范围之内。\n首先，systemd 根据 /etc/fstab 文件中的配置挂载文件系统。然后读取 /etc 目录下的配置文件，包括其自身的配置文件 /etc/systemd/system/default.target。该文件指定了 systemd 需要引导计算机到达的最终目标和状态，实际上是一个软链接：\n1 2 [root@bastion ~]# ls /etc/systemd/system/default.target -l lrwxrwxrwx. 1 root root 37 Oct 17 2019 /etc/systemd/system/default.target -\u003e /lib/systemd/system/multi-user.target 在我使用的 bastion 服务器上，它指向的是 multi-user.target；对于带有图形化界面的桌面工作站，它通常指向 graphics.target；而对于单用户模式的机器，它将指向 emergency.target。target 等效于过去 SystemV 中的 运行级别（Runlevel），它提供了别名以实现向后兼容性：\nSystemV Runlevel systemd target systemd target alias Description halt.target 在不关闭电源的情况下中止系统。 0 poweroff.target runlevel0.target 中止系统并关闭电源。 s emergency.target 单用户模式。 没有服务正在运行，也未挂载文件系统。仅在主控制台上运行一个紧急 Shell，供用户与系统交互。 1 rescue.target runlevel1.target 一个基本系统。文件系统已挂载，只运行最基本的服务和主控制台上的紧急 Shell。 2 runlevel2.target 多用户模式。虽然还没有网络连接，但不依赖网络的所有非 GUI 服务都已运行。 3 multi-user.target runlevel3.target 所有服务都在运行，但只能使用命令行界面（CLI）。 4 runlevel4.target 用户自定义 5 graphical.target runlevel5.target 所有服务都在运行，并且可以使用图形化界面（GUI）。 6 reboot.target runlevel6.target 重启系统 每个 target 都在其配置文件中指定了一组依赖，由 systemd 负责启动。这些依赖是 Linux 达到某个运行级别所必须的服务（Service）。换句话说，当一个 target 配置文件中的所有 service 都已成功加载，那么系统就达到了该 target 对应的运行级别。\n下图展示了 systemd 启动过程中各 target 和 service 实现的一般顺序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 cryptsetup-pre.target veritysetup-pre.target | (various low-level v API VFS mounts: (various cryptsetup/veritysetup devices...) mqueue, configfs, | | debugfs, ...) v | | cryptsetup.target | | (various swap | | remote-fs-pre.target | devices...) | | | | | | | | | v | v local-fs-pre.target | | | (network file systems) | swap.target | | v v | | | v | remote-cryptsetup.target | | | (various low-level (various mounts and | remote-veritysetup.target | | | services: udevd, fsck services...) | | remote-fs.target | | tmpfiles, random | | | / | | seed, sysctl, ...) v | | / | | | local-fs.target | | / | | | | | | / \\____|______|_______________ ______|___________/ | / \\ / | / v | / sysinit.target | / | | / ______________________/|\\_____________________ | / / | | | \\ | / | | | | | | / v v | v | | / (various (various | (various | |/ timers...) paths...) | sockets...) | | | | | | | | v v | v | | timers.target paths.target | sockets.target | | | | | | v | v \\_______ | _____/ rescue.service | \\|/ | | v v | basic.target rescue.target | | | ________v____________________ | / | \\ | | | | | v v v | display- (various system (various system | manager.service services services) | | required for | | | graphical UIs) v v | | multi-user.target emergency.service | | | | \\_____________ | _____________/ v \\|/ emergency.target v graphical.target 如上图所示，想要到达到某个 target，其依赖的所有 target 和 service 就必须已完成加载。如实现 sysinit.target，需要先挂载文件系统（local-fs.target）、设置交换文件（swap.target）、初始化 udev （various low-level services）和设置加密服务（cryptsetup.target）等。不过，同一个 target 的不同依赖项可以并行执行。\n当计算机达到 multi-user.target 或 graphical.target 时，它的漫漫启动之路就走到了尽头。但为了满足用户多样的需求，它所面临的挑战其实才刚刚开始。\nFuture Work 前言提到 RedHat 官方给出了 IPXE/PXE 引导 CoreOS 系统的方法，那么这项技术又是如何实现的呢？ MBR 只有 446 个字节，可为什么 boot.img 文件却有 512 个字节？ 目前已经有越来越多的计算机使用 UEFI 和 GPT 来代替 BIOS 和 MBR，其优势体现在哪？ 我们该如何理解 systemd 的配置文件？如何使用 systemd 部署我们的应用？ 参考文献 Creating Red Hat Enterprise Linux CoreOS (RHCOS) machines by PXE or iPXE Booting\nBIOS - Wikipedia\nINT 13H - Wikipedia\n主引导记录 - Wikipedia\nAn Introduction To the Linux Boot and Startup Processes\nGNU GRUB Manual 2.06\nBootup(7) - Linux manual page\n","description":"","tags":["OS","Linux","CoreOs"],"title":"通过安装 CoreOS 系统了解 Linux 启动流程","uri":"/posts/understand-linux-boot-process-by-installing-coreos/"},{"content":"在使用高级语言，如 C、Java 编程时，我们无法了解程序在机器级别的实现。而使用汇编语言编写程序时，程序员则只能引用低级指令。由高级语言编写的程序可以在多种不同的机器上编译运行，而汇编语言则与机器特性高度相关。\n尽管编译器完成了生成汇编代码的大部分工作，但阅读和理解汇编语言对于程序员来说仍是一项重要的技能：\nThose who say “I understand the general principles, I don’t want to bother learning the details” are deluding themselves.\nIntel 处理器历史 程序编码 机器级代码 机器级程序的格式和行为是由指令集架构（Instruction Set Architecture，ISA）定义的，它包括处理器状态、指令格式以及每条指令对状态的影响。大多数 ISA，包括 x86-64，都将程序的行为描述为每条指令按顺序执行，且一条指令在下一条指令开始之前完成。虽然处理器硬件可以同时执行许多指令，但它采用了安全措施以确保其整体行为与 ISA 规定的操作顺序相匹配。\n汇编代码非常接近二进制格式的机器代码，但其文本格式更具可读性。一些对程序员隐藏的处理器状态在汇编代码中是可见的：\n程序计数器（PC）：在 x86-64 中被称为 %rip，代表即将执行的下一条指令在存储器中的地址； 整数寄存器文件（Register File）：最多可以存储 64 位的地址（与 C 中的指针对应）或整数数据。一些寄存器用于记录程序状态的关键部分，而其他寄存器则用于保存临时数据，例如 过程 中的参数和局部变量以及函数返回值； 条件码寄存器（Condition Code Registers）：保存了最近一次执行的算术或逻辑指令的状态信息，用于实现控制流或数据流中条件的改变，例如 If 语句和 While 语句； 向量寄存器（Vector Registers）：每个都可以保存一个或多个整数或浮点数值。 虽然 C 提供了一个模型，让我们可以在内存中声明和分配不同数据类型的对象。但机器级代码只会简单地将内存视为一个按字节寻址的数组，因此 C 中的聚合数据类型（如数组和结构体）在机器级代码中会表示为连续的字节集合。甚至对于标量数据类型（如int、char、float和bool等），汇编代码也不会区分有符号和无符号整数、不同类型的指针以及指针和整数。\n程序的可执行机器级代码、操作系统所需的一些信息、用于管理过程调用和返回的运行时栈以及用户请求的堆内存（如使用库函数malloc）共同构成了程序内存。它使用虚拟地址寻址，不过只有部分虚拟地址的范围有效。例如，x86-64 机器的虚拟地址必须将前 16 位设置为 0，因此其有效范围包含 $2^{48}$ （64 TB）字节。\n单个机器指令仅执行一些基本的操作，如将存储在寄存器中的两个数字相加、在内存和寄存器之间传输数据以及有条件地跳转到新的指令地址。编译器必须生成这样的指令序列来实现程序结构，例如算术表达式求值、循环或过程调用和返回。\n代码示例 示例 C 程序文件mstore.c中包含如下代码：\n1 2 3 4 5 long mult2(long, long); void multstore(long x, long y, long *dest) { long t = mult2(x, y); *dest = t; } 使用gcc -Og -S mstore.c命令即可生成汇编代码文件mstore.s，其中的-Og代表对代码进行优化。汇编代码中有多种声明，包括：\n每一行缩进的代码都对应着一条机器指令，图中的蓝色注解则标示了指令的作用，如pushq代表将寄存器%rbx中的内容压入程序栈。原程序中局部变量名称以及数据类型的所有信息都已被删除，随后我们可以在 Linux 系统中执行下列命令：\n1 2 gcc -Og -c mstore.c objdump -d mstore.o 第一条命令将生成二进制格式的目标代码文件mstore.o，第二条命令则是进行反汇编，即将机器级代码转换为一种与汇编语言格式类似的代码。图中的行号和斜体注释是为了方便说明加入的，左侧有 6 组十六进制字节序列，每个都是一条指令，右侧则显示了等效的汇编代码：\nx86-64 指令的长度范围为 1 到 15 个字节，常用的和 操作数 较少的指令比不太常用或操作数较多的指令需要更少的字节数； 从给定的起始位置开始，反汇编程序将字节唯一地解码为机器指令。例如，只有指令pushq %rbx以字节值 53 开头； 反汇编程序只是根据机器级代码文件中的字节序列来确定汇编代码，不需要访问源代码或汇编代码； 反汇编程序使用的指令命名规则与 GCC 生成的汇编代码略有不同，如许多指令中的后缀q被省略了。这些后缀是尺寸指示符，在大多数情况下可以省略。而反汇编器在call和ret指令中添加了后缀q，它们同样是可以省略的。 想要生成实际的可执行代码还需要在一组包含main函数的目标代码文件上运行链接器（Linker），假设 main.c 文件如下：\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u003cstdio.h\u003e void multstore(long, long, long *); int main() { long d; multstore(2, 3, \u0026d); printf(\"2 * 3 --\u003e %ld\\n\", d); return 0; } long mult2(long a, long b) { long s = a * b; return s; } 那么通过gcc -Og -o prog main.c mstore.c命令生成的可执行文件prog的大小就超过了mstore.o，因为它还包含了用于启动和终止程序以及与操作系统交互的代码。同样对prog文件使用objdump命令进行反汇编，其输出结果包含如下代码：\n与第一次反汇编的结果相比，区别主要在：\n链接器移动了代码的位置，因此图中左侧的地址不同； 链接器的一项任务是将函数调用与其可执行代码的位置进行匹配。在上图第 4 行，链接器填充了callq指令在调用函数mult2时应该使用的地址； 上图第 8，9 行填充的代码对结果没有任何影响，nop意为“No Operation”。插入它们是为了将函数的代码增加到 16 字节，这样可以更好地放置下一个代码块，从而提升存储器的系统性能。 数据格式 Intel 用术语“字”（Word）来表示 16 位数据类型，因此 32 位数被称为“双字”（Double Words），64 位数被称为“四字”（Quad Words）。在 x86-64 机器上 C 的原始数据类型大小如下：\nC declaration Intel data type Assembly-code suffix Size(bytes) char Byte b 1 short Word w 2 int Double word l 4 long Quad word q 8 char * Quad word q 8 float Single precision s 4 double Double precision l 8 大多数由 GCC 生成的汇编代码都有一个表示操作数大小的单字符后缀，如数据移动指令有四种变体：movb（移动字节）、movw（移动字）、movl（移动双字）和movq（移动四字）。值得一提是，后缀“l”即可以表示 4 字节整数又表示 8 字节双精度浮点数。这并不会引起歧义，因为涉及到浮点数的代码使用一组与整数完全不同的指令和寄存器。\n访问信息 上文提到，x86-64 机器的 CPU 中包含 16 个通用的整数寄存器，均可以存储 64 位的整数或指针数据：\n图中所有寄存器的名称均以 %r 开头，它们的演变顺序是从右往左的。前 8 个寄存器，即 %ax 到 %sp，是最初的 8086 机器使用的 8 个 16 位寄存器。随着 IA32 的出现，它们被扩展位 32 位，即 %eax 到 %esp。目前的 x86-64 机器将其进一步地扩展为 64 位，即 %rax 到 %rsp。同时还新添加了 8 个寄存器，即 %r8 到 %r15。图中右侧的注释说明了各个寄存器在典型程序中扮演的角色，其中最独特的是栈指针 %rsp，它用于指示运行时栈的结束位置。\n指令可以对存储在寄存器低位字节中的不同大小的数据进行操作。字节级操作可以访问最低有效字节，16 位操作可以访问最低有效 2 个字节，32 位操作可以访问最低有效 4 个字节，64 位操作则可以访问整个寄存器。\n操作数 大多数指令都有一个或多个操作数（Operand），指定了执行操作时使用的源数据和结果放置的位置。x86-64 机器支持的操作数格式如下：\n源数据既可以以常数形式给出，也可以从寄存器或内存中读取，结果则存储在寄存器或内存中。因此操作数有三种可能的类型：\n立即数（Immediate）：即常数值，书写方式为 $ 符号后面跟一个整数； 寄存器（Register）：寄存器中的内容。我们使用 $r_a$ 表示任意寄存器 $a$，使用 $R[r_a]$ 来表示它的值； 内存（Memory）引用：根据计算出的地址（也称有效地址）来访问某个内存位置。使用 $M_b[Addr]$ 表示在内存中从地址 $Addr$ 开始 $b$ 字节的引用，右下角标 $b$ 可以省略。 最通用的内存引用方式在上表底部：$M[Imm + R[r_b] + R[r_i]\\times s]$，常用于引用数组元素。\n假设下列值存储在内存或寄存器中指定的地址处：\n那么以下操作数存储的值分别为：\n%rax：0x100 0x104：地址为 0x104，值为 0xAB $0x108：0x108（立即数） (%rax)：地址为 0x100，值为 0xFF 9(%rax,%rdx)：地址为 9 + 0x100 + 0x3 = 0x10C，值为 0x11 260(%rcx,%rdx)：260 即十六进制数 0x104，因此地址为 0x104 + 0x1 + 0x3 = 0x108，值为 0x13 0xFC(,%rcx,4)：地址为 0xFC + 0x1 * 4 = 0x100，值为 0xFF %rax,%rdx,4：地址为：0x100 + 0x3 * 4 = 0x10C，值为 0x11 数据移动指令 在所有机器指令中使用最为频繁的便是数据移动指令，它们负责将数据从一处移动到另一处。我们将操作相同但操作数尺寸不同的指令划分为同一个指令类（Instruction Classes），下表列出的便是 MOV 指令类中的各种操作：\n上表中的 S 代表 源地址（Source），D 代表目的地址（Destination），I 代表立即数，R 代表寄存器。其中，移动指令不能将一个位于内存中的数据直接移动到内存中的另一个位置，必须经过一个寄存器中转。此外，当movl指令的目的地址为一个寄存器时，它不仅会把目的寄存器的较低四位更新为源数据，还会将较高四位的字节全部置 0。最后，movabsq指令只能将寄存器作为数据的目的地址。下面的例子中，左边为顺序执行的移动指令，右边为寄存器 %rax 中字节的变化情况：\n1 2 3 4 5 movabsq $0x0011223344556677, %rax %rax = 0011223344556677 movb $-1, %al %rax = 00112233445566FF movw $-1, %ax %rax = 001122334455FFFF movl $-1, %eax %rax = 00000000FFFFFFFF movq $-1, %rax %rax = FFFFFFFFFFFFFFFF 还有两类数据移动指令可以将较小尺寸的源数据移动到较大尺寸的目的寄存器，如下表所示：\n两者不同的是，movz指令将目的寄存器的剩余字节均填充为 0（零扩展），movs指令则将其填充为源操作数的最高有效位（符号扩展）。相比于符号扩展，零扩展缺少了指令movzlq。这是因为上文提到，使用movl指令移动数据到寄存器时，会将高位全部置为 0，其效果与零扩展无异。另外，符号扩展还多了一个指令cltq。它没有操作数，实际上等效于movslq %eax, %rax。\n在 C 中，对指针解引用（Dereference Pointer，*p）会将指针拷贝到寄存器中，然后将该寄存器作为内存地址的引用。一个简单的 C 程序如下：\n1 2 3 4 5 6 long exchange(long *xp, long y) { long x = *xp; *xp = y; return x; } 与之等效的汇编代码为：\n1 2 3 4 5 ; xp in %rdi, y in %rsi exchange: movq (%rdi), %rax movq %rsi, (%rdi) ret 最后两个数据移动指令分别是将数据压入程序栈（Stack）的push和将数据从程序栈中弹出的pop，如下表所示：\n在 x86-64 中，程序栈存储在内存中的某些区域中，其特性为后进先出（Last-in, First-out）。习惯上我们将栈顶画在底端，而栈顶元素的地址（由栈指针 %rsp 保存）是整个栈中最小的：\n如上图所示，想要将一个四字数据压入栈中，首先要把栈指针减 8，然后令源数据值成为新的栈顶元素。因此指令pushq %rax就等效于：\n1 2 3 ; subq 为减法运算，下一节会进行介绍 subq $8, \u0026rsp movq %rax, (%rsp) 同样，若想将栈顶的四字数据弹出栈，首先要把栈顶元素的值拷贝到寄存器中，然后再把栈指针加 8。因此指令popq %rdx就等效于：\n1 2 3 movq (%rsp), %rdx ; addq 为加法运算，下一节会进行介绍 addq $8, %rsp 算术和逻辑操作 下图列出了一些 x86-64 中的整数算术和逻辑操作，其中除了leaq外给出的都是指令类：\n以上操作可分为四类：加载有效地址（Load Effective Address）、一元（Unary）、二元（Binary）和移位（Shifts）。一元操作只有一个操作数，而二元操作则有两个。接下来我们将分别介绍它们。\n加载有效地址 加载有效地址的指令名为leaq，其实质是movq指令的一种变体。它会从内存中读取源操作数的地址拷贝到寄存器中，有时候也用于实现一些简单的运算。例如寄存器 %rdx 中存储的值为 x，那么指令leaq 7(%rdx, %rdx, 4), %rax的作用便是将寄存器 %rax 的值设为 5x+7。虽然leaq指令在执行运算方面的能力是有限的，但是与加法和乘法指令相比，它的性能更加出色。\n一元和二元操作 一元操作只有一个操作数，因此源地址和目的地址相同。如操作incq (%rsp)可以将程序栈顶增加 8 个字节的元素，类似于 C 中的自增运算符++。\n二元操作类似于 C 中的赋值运算符（Assignment Operator），如x -= y。举例来说，操作subq %rax, %rdx会将寄存器 %rdx 中的值减去寄存器 %rax 中的值。第一个操作数可以是立即数、寄存器或内存中的位置，第二个操作数则只能是寄存器或内存中的位置。与 MOV 类指令相同，二元操作的两个操作数不能同时为内存中的位置。\n移位操作 移位操作的第一个操作符为位数，可以是立即数，也可以是单字节的寄存器（通常使用寄存器 %cl）。第二个操作数为移位的值。可以是寄存器或内存中的位置。对于右移运算来说，SAR 代表算术右移，SHR 则代表逻辑右移。\n特殊算数操作 两个 64 位整型的积需要用 128 位来表示，因此 Intel 引入了 16 字节单位“八字”（Oct Word）来解决这一问题。下表展示了一些支持运算结果为八字的操作：\n我们在普通算数操作和特殊算数操作中均发现了imulq指令。第一种属于 IMUL 类，有两个操作数。其计算结果为 64 位（若超过 64 位，则截断高位），等效于第二章介绍的 无符号乘法 和 二进制补码乘法。第二种即是上表中的特殊算数操作，只有一个操作数，因此编译器可以根据操作数的数量区分它们。\n用于有符号乘法的操作被称为imulq，用于无符号乘法的则为mulq。两者的第一个参数为寄存器 %rax，第二个参数为源操作数。计算结果中较高 64 位将存储在寄存器 %rdx 中，较低 64 位则存储在寄存器 %rax 中。\n1 2 3 4 5 #include \u003cinttypes.h\u003e typedef unsigned __int128 uint128_t void store_uprod(uint128_t *dest, uint64_t x, uint64_t y){ *dest = x * (uint128_t)y; } 示例 C 程序在小端法机器上可转化为如下的汇编代码：\n1 2 3 4 5 6 ; dest in %rdi, x in %rsi, y in %rdx store_uprod movq %rsi, %rax mulq %rdx movq %rax, (%rdi) movq %rdx, 8(%rdi) 普通算数操作中没有提供除法或余数运算，因此需要使用特殊算数操作idivq和divq。与乘法类似，被除数的较高 64 位将存储在寄存器 %rdx 中，较低 64 位存储在寄存器 %rax 中。除数为操作数，商保存在寄存器 %rax 中，余数则保存在寄存器 %rdx 中。如果被除数只有 64 位，那么就应当将寄存器 %rdx 全部置为 0（无符号运算）或符号位（有符号运算）。后者可以使用cqto操作实现，它会从寄存器 %rax 中读取符号位，然后将其拷贝到寄存器 %rdx 内的每一位中。\n控制 上文中介绍的操作只考虑了顺序执行的代码，对于 C 中的 If、For、While 和 Switch 语句，它们还需要根据数据检验的结果来决定代码执行的顺序。机器级代码提供了两种基本机制来实现这种条件行为（Conditional Behavior），一种根据检验结果改变控制流（Control Flow），另一种则改变数据流（Data Flow）。\n条件码 上文提到，CPU 维护了一组单字节的条件码寄存器，它们记录了最近一次算数或逻辑操作结果的某些属性：\nCF（Carry Flag）：进位标识，记录最高有效位是否发生进位，用于检测无符号数操作的溢出； ZF（Zero Flag）：零标识，记录结果是否为 0； SF（Sign Flag）：符号标识，记录结果是否为负值； OF（Overflow Flag）：溢出标识，记录是否发生二进制补码溢出。 下列两个指令类可以在不改变任何其他寄存器的情况下设置条件码，如指令testq %rax, %rax可以检测寄存器 %rax 存储的值是正数、负数还是零：\n相比于直接读取，我们更常用以下三种方式使用条件码：\n根据条件码的组合将单个字节设置为 0 或 1； 有条件地跳转到程序的其他部分； 有条件地传输数据。 下列操作指令便可以实现上述第一种方式。注意，此处的指令后缀代表的并非是不同的操作数大小，而是不同的条件判断。如指令setl和setb分别代表 set less 和 set below：\n如下汇编代码首先比较了变量a和b的大小，然后根据结果把寄存器 %eax 的最低字节（即寄存器 %al）置为 0 或 1。movzbl指令的作用是将寄存器 %eax 的高位三个字节以及寄存器 %rax 的高位四个字节全部清零：\n1 2 3 4 5 6 7 ; int comp(data_t a, data_t b) ; a in rdi%, b in rsi% comp: cmpq %rsi, %rdi setl %al movzbl %al, %eax ret 跳转指令 跳转指令可以让程序转到一个全新的位置继续执行，该位置在汇编代码中使用标签（Label）来指定。\n1 2 3 4 5 movq $0, %rax jmp .L1 movq (rax%), %rdx .L1: popq %rdx 示例 C 程序中，指令jmp .L1将使程序跳过movq指令，开始执行popq操作。 下图展示了不同的跳转指令：\n​\njmp指令既可以是直接跳转，也可以是间接跳转。直接跳转的目标使用标签指定，而间接跳转的目标则需要从寄存器或内存中读取。上图中的其余指令均为条件跳转，它们根据条件判断的结果来决定是否执行跳转操作。注意，条件跳转均为直接跳转。\n在生成机器代码的过程中，汇编器和链接器会确定跳转目标（即目标指令的地址），并编码为跳转指令的一部分。其使用的编码方式有多种，但大多数与程序计数器相关，即比较目标指令的地址和紧挨着跳转指令的下一条指令的地址之间的差异。这样的说法有些绕口，我们以一个简单的例子来说明：\n1 2 3 4 5 6 7 8 movq %rdi%, %rax jmp .L2 .L3 sarq %rax .L2 testq %rax, %rax jg .L3 rep; ret 该汇编代码包含了两个跳转指令，第一个跳转到了更高的地址处，第二个则相反。而下图是对上述代码汇编然后再进行反汇编后的结果：\n在右侧注释中，第一个跳转指令为 +0x8，第二个跳转指令为 +0x5。再看左侧指令的字节编码，第一个指令的目标被编码为 0x03，将其加上下一条指令的地址 0x5，就得到了跳转目标指令的地址，即第四行指令的地址 0x8。同样，第二个指令的目标是使用单字节二进制补码表示的 0xf8（即十进制数 -8），将其加上下一条指令的地址 0xd，就得到了第三行指令的地址 0x5。\n当目标代码文件经过链接器处理后，这些指令会被重新分配地址。不过第二行和第五行跳转目标的编码依然不变，这种方式能够让指令编码更加紧凑：\n使用条件控制实现条件分支 若想将 C 中的条件表达式转化为机器代码，通常使用条件跳转和无条件跳转的组合。一个简单的 C 程序及其编译得到的汇编代码分别如下：\n1 2 3 4 5 6 7 8 long absdiff(long x, long y) { long result; if (x \u003c y) result = y - x; else result = x - y; } 1 2 3 4 5 6 7 8 9 10 11 12 ; long absdiff(long x, long y) ; x in %rdi, y in %rsi absdiff: cmpq %rsi, %rdi jge .L2 movq %rsi, %rax subq %rdi, %rax ret .L2 movq %rdi, %rax subq %rsi, %rax ret 实际上该汇编代码的控制流（Control Flow）更像是使用 Goto 语句将示例 C 程序改写后得到的结果，即先比较两数大小，然后根据结果决定是否跳转：\n1 2 3 4 5 6 7 8 9 10 11 long gotodiff(long x, long y) { long result; if (x \u003e= y) goto x_ge_y; result = y - x; return result; x_ge_y: result = x - y; return result; } 让我们推广到一般情况。假设 C 中的 If-else 语句模板为：\n1 2 3 4 if (test-expr) then-statement else else-statement 那么编译生成的汇编代码的控制流便可以用如下 C 程序描述：\n1 2 3 4 5 6 7 8 t = test-expr; if (!t) goto false; then-statement goto done; false: else-statement done: 使用条件移动实现条件分支 使用条件控制实现条件分支虽然简单有效，但在现代处理器上使用可能十分低效，我们更倾向于使用一些简单的条件移动指令。上一节中的 C 程序可以改写为：\n1 2 3 4 5 6 7 8 9 10 11 long cmovdiff(long x, long y) { long rval = y - x; long eval = x - y; long ntest = x \u003e= y; /* Line below requires single instruction: */ if (ntest) rval = eval; return rval; } 这段代码首先计算y-x和x-y，分别命名为变量rval和变量eval。然后测试x是否大于或等于y，如果是，则在返回rval之前将eval赋值给rval。编译器可以参考这种控制流生成汇编代码：\n1 2 3 4 5 6 7 8 9 10 ; long absdiff(long x, long y) ; x in %rdi, y in %rsi absdiff: movq %rsi, %rax subq %rdi, %rax movq %rdi, %rdx subq %rsi, %rdx cmpq %rsi, %rdi cmovge %rdx, %rax ret 上述代码中的comovge就是一个条件移动指令，只有cmpq指令判断一个值大于或等于（如后缀 ge 所示）另一个值时，它才会将数据从源寄存器传输到目标寄存器。\n我们必须了解现代处理器的运行方式，才能明白为什么基于条件移动的代码效率胜过条件控制。一条指令需要处理器通过一系列的步骤进行处理，每个步骤只执行所该指令的一小部分（例如，从内存中获取指令，确定指令类型、从内存读取、执行算术运算、写入内存和更新程序计数器等）。为了实现高性能，这条流水线（Pipelining）需要将指令的步骤重叠。例如，在执行前一条指令的算术运算的同时提取下一条指令。想要做到这一点，处理器需要能够提前确定即将执行的指令序列，以保证流水线上充满指令。\n当处理器遇到条件跳转（即分支）时，它将采用复杂的逻辑来预测跳转指令是否触发。如果预测结果足够可靠（现代微处理器试图达到 90% 的成功率），流水线就可以保持指令充满。但是，错误的预测将导致处理器不得不丢弃它在未来指令上已经完成的大部分工作，使程序性能严重下降。\n示例代码中x \u003e= y的判断结果显然是难以预测的，这种情况下使用条件控制代码的效率很低。而条件移动代码先计算出所有可能的结果，再根据条件判断决定返回值。这样控制流便不再依赖数据，处理器也就更容易保持其流水线的完整性，从而提升执行效率。全部的条件移动指令如下：\n编译器可以从目标寄存器的名称推断条件移动指令的操作数长度，因此相同的指令名称可用于不同的操作数长度。我们同样把条件分支推广到一般情况，使用 C 程序来描述条件移动的控制流：\n1 2 3 4 5 v = then - expr; ve = else - expr; t = test - expr; if (!t) v = ve; 当然，使用条件移动来实现条件分支是也有一些缺点的。因为无论判断结果如何，我们都会全部执行 then-expr 和 else-expr。一旦某一个分支中的指令发生错误，将影响整个程序的可用性。另外，如果 then-expr 或 else-expr 需要大量计算，而对应的条件又不成立时，处理器所做的工作就完全白费了。不过总体来说，条件移动的性能还是高于条件控制的，这也是 GCC 编译器使用它的原因。\n循环 Do-While 假设 C 中的 Do-While 语句模板为：\n1 2 3 do body-statement while (text-expr); 我们可以将其转化为 Goto 语句和 If-else 语句的组合：\n1 2 3 4 5 loop: body-statement t = text-expr; if (t) goto loop; 实际上汇编代码正是用这种方式来实现 Do-While 语句的控制流 。示例函数fact_do及其编译得到的汇编代码分别如下：\n1 2 3 4 5 6 7 8 9 10 long fact_do(long n) { long result = 1; do { result *= n; n = n - 1; } while (n \u003e 1); return result; } 1 2 3 4 5 6 7 8 9 10 ; long fact_do(long n) ; n in %rdi fact_do: movl $1, %eax .L2: imulq %rdi, %rax subq $1, %rdi cmpq $1, %rdi jq .L2 rep; ret While 假设 C 中的 While 语句模板为：\n1 2 while (text-expr); body-statement 我们有两种方法将其转化为 Goto 语句和 If-else 语句的组合。第一种被称为 Jump-to-Middle，通过一个非条件跳转在循环的结束执行条件判断：\n1 2 3 4 5 6 7 goto test; loop: body-statement test: t = text-expr; if (t) goto loop; 当 GCC 的优化参数指定为-Og时，汇编代码就会用这种方法来实现 While 语句的控制流 。示例函数fact_while及其编译得到的汇编代码分别如下：\n1 2 3 4 5 6 7 8 9 10 long fact_while(long n) { long result = 1; while (n \u003e 1) { result *= n; n = n - 1; } return result; } 1 2 3 4 5 6 7 8 9 10 11 12 ; long fact_while(long n) ; n in %rdi fact_while: movl $1, %eax jmp .L5 .L6: imulq %rdi, %rax subq $1, %rdi .L5: cmpq $1, %rdi jg .L6 rep; ret 第二种方法被称为 Guarded-Do，即首先将代码转化为 Do-While 循环，如果条件判断失败则通过条件移动指令跳过循环：\n1 2 3 4 5 6 7 8 9 t = test-expr; if (!t) goto done; loop: body-statement t = test-expr; if (t) goto loop; done: 当 GCC 的优化参数指定为更高级别的-O1时，汇编代码就会用这种方法来实现 While 语句的控制流 。上面提到的函数fact_while使用 Guarded-Do 编译得到的汇编代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ; long fact_while(long n) ; n in %rdi fact_while cmpq $1, %rdi jle .L7 movl $1, %eax .L6: imulq %rdi, %rax subq $1, %rdi cmpq $1, %rdi jne .L6 rep; ret .L7 movl $1, %eax ret For 假设 C 中的 For 语句模板为：\n1 2 for (init-expr; test-expr; update-expr) body-statement 显然可以将其转化为等效的 While 语句：\n1 2 3 4 5 init-expr; while (test-expr) { body-statement update-expr; } 因此，我们依然可以使用两种方法来将其转化为 Goto 语句和 If-else 语句的组合。\nJump-to-Middle：\n1 2 3 4 5 6 7 8 9 init-expr; goto test; loop: body-statement update-expr; test: t = test-expr; if (t) goto loop; Guarded-Do：\n1 2 3 4 5 6 7 8 9 10 11 init-expr; t = test-expr; if (!t) goto done; loop: body-statement update-expr; t = test-expr; if (t) goto loop; done: 同样地，编译器会根据给定的优化参数使用对应的控制流来生成汇编代码。\nSwitch GCC 会根据 Switch 语句中 Case 的数量和 Case 值的稀疏性（Sparsity）决定编译方法。当存在多种 Case（例如四个或更多），且它们跨越的值范围较小时会使用一种名为跳转表（Jump Table）的数据结构来实现。跳转表是一个数组，数组元素分别是 Switch 语句中每个 Case 对应的代码块地址。\n一个简单的 C 程序及其通过 GCC 编译后得到的汇编代码分别如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 void switch_eg(long x, long n, long *dest) { long val = x; switch (n) { case 100: val *= 13; break; case 102: val += 10; /* Fall through */ case 103: val += 11; break; case 104: case 106: val *= val; break; default: val = 0; break; } *dest = val; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ; void switch_eg(long x, long n, long *dest) ; x in %rdi, n in %rsi, dest in %rdx switch_eg: subq $100, %rsi cmpq $6, %rsi ja .L8 jmp *.L4(,%rsi,8) .L3: leaq (%rdi,%rdi,2), %rax leaq (%rdi,%rax,4), %rdi jmp .L2 .L5: addq $10, %rdi .L6: addq $11, %rdi jmp .L2 .L7: imulq %rdi, %rdi jmp .L2 .L8: movl $0, %edi .L2: movq %rdi, (%rdx) ret 为了便于理解，我们用 C 来描述其实现（运算符\u0026\u0026会为代码块的位置创建指针）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 void switch_eg_impl(long x, long n, long *dest) { /* Table of code pointers */ static void *jt[7] = { \u0026\u0026loc_A, \u0026\u0026loc_def, \u0026\u0026loc_B, \u0026\u0026loc_C, \u0026\u0026loc_D, \u0026\u0026loc_def, \u0026\u0026loc_D}; unsigned long index = n - 100; long val; if (index \u003e 6) goto loc_def; /* Multiway branch */ goto *jt[index]; loc_A: /* Case 100 */ val = x * 13; goto done; loc_B: /* Case 102 */ val = x + 10; loc_C: /* Case 103 */ val = x + 11; goto done; loc_D: /* Case 104, 106 */ val = x * x; goto done; loc_def: /* Default case */ val = 0; done: *dest = val; } 其中的goto *jt[index]就相当于汇编代码中第五行的jmp *.L4(,%rsi,8)。它是一个间接跳转指令，其操作数.L4(,%rsi,8)指定了由寄存器 %rsi 索引的内存地址（我们将在后续章节讨论数组是如何转化为机器代码的）。\n在汇编代码中，跳转表将被表示为：\n在名为.rodata的只读目标代码段中，包含了由七个quad（八字节）组成的序列，每个quad的值为汇编代码标签（如.L3）所对应的指令地址。\n过程 过程（Procedure）在不同的编程语言中有不同的叫法，如函数（Function）、方法（Method）、子程序（Subroutine）和处理器（Handler）等，不过它们都提供了一种打包代码的方法。该代码使用一组参数和可选的返回值来实现某些功能，并可以在程序的不同位置调用。\n假设过程 P 调用了过程 Q，Q 执行完毕后返回 P。那么：\n传递控制：在调用 Q 时程序计数器必须设置为其代码地址，同时在返回 P 时也要置为 P 的代码地址； 传递参数：P 必须能向 Q 提供一个或多个参数，反之 Q 必须能将值返回给 P； 分配和释放内存：在调用 Q 之前可能需要为其局部变量分配内存空间，并在返回时释放。 运行时栈 当过程所需的存储空间超过寄存器所能容纳的范围时，它便会在运行时栈上分配空间。上图为运行时栈的一般结构，主要由执行过程 Q 和调用过程 P 所需的帧（Frame）组成。每个过程可以在其栈帧内保存寄存器的值（图中的“Saved Registers”），为局部变量分配空间（图中的“Local Variables”），以及为其调用的过程设置参数（图中的“Argument”）等。当 P 调用 Q 时，它会将返回地址（图中“Return Address”）压入栈中。这样当 Q 返回时，程序便知道应该在哪里恢复执行 P。\n不过出于对时间和空间效率的考虑，程序只会为过程分配它们必须的栈帧。例如某个过程的参数不足 6 个，那么它们将全部存储在寄存器中而非运行时栈（图中的参数区是从 Argument 7 开始的）。许多过程的局部变量很少且不调用其他过程，那么就不需要运行时栈。\n接下来我们会对运行时栈中的各个区域进行更为深入地讨论。\n传递控制 在汇编代码中，过程间调用是通过指令call和ret来实现的。其中，指令call Q会将程序计数器设置为过程 Q 代码的起始地址，并将返回地址 A 压入栈中。指令ret则会将地址 A 从栈中弹出，然后将程序计数器设置为 A。实际上，地址 A 就是紧跟在call指令之后的指令的地址。\n下图说明了 代码示例 中主函数调用multstore后返回的过程中运行时栈的变化情况：\n其对应的反汇编代码如下：\n当主函数调用函数multstore时，程序计数器 %rip 中的值为call指令的地址 0x400563。该指令将返回地址 0x400568 压入栈中并跳转到函数multstore中的第一条指令，其地址为 0x0400540。 随后函数multstore继续执行，直到遇到地址 0x40054d 处的ret指令。 该指令将返回地址 0x400568 从栈中弹出并跳转到该地址对应的指令，主函数得以继续执行。\n传递参数 在 x86-64 机器上，最多可以通过寄存器传递六个参数：\n第七个及之后的参数将存储在运行时栈中。一个简单的 C 程序及其通过 GCC 编译后得到的汇编代码分别如下：\n1 2 3 4 5 6 7 8 9 10 11 void proc(long a1, long *a1p, int a2, int *a2p, short a3, short *a3p, char a4, char *a4p) { *a1p += a1; *a2p += a2; *a3p += a3; *a4p += a4; } 虽然参数a4的类型为char，但程序分别通过8(%rsp)和16(%rsp)来对它和指针类型的a4p进行寻址，说明两者均占用了栈中 8 个字节的空间。参数的栈帧结构如下图所示：\n局部变量 某些情况下，局部变量必须存储在运行时栈中：\n没有足够的寄存器来存储局部变量； 程序需要对局部变量进行取地址（\u0026）操作； 局部变量的类型为数组或结构体（我们将在后续的章节中讨论这种情况）。 示例函数call_proc的代码如下，其中调用的函数proc在上一节中已有介绍：\n1 2 3 4 5 6 7 8 9 long call_proc() { long x1 = 1; int x2 = 2; short x3 = 3; char x4 = 4; proc(x1, \u0026x1, x2, \u0026x2, x3, \u0026x3, x4, \u0026x4); return (x1 + x2) * (x3 - x4); } 该 C 程序生成的汇编代码十分冗长，但值得我们认真阅读和研究：\n图中“Set up arguments to proc”阶段对应的栈帧结构如下图所示：\n我们可以看到，局部变量x1到x4存储在栈中且有着不同的大小，分别占用字节 24-31、20-23、18-19 和 17。指向这些参数的指针均通过指令leaq生成，分别对应汇编代码中的第 7、10、12 和 14 行。前六个参数通过寄存器传递，而第七个和第八个参数则存储在栈中，相对于栈指针 %rsp 的偏移量为 0 和 8。\n当程序执行到“Call proc”阶段时，由于调用了函数proc，因此返回地址需要被压入到栈顶。此时的栈帧结构和上一节展示的相同，第七个参数和第八个参数相对于栈指针 %rsp 的偏移量分别变为了 8 和 16。\n被保存的寄存器 当一个过程（调用者）在调用另一个过程（被调用者）时，我们必须保证被调用者的执行不会影响到调用者后续计划使用的寄存器值。因此，x86-64 规定寄存器 %rbx、%rbp 和 %r12–%r15 为被调用者保存（Callee-saved）寄存器。被调用者通过将上述寄存器中的值压入栈中，然后在返回时将原始值弹出以实现调用前后寄存器的值不变。除栈指针 %rsp 以外的其他寄存器则为调用者保存（Caller-saved）寄存器，由于被调用者可以随意修改其中的值，因此调用者有责任保存调用之前的数据。\n递归 x86-64 允许过程以递归（Recursive）的方式调用自身，这是因为每个过程在运行时栈上的空间是私有的，因此多个未完成调用的局部变量不会互相干扰。递归调用实质上和调用一个其他过程没有区别。\n数组 对于长度为 L 的数据类型 T 和整型常量 N，声明T A[N]代表：\n内存中将为其分配 L * N 大小的空间； 数组名称 A 为指向数组头部（设为$x_A$）的指针，任意数组元素 i 的地址为 $x_A$ + L * i。 在 x86-64 中，内存引用指令的设计旨在简化对数组元素的访问。例如int类型的数组E[i]，E的地址存储在寄存器 %rdx 中，i 则存储在寄存器 %rcx 中。那么我们就可以通过指令movl(%rdx, %rcx, 4), %eax来将目标数组元素拷贝到寄存器 %eax 中。\nC 允许我们对指针进行计算。假设指针p指向一个长度为 L、数据类型为 T 的数组且其值为 $x_p$，则表达式p + i的值为 $x_p$ + L * i。进一步地，任意数组元素A[i]就等效于表达式*(A + i)。\n还是以数组E[i]为例，一些指针算数表达式的结果和对应的汇编指令如下：\n最后一个例子表明，我们可以计算同一数据结构中两个指针的差值。其结果的数据类型为long， 值为两个地址的差值除以数据类型的长度。\n多维数组 多维数组可以转化为一般数组的形式，例如声明int A[5][3]就等效为：\n1 2 typedef int row3_t[3]; row3_t A[5]; 数据类型row3_t是一个包含三个整型的数组，而数组A则包含五个这样的元素。我们将其推广到一般情况，若一个数组声明为T D[R][C]，则数组元素D[i][j]在内存中的地址为：\n$$\\tag{3.1} \\And D[i][j] = x_D + L(C * i + j)$$\n其中，$x_D$ 为数组地址，L 为数组元素的长度。\n一个 5 X 3 的整型数组A，其任意数组元素A[i][j]的地址用汇编代码的表示结果为：\n1 2 3 4 5 6 7 ; A in %rdi, i in % rsi and j in %rdx ; Compute 3i leaq (%rsi, %rsi, 2), %rax ; Compute A + 12i leaq (%rdi, %rax, 4), %rax ; Read from M[A + 12i + 4j] movl (%rax, %rdx, 4), %rax 定长数组 编译器可以对一些操作定长多维数组的代码进行优化。例如示例 C 程序执行矩阵运算：\n1 2 3 4 5 6 7 8 9 10 11 #define N 16 typedef int fix_matrix[N][N]; /* Compute i,k of fixed matrix product */ int fix_prod_ele(fix_matrix A, fix_matrix B, long i, long k) { long j; int result = 0; for (j = 0; j \u003c N; j++) result += A[i][j] * B[j][k]; return result; } 它可以被优化为下列代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #define N 16 typedef int fix_matrix[N][N]; /* Compute i,k of fixed matrix product */ fix_prod_ele_opt(fix_matrix A, fix_matrix B, long i, long k) { int *Aptr = \u0026A[i][0]; /* Points to elements in row i of A */ int *Bptr = \u0026B[0][k]; /* Points to elements in column k of B */ int *Bend = \u0026B[N][k]; /* Marks stopping point for Bptr */ int result = 0; do { /* No need for initial test */ result += *Aptr * *Bptr; /* Add next product to sum */ Aptr++; /* Move Aptr to next column */ Bptr += N; /* Move Bptr to next row */ } while (Bptr != Bend); /* Test for stopping point */ return result; } 比较两者我们可以发现，优化代码没有使用索引 j，并将所有的数组引用都转换为了指针引用。其中，Aptr指向矩阵 A 中第 i 行中的连续元素，Bptr指向矩阵 B 中第 k 列 中的连续元素。Bend则指向矩阵 B 中第 k 列中的第 N + 1 个元素，它就等于循环结束时Bptr的值。\n变长数组 C 只支持可以在编译时确定长度的多维数组(一维可能除外），声明可变大小的数组时必须使用malloc或calloc等函数来分配数组的存储空间，并且需要通过行主索引（Row-major Indexing）将多维数组的映射显式地编码为一维数组（就像 公式 3.1 做的那样）。\n我们可以编写一个函数来访问 n × n 数组的元素A[i][j]，如下所示：\n1 2 3 4 int var_ele(long n, int A[n][n], long i, long j) { return A[i][j]; } 参数n必须在参数A[n][n]之前，这样函数在处理数组时才能够明确其维度。该程序经 GCC 编译得到的汇编代码如下：\n1 2 3 4 5 6 7 8 9 10 ; int var_ele(long n, int A[n][n], long i, long j) ; n in %rdi, A in %rsi, i in %rdx, j in %rcx var_ele: ； Compute n * i imulq %rdx, %rdi ; Compute A + 4(n * i) leaq (%rsi,%rdi,4), %rax ; Read from M[A + 4(n * i) + j] movl (%rax,%rcx,4), %eax ret 数组元素A[i][j]地址的计算方式与定长多维数组类似，即 $x_A + 4(n * i) + 4j = x_A + 4(n * i + j)$。区别之处在于：\n由于添加了变量n，寄存器的使用方式不同； 使用了乘法指令imulq而不是leaq来计算n * i，因此程序的性能将会下降。 无论数组的长度是否为常量，编译器都会对操作多维数组的代码进行一定优化。虽然二者实现的细节有所差异，但其宗旨是一致的：避免直接使用 公式 3.1 而导致的乘法运算。\n异构数据结构 结构体 结构体（Structure）的每个部分都存储在连续的内存空间中，指向结构体的指针是其第一个字节的地址。一个简单的结构体声明如下：\n1 2 3 4 5 6 7 struct rec { int i; int j; int a[2]; int *p; }; 该结构体包含了四个字段：两个四字节的int变量，一个两元素的int型数组和一个八字节的int型指针，共占用 24 字节的内存空间：\n汇编代码可以通过在结构体地址上添加适当的偏移量来访问结构体中的任意字段。假设structure rec *类型的变量r存储在寄存器 %rdi 中，那么下列代码将元素r -\u003e i，即(*r).i，拷贝到r -\u003e j：\n1 2 movl (%rdi), %eax movl %eax, 4(%rdi) 同样，如果我们要获取结构体中数组元素rec.a[i]的地址\u0026(r -\u003e a[i])，只需：\n1 2 ; r in %rdi, i in %rdi leaq 8(%rdi, %rsi, 4), %rax 如上述汇编代码所示，程序对结构体字段的选择是在编译时完成的，因此机器代码中不含有任何有关字段声明或字段名称的信息。\n联合体 联合体（Unions）的声明和语法与结构体相同，但其不同字段均引用相同的内存空间。例如一个结构体和一个联合体的声明如下：\n1 2 3 4 5 6 7 8 9 10 11 12 struct S3 { char c; int i[2]; double v; }; union U3 { char c; int i[2]; double v; }; 那么S3和U3各个字段的偏移量和总数据长度为：\nType c i v Size S3 0 4 16 24 U3 0 0 0 8 对于类型为union U3 *的指针p，表达式p -\u003e c，p -\u003e i[0]和p -\u003e v都将引用联合体的起始地址。联合体的长度等于其所有字段中最大的数据长度，而结构体则等于其所有字段长度的和。我们将在下一节 数据对齐 中介绍为什么i在S3中的偏移量是 4 而不是 1，以及v的偏移量是 16，而不是 9 或 12。\n如果一个数据结构中的两个字段是互斥（Mutually Exclusive）的，我们就可以使用联合体来减少空间浪费。假如存在一个二叉树，其每个叶节点（Leaf node）都有两个双精度浮点值，每个内部节点（Internal node）都有两个指向子节点的指针。那么使用结构体实现该数据结构的代码为：\n1 2 3 4 5 6 7 8 struct node_s { // for internal node struct node_s *left; struct node_s *right; // for leaf node double data[2]; }; 这样每个节点都需要占用 32 字节的空间，其中只有一半会被节点真正使用。而如果我们使用联合体来实现：\n1 2 3 4 5 6 7 8 9 union node_u { struct { union node_u *left; union node_u *right; } internal; double data[2]; }; 则每个节点就只需占用 16 个字节的空间。对于类型为union node_u *的指针n，叶节点可以用n -\u003e data[0]和n -\u003e data[1]来表示，而内部节点指向的子节点可以用n -\u003e internal.left和n -\u003e internal.right来表示。\n联合体还可用于访问不同数据类型的位模式。假设我们需要将一个double类型的变量强制转换为unsigned long，则可以用以下方法实现：\n1 2 3 4 5 6 7 8 9 10 unsigned long double2bits(double d) { union { double d; unsigned long u; } temp; temp.d = d; return temp.u; }; 该代码将两种数据类型均存储在联合体temp中，使其有着相同的位级表达，从而实现了类型转换。\n数据对齐 许多计算机系统要求程序对象的地址必须是某个值（通常为 2，4 或 8）的倍数，其目的是简化处理器和内存系统之间的硬件接口设计。假设一个处理器每次都从内存中读取 8 个字节，而一个double类型的数据地址为 8 的倍数，那么它就可以被一次内存访问操作读取或写入。否则，它会被拆分为两个 8 字节的内存块，导致处理器操作次数的增加。\n无论数据对齐是否实现，x86-64 的硬件都将正常工作。但是 Intel 建议对齐数据以提高内存系统性能，其规则为：任何 K 字节对象的地址必须为 K 的倍数：\nK Types 1 char 2 short 4 int, float 8 long, double, char * 编译器会在汇编代码中放置指令，指示全局数据所需的对齐方式。比如我们在介绍跳转表时，示例代码中的.align 8就代表该指令后面的数据地址均为 8 的倍数。对于涉及到结构体的代码，编译器可能还需要在字段分配空间时插入间隙以实现数据对齐。一个简单结构体的声明如下：\n1 2 3 4 5 6 struct S1 { int i; char c; int j; }; 编译器实际为其分配的内存空间为：\n即然各字段的偏移量均为 4 的倍数，那么只要起始地址也为 4 的倍数，该结构体便实现了数据对齐。\n机器级代码中控制和数据的组合 理解指针 指针不是机器代码的一部分，而是 C 提供的一种用来帮助程序员避免寻址错误的抽象； 每个指针都有一个关联的类型。特殊的指针类型void *代表通用（范型）指针，可以显式或隐式地转换为有关联类型的指针； 每个指针都有一个值，其值为指定类型的某个对象的地址。若指针的值为NULL(0)，则代表它没有指向任何地方； 指针是操作符\u0026创建的，在机器代码中常用leaq指令实现； 使用操作符*来对指针解引用； 数组和指针之间关系密切； 指针可以被强制类型转换，但不会改变其值； 指针也可以指向函数，使程序可以在其他地方调用代码，其值为函数的机器代码中第一条指令的地址。 例如一个函数的原型为：\n1 int fun(int x, int *p); 我们可以声明一个指针来指向它：\n1 2 int (*fp)(int, int *) fp = fun; 这样便可以使用指针来调用该函数：\n1 2 int y =1; int result = fp(3, \u0026y); 内存引用越界和缓冲区溢出 C 不会对数组引用做任何的边界检查，这可能导致存储在栈中的数据因写入越界（Out-of-Bounds）的数组元素而损坏。如果程序随后以这种状态重新加载寄存器或执行ret指令，事情可能会变得十分严重。\n一种常见的状态损坏原因被称为缓存区溢出（Buffer Overflow），比较典型的例子是字符串的长度超过了栈中为其分配的字符数组空间：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Implementation of library function gets() */ char *gets(char *s) { int c; char *dest = s; while ((c = getchar()) != '\\n' \u0026\u0026 c != EOF) *dest++ = c; if (c == EOF \u0026\u0026 dest == s) /* No characters read */ return NULL; *dest++ = '\\0'; /* Terminate string */ return s; } /* Read input line and write it back */ void echo() { char buf[8]; /* Way too small! */ gets(buf); puts(buf); } 上半部分代码展示了库函数gets的实现过程：它首先从标准输入中读取一行字符串，当遇到换行符或某些错误条件时停止；然后它将读取内容复制到参数s指向的位置上，并以字符NULL结尾。gets的问题在于其无法确定是否分配了足够的空间来保存读取到的字符串。而在下半部分的函数echo中，我们故意将缓冲区做得非常小（只有 8 个字节），因此任何超过 7 个字符的字符串都会导致越界写入。随着字符串长度的增加，受到影响的栈区域会越来越多：\nCharacter Typed Additional Corrupted State 0-7 None 8-23 Unused Stack Space 24-31 Return Address 32+ Saved State in Caller 编译器为函数echo分配了 24 个字节的空间，因此读取少于 23 个字符的内容不会发生严重后果。但一旦超出这个范围，返回指针的值和其他保存的状态就会被破坏，ret指令将导致程序跳转到一个完全不可预知的位置。\n阻止缓冲区溢出攻击 缓冲区溢出甚至会导致计算机受到网络攻击，危害系统安全。受到攻击的程序会接受一个字符串，包含一些可执行代码的字节编码（也称漏洞利用代码），以及一些额外字节。只要额外字节能够将返回地址覆盖为指向漏洞利用代码的指针，程序执行ret指令时就会跳转到漏洞利用代码。现代编译器和操作系统已经开始引入一些机制来抵御这种攻击。\n随机化栈 只要我们在程序开始运行时在栈上分配 0 到 n 个字节之间的随机空间（例如使用分配函数alloca），就可以让相同的代码在多次运行中使用不同的栈地址。分配的空间范围 n 需要足够大，以便栈地址能够发生足够的变化。但又要足够小，否则程序将浪费太多的内存空间。\n不过攻击者可以在实际的漏洞利用代码前加入一长串的nop指令，从而暴力攻克随机化栈。因此随机化栈可以增加成功攻击系统所需的工作量，但不能提供可靠完善的保障。\n栈损坏检测 我们还可以在局部缓冲区和栈的剩余部分之间插入一个金丝雀值（Canary）来检测栈是否损坏：\n限制可执行代码区域 最后，我们可以限制只有保存了编译器生成的代码的那部分内存区域是可执行的，其他部分被限制为只读或只写。\n支持可变大小的栈帧 在之前我们介绍的汇编代码中，编译器为程序分配的运行时栈大小都是确定的。而有些程序则需要大小可变的运行时栈，例如：\n1 2 3 4 5 6 7 8 9 long vframe(long n, long idx, long *q) { long i; long *p[n]; p[0] = \u0026i; for (i = 1; i \u003c n; i++) p[i] = q; return *p[idx]; } 函数vframe声明了一个变长的指针数组*p[n]，将在栈中占用8n个字节的空间。由于n的值是由函数第一个参数给出的，因此编译器无法确定要为该函数的运行时栈分配多少空间。另外，程序涉及了对局部变量i地址的引用，所以该变量必须存储在栈中。当函数返回时，运行时栈需要被回收，栈指针将指向存储返回地址的位置。\n为了管理可变大小的栈帧，x86-64 使用寄存器 %rbp 作为帧指针（又称基指针，Base Pointer）。栈帧结构如下图所示：\n上文提到，%rbp 是一个被调用者保存寄存器，因此其原值将被保存在栈中（图中的“Saved %rbp”）。在程序的执行过程中，%rbp 会一直指向这个位置。一些固定长度的局部变量，比如i，就可以根据其相对于 %rbp 的偏移量来引用。函数编译后生成的部分汇编代码如下：\n函数首先将 %rbp 压入栈中，然后将其置为当前运行时栈的地址（汇编代码第 2 到 3 行）。接下来在栈上分配了 16 个字节的空间，栈指针指向图中 s1 的位置。前 8 个字节用于存储局部变量i，后 8 个字节并未使用。然后它开始为数组*p[n]分配空间，栈指针指向图中 s2 的位置。其相对于 s1 的偏移量是通过汇编代码第 5 到 7 行计算得到的：\n$$ (8n + 22) \\And (-16)= \\begin{cases} 8n + 8 \u0026\\text n 为奇数 \\cr 8n + 16 \u0026\\text n 为偶数 \\end{cases} $$\n由于该结果是 16 的倍数，因此实现了数据对齐。汇编代码第 8 到 10 行将图中 p 的值置为最接近 s2 的 8 的倍数，最终由寄存器 %rcx 中的值作为*p[n]的起始地址。假设 n 为 5 或 6，s1 的值为 2065 或 2064，则图中各值为：\nn s1 s2 p e1 e2 5 2065 2017 2024 1 7 6 2064 2000 2000 16 0 在函数执行结束前，汇编代码第 20 行的leave指令将帧指针恢复原值。相当于执行了以下两条指令：\n1 2 3 4 5 ; Set stack pointer to beginning of frame movq %rbp, %rsp ; Restore saved %rbp and set stack ptr ; to end of caller’s frame popq %rbp 浮点代码 处理器的浮点架构决定了操作浮点数的程序与机器级代码之间的映射方式，包括以下方面：\n浮点数是被如何被存储和访问的； 操作浮点数的指令； 浮点数如何作为参数传递给函数以及如何作为结果返回； 在函数调用时如何保存寄存器中的值。 我们的内容基于 AVX2（Adcanced Vector Extensions2）扩展，可以在 GCC 编译时加入-mavx2参数以生成这种架构的代码。\n如上图所示，AVX 架构允许浮点数存储在 16 个 YMM 寄存器中，每个长度均为 256 位（32 字节）。在对标量数据进行操作时，这些寄存器只会保存浮点型数据。而对于float类型和double类型，分别只有较低的 32 位和 64 位被使用。汇编代码通过 XMM 寄存器（即图中的“%xmm0”～“%xmm15”）的名称来引用它们，每个 XMM 寄存器是其对应的 YMM 寄存器的低 128 位（16 字节）。\n浮点数的移动和转换操作 下图展示了一组在内存和 XMM 寄存器之间和在两个 XMM 寄存器之间不进行类型转换的传输数据浮点数指令：\n前四个指令涉及到对内存的引用，我们称其为 Scalar 指令。它们操作的对象是单独的数值，只会改变目的寄存器低位的四字节或八字节。而后两个指令则属于 Packed 指令，它们会更新目的寄存器中全部的内容。\n浮点数和整型之间进行转换的操作指令为：\n在 C 和大多数编程语言中，浮点数转换为整型时会先进行截断操作，将数值向零舍入。而整型转化为浮点数时，我们一般会忽略第二个源操作数，因为它只影响结果的高位字节。因此，通常情况下第二个源操作数和目的操作数是相同的。\n最后则是两种浮点数之间的类型转换。假设寄存器 %xmm0 的低位四字节保存了一个单精度浮点值，那么我们很容易使用指令vcvtss2sd %xmm0, %xmm0, %xmm0来把它转换为双精度浮点值然后再存储于寄存器 %xmm0 的低位八字节中。然而实际上 GCC 生成的汇编代码为：\n1 2 3 4 ; Replicate first vector element vunpcklps %xmm0, %xmm0, %xmm0 ; Convert two vector elements to double vcvtps2pd %xmm0, %xmm0 指令vunpcklps会交错两个 XMM 寄存器中的值，并将它们存储在第三个寄存器中。举例来说，如果两个源寄存器中的值分别为$[s_3, s_2, s_1, s_0]$和$[d_3, d_2, d_1, d_0]$，那么目标寄存器的值就是$[s_1, d_1, s_0, d_0 ]$。在上述代码中，三个操作数使用相同的寄存器，因此如果寄存器 %xmm0 中的原始值为$[x_3, x_2, x_1, x_0]$，则该指令将更新其值为$[x_1, x_1, x_0, x_0]$。\n指令vcvtps2pd将源 XMM 寄存器中的两个低位单精度值扩展为目的 XMM 寄存器中的两个双精度值。设 $dx_0$ 为将 $x_0$ 转换为双精度的结果，那么该指令将得出值$[dx_0, dx_0]$。综上，这两条指令的最终效果是将寄存器 %xmm0 中低位四字节中的原始单精度值转换为双精度值，并将它的两个副本存储在寄存器 %xmm0 中。\n同样，GCC 为双精度值转换为单精度生成类似的汇编代码：\n1 2 3 4 ; Replicate first vector element vmovddup %xmm0, %xmm0 ; Convert two vector elements to single vcvtpd2psx %xmm0, %xmm0 假设寄存器 %xmm0 中包含了两个双精度值$[x_1, x_0]$，则执行上述代码的结果为$[0.0, 0.0, x_0, x_0]$。\n过程中的浮点代码 观察图 3.45 中最右侧的注释，我们可以发现以下准则：\n最多可以使用 XMM 寄存器传递八个参数（%xmm0-%xmm7），其余的则需要通过栈； 和 %rax 类似，%xmm0 通常作为浮点数的返回寄存器； 所有 XMM 寄存器均为调用者保存，被调用者可以覆盖其中任意一个； 当函数参数是指针、整数和浮点数的组合时，指针和整数在通用寄存器中传递，而浮点值则在 XMM 寄存器中传递。 浮点数的算数操作 浮点数算数操作指令如下，每个指令都有一到两个源操作数和一个目的操作数。第一个源操作数可以是 XMM 寄存器或内存中的位置，第二个源操作数和目的操作数只能是 XMM 寄存器；\n浮点常量的定义和使用 与整数算术运算不同，AVX 浮点运算不能将立即数作为操作数。编译器必须为常量分配和初始化存储空间，再由代码从内存中读取值。\n浮点代码中的位级运算 下图展示了两个用于 XMM 寄存器的位级运算指令，其操作对象均为 Packed 数值（XMM 寄存器中全部的 128 位）：\n浮点数的比较操作 AVX 2 为浮点数值的比较运算提供两种操作指令：\nInstruction Based on Description vucomiss $S_1$, $S_2$ $S_2 - S_1$ Compare Single Precision vucomisd $S_1$, $S_2$ $S_2 - S_1$ Compare Double Precision 上述指令与 条件码 中介绍的 CMP 指令类相似。参数 $S_2$ 必须是 XMM 寄存器，而参数 $S_1$ 则既可以是 XMM 寄存器，又可以是内存中的位置。\n浮点数比较操作会改变以下条件码的值，其中 PF 意为 Parity Flag：\nOrdering $S_2$:$S_1$ CF ZF PF Unordered 1 1 1 $S_2$ \u003c $S_1$ 1 0 0 $S_2$ = $S_1$ 0 1 0 $S_2$ \u003e $S_1$ 0 0 0 当任意操作数为 NaN 时，图中“Unordered”的情况就会出现。PF 的值将被置为 1，对应的跳转指令为jp。其余三种情况则和整型的 跳转指令 相同，分别为jb、je和ja。\n","description":"","tags":["OS"],"title":"CSAPP 读书笔记：程序的机器级表示","uri":"/posts/machine-level-representation-of-programs-note/"},{"content":"信息的存储 大多数机器使用字节（8 位的块）作为存储器中的最小寻址单元，而非访问单独的位。内存中的每一个字节都对应一个唯一的数字，即它的地址，所有可能的地址集合构成了 虚拟内存。它是由 DRAM、闪存（Flash Memory) 和磁盘存储共同实现的，而在程序看来则只是一个统一的字节数组。\n编译器和运行时系统负责将内存空间划分为更加易于管理的单元，从而存储不同的程序对象。例如，C 中指针的值代表其指向的存储块内第一个字节的虚拟地址。C 编译器还将每个指针与其类型信息联系起来，这样就可以根据指针类型生成不同的机器级代码来访问指针所指向的对象。不过机器级代码中并没有任何与类型相关的信息，编译器只是简单地把每个程序对象都视为一个字节块，而把程序视为一个字节序列。\n十六进制表示法 使用二进制表示位模式（Bit Pattern）会非常冗长，因为一个字节就包含了 8 位。而如果使用十进制，则不方便与位模式进行互相转化，因此我们采用十六进制（Hexadecimal）来书写位模式。一个十六进制数占 4 位，因此一个字节的取值范围就是 $00_{16}$ ~ $FF_{16}$ 。\n将一个二进制数字转化为十六进制数字，需要首先将其分为多个 4 位的组，然后再将每组数转化为十六进制。如果总位数不为 4 的倍数，那么最左边的一组可以少于四位，然后在首位补 0。如 $111100_2$ 可以分成 $0011_2$ 和 $1100_2$，转化结果为 $3C_{16}$ 。在 C 中，若一个常数以 0x 或 0X 作为前缀，则代表它是一个十六进制数字。\n数据大小 每台计算机都有一个字长（Word Size），它指定了指针数据的标准大小。如果一台机器的字长为 $w$ 位，那么虚拟地址的范围为 $0～2^w -1$，程序最多可以访问 $2^w$ 字节。32 位机器的虚拟地址大小约为 4 GB，而 64 位机器则能达到 16 EB。\nC 中几个基本数据类型的大小如下表所示：\nSigned Unsigned 32-bit 64-bit [signed] char unsigned char 1 1 short unsigned short 2 2 int unsigned 4 4 long unsigned long 4 8 int32_t uint_32t 4 4 int64_t uint_64t 8 8 char * 4 8 float 4 4 double 8 8 除char外，若不添加前缀unsigned，则默认使用有符号类型。指针类型的数据使用机器的全字长，如char *。由于某些数据类型的大小在不同机器上有所不同，因此开发人员应使程序对不同数据类型的确切大小不敏感，从而保证程序的可移植性（Portable）。\n寻址和字节顺序 对于包含多字节的程序对象，我们必须建立两个准则：这个对象的地址是什么和这些字节在内存中的排列顺序是怎样的。某些机器按照从最低有效字节到最高有效字节的顺序存储对象，该方式被称为小端法（Little Endian）；某些机器则与之相反，被称为大端法（Big Endian）。例如一个int类型的变量地址为 0x100，其值为十六进制的 0x1234567，那么上述两种机器存储该变量的方式分别如下：\nLittle Endian\n0x100 0x101 0x102 0x103 … 67 45 23 01 … Big Endian\n0x100 0x101 0x102 0x103 … 01 23 45 67 … 有些时候不同的字节存储顺序可能导致一些问题：\n不同类型的机器通过网络传递二进制数据，如小端法机器生成的数据发送到大端法机器上，程序收到的字节序列是反的。为了避免这一问题，发送方应先将数据转换为网络标准格式，接收方再将其转换为内部表达方式； 对于小端法机器，书写字节序列与书写数字的顺序相反； 某些使用强制类型转换（Cast）的程序，在不同类型的机器上编译运行的结果不同。 对于上述第三种情况，我们以一个程序为例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 #include \u003cstdio.h\u003e typedef unsigned char *byte_pointer; void show_bytes(byte_pointer start, size_t len) { size_t i; for (i = 0; i \u003c len; i++) { // %.2x 代表整数会被打印为至少两位（digits）的十六进制数字 printf(\"%.2x\", start[i]); } printf(\"\\n\"); } void show_int(int x) { show_bytes((byte_pointer)\u0026x, sizeof(int)); } void show_float(float x) { show_bytes((byte_pointer)\u0026x, sizeof(float)); } void show_pointer(void *x) { show_bytes((byte_pointer)\u0026x, sizeof(void *)); } int main() { int val = 12345; float fval = (float) val; int *pval = \u0026val; show_int(val); show_float(fval); show_pointer(pval); } 不同类型机器的输出结果如下：\nMachine val fval pval Linux32 0x39300000 0x00e44046 0xe4f9ffbf Windows32 0x39300000 0x00e44046 0xb4cc2200 Sun 0x00003039 0x4640e400 0xeffffa0c Linux64 0x39300000 0x00e44046 0xb811e5ffff7f0000 这是因为 Sun 系统采用大端法，其他三者采用小端法。对于指针类型的变量，不同操作系统在存储分配上有着不同的准则。同时，64 位系统使用 8 字节地址，32 位系统使用 4 字节地址，这导致了指针类型变量pval输出结果的不同。\n字符串 字符串在 C 中被编码为一个以NULL字符结尾（其值为 0）的字符数组，每个字符都由某种标准编码组成，如 ASCII 码。因此，如果我们执行上面的程序show_bytes(\"12345\", 6)，将得到31 32 33 34 35 00。\n由于字符串中各字符的排列顺序是由字符串本身决定的，因此字符串不会受到字节顺序的影响，除非字符使用两字节的 Unicode 进行编码。\n代码 不同类型的机器使用不同且不兼容的指令和编码方式，因此二进制代码很少能在不同机器和操作系统组合之间移植。\n布尔代数简介 几种布尔运算符的定义如下：\n～：非，相当于逻辑运算的 NOT； \u0026：与，相当于逻辑运算的 AND； |：或，相当于逻辑运算的 OR； ^：异或，相当于逻辑运算的 EXCLUSIVE-OR。若 $p = 0$，$q = 1$ 或 $p = 1$，$q = 0$ 时，$p \\text{\\textasciicircum} q = 1$。 布尔运算符可以应用于位向量，即固定长度的 0、1 序列。举例来说，若 a 为 [0110]，b 为 [0101]，那么：\nOperation Result ~a [1001] a \u0026 b [0100] a | b [0111] a ^ b [0011] C 中的位级运算 C 中支持按位布尔运算，上面提到的布尔运算符其实就是在 C 中使用的。一个使用布尔运算符的经典程序如下：\n1 2 3 4 5 6 7 8 #include \u003cstdio.h\u003e void inplace_swap(int *x, int *y) { *y = *x ^ *y; *x = *x ^ *y; *y = *x ^ *y; } 利用对于任意数 $a$ ，$a \\text{\\textasciicircum} a$ = 0 且 $0 \\text{\\textasciicircum} a = a$ 这一性质，该程序不使用中间变量便完成了变量值的交换。另外，上述程序的实现还建立在异或运算满足交换律和结合律的基础之上。\nC 中的逻辑运算 C 还提供了逻辑运算符，即||、\u0026\u0026和!。它们和位级运算的一个区别是，如果对第一个参数求值就能确定表达式的结果，便不会对第二个参数进行求值。如表达式a \u0026\u0026 5 / a不会导致除数为 0 的异常，而p \u0026\u0026 *p++也不会导致空指针引用异常。\nC 中的移位运算 C 中的移位运算有左移和右移两种，均不会改变位向量的长度。左移运算 $x « k$ 就是 $x$ 向左移动 $k$ 位，丢弃 $k$ 个高位，并在右端补充 $k$ 个 0。通常可以使用 $x « 1$ 和 $x « 2$ 分别代替 $x \\times 2$ 和 $x \\times 4$，因为位级运算拥有相比乘法更快的运算速度。\n右移运算分为两种形式，逻辑和算术。无符号数据必须使用逻辑右移，$x » k$ 将 x 的左端补充 $k$ 个 0 ，并丢弃 $k$ 个低位。而大多数机器使用算术右移处理有符号数据，$x » k$ 将 $x$ 的左端补充 $k$ 个最高有效位的拷贝，并丢弃 $k$ 个低位。\n加减乘除运算符的优先级大于移位运算符，因此 $1 « 2 + 3 « 4$ 等效于 $1 « (2 + 3) « 4$。\n整数的表示 无符号编码 一个长度为 $w$ 的位向量 $\\vec{x} = [x_{w-1},x_{w-2},…,x_0]$，它从二进制（Binary）转化为无符号编码（Unsigned）的公式为：\n$$ B2U_w(\\vec{x}) \\doteq \\displaystyle\\sum_{i=0}^{w - 1}x_i2^i $$\n其中， $\\doteq$ 符号表示等式的左手边被定义为右手边。无符号编码的最小值为位向量 [00…0]，即整数值 0。最大值为位向量 [11…1]，即整数值 $U\\max_w \\doteq \\displaystyle\\sum_{i=0}^{w - 1}2^i = 2^w -1$。函数 $B2U_w$ 是一个双射（Bijection）：对于每个长度为 $w$ 的位向量，都有唯一的整数值与之对应，反之亦然。\n二进制补码 二进制补码（Two’s-Complement Encoding）将位向量的符号位（即最高有效位）作为负权重（Negative Weight），符号位为 1 代表值为负，符号位为 0 代表值为正。如一个长度为 $w$ 的位向量 $\\vec{x} = [x_{w-1},x_{w-2},…,x_0]$，它从二进制转化为二进制补码的公式为：\n$$ B2T_w(\\vec{x}) \\doteq -x_{w - 1}2^{w - 1} + \\displaystyle\\sum_{i=0}^{w - 2}x_i2^i $$\n二进制补码的最小值为位向量 [10…0]，即整数值 $T\\min_w \\doteq -2^{w-1}$。最大值为位向量 [01…1]，即整数值 $T\\max_w \\doteq \\displaystyle\\sum_{i=0}^{w - 2}2^i = 2^{w-1} -1$。与二进制转化无符号编码类似，函数 $B2T_w$ 也是一个双射。而它们的最值之间有着如下性质：\n$$ |T\\min| =|T\\max| + 1$$ $$ U\\max = 2T\\max + 1$$\n特别地，整数 -1 和 $U\\max_w$的位级表示均为全 1：[11…1]，而整数 0 在两种表达方式中均为全 0：[00…0]。虽然 C 标准并没有限制有符号整数的二进制表达，但大多数机器都采用了二进制补码的方式。\n有符号数和无符号数的转换 在 C 中，有符号数和无符号数之间的转换是基于位级视角的，而非数字。例如：\n1 2 3 short int v = -12345; unsigned short uv = (unsigned short) v; printf(\"v = %d, uv = %u\\n\", v, uv); 输出结果为v = -12345，uv = 53191。这意味着在类型转换过程中位向量不变，但位向量转换到整数值的方式不同。根据推导，二进制补码转换为无符号数的公式如下：\n$$T2U_w(x) = \\begin{cases} x + 2^w \u0026\\text x \u003c 0 \\cr x \u0026\\text x \\geq 0 \\end{cases}$$\n如下图所示，非负数转换前后保持不变，负数则变成了一个更大的正数：\n而无符号数转换为二进制补码的公式则为：\n$$U2T_w(u) = \\begin{cases} u \u0026\\text u \\leq T\\max_w \\cr u - 2^w \u0026\\text u \u003e T\\max_w \\end{cases}$$\n如图所示，小于 $2 ^ {w - 1}$ （最高有效位为 0）的数转换前后保持不变，大于等于 $2 ^ {w - 1}$ （最高有效位为 1）的数将被转换为一个负数：\n通过上面的讨论我们发现，大于等于 0 且小于 $2 ^ {w - 1}$ 的值有相同的无符号和二进制补码表示。而这个范围之外的数，在转换过程中需要加上或减去 $2 ^ w$。\nC 中的有符号数和无符号数 通常我们默认数字是有符号的，除非加上后缀 U 或 u，如 12345U 和 0x1A2Bu 等。除了显式地使用强制类型转换（如上一节中的程序）以外，也可以将一种类型的表达式赋值给另一种变量，即隐式转换：\n1 2 3 4 int tx, ty; unsigned ux, uy; tx = ux; /* Cast to signed*/ uy = ty; /* Cast to usigned*/ 如果参与运算的两个数一个是有符号的，一个是无符号的，那么 C 会隐式地将有符号数转换为无符号数并假定两数均为非负后再进行计算。比如表达式 -1 \u003c 0U 的值为 false，因为 -1 会先被转换为无符号数再与 0 进行比较。\n扩展一个数的位级表示 要将一个无符号数转换为更大的数据类型，只需简单地在头部添加 0，这种运算被称为零扩展（Zero Extension）。而对于二进制补码，则需要在头部添加最高有效位（符号位），即符号扩展（Sign Extension）。\n当类型转换既改变数据类型的大小又改变符号类型时，则先改变大小，再改变有无符号。例如将一个short类型的变量转换为unsigned类型，它会先被转换为int类型，再被转换为unsigned类型。\n截断数字 将一个数转换为更小的数据类型时，截断数字的位数是不可避免的。如一个 $w$ 位的位向量 $\\vec{x} = [x_{w-1},x_{w-2},…,x_0]$ 被截断为 $k$ 位时，我们会丢弃 $w-k$ 个高位，得到 ${\\vec{x} = [x_{k-1},x_{k-2},…,x_0]}$。截断数字可能会导致值的变化：\n$$B2U_k([x_{k-1},x_{k-2},…,x_0]) = B2U_w([x_{w-1},x_{w-2},…,x_0]) \\bmod 2^k $$ $$B2T_k([x_{k-1},x_{k-2},…,x_0])= U2T_k(B2U_w([x_{w-1},x_{w-2},…,x_0]) \\bmod 2^k)$$\n通过上面几小节的讨论，我们发现无符号数与有符号数之间的隐式转换导致了一些与常识相悖的运算结果，这将导致一些很难发现的程序错误。因此很多编程语言，如 Java，不支持无符号数的使用。\n整数的运算 无符号加法 两个可用 $w$ 位无符号编码表示的非负整数 $x$ 和 $y$，其范围：$0 \\leq x, y \\leq 2^w -1$，那么它们的和：$0 \\leq x+ y \\leq 2^{w + 1} -2$ 就有可能需要用 $w+1$ 位来表示。如果出现溢出便丢弃高位，因此无符号加法（$+_w^u$）等价于计算 $(x+y) \\bmod 2^w$，即：\n$$x + _w^uy = \\begin{cases} x + y \u0026\\text x + y \u003c 2^w \u0026\\text Normal \\cr x + y - 2^w \u0026\\text 2^w \\leq x + y \u003c 2^{w+1} \u0026\\text \\space \\space \\space Overflow \\end{cases}$$\n模数加法构成了一种数学结构，即阿贝尔群（Abelian Group），它是可交换的和可结合的。$w$ 位无符号数的集合执行 $+_w^u$ 运算，对于每个值 $x$，必然有某个值 $-_w^ux$ 满足 $-_w^ux +_w^ux = 0$，该值被称为 $x$ 的逆元（Inverse）。当 $x = 0$ 时，其逆元自然为 0。当 $x \u003e 0$ 时，显然 $ (x + 2^w - x)\\bmod 2^w = 0$。由于 $0 \u003c 2^w -x \u003c 2^w$，因此 $2^w -x$ 便是 $x$ 的逆元。上述两种情况总结如下：\n$$ -_w^ux = \\begin{cases} x \u0026\\text x = 0 \\cr 2^w -x \u0026\\text x \u003e 0 \\end{cases}$$\n二进制补码加法 两个数的 $w$ 位二进制补码之和（$+_w^t$）与无符号之和有着完全相同的位级表示，因此对于 $-2^{w-1} \\leq x, y \\leq 2^{w-1} -1$ ，有：\n$$\\begin{split} x +_w^ty \u0026=U2T_w(T2U_w(x) +_w^uT2U_w(y))\\cr \u0026=U2T_w[(x+y)\\bmod 2^w] \\end{split}$$\n进一步地，我们根据两数之和的范围，将上述结果分情况讨论，从而得到：\n$$x + _w^ty = \\begin{cases} x + y + 2^w \u0026\\text x + y \u003c -2^{w-1} \u0026\\text \\space \\space \\space Negative \\space \\space Overflow \\cr x + y \u0026\\text -2^{w-1} \\leq x + y \u003c 2^{w-1} \u0026\\text Normal \\cr x + y - 2^w \u0026\\text x + y \\geq 2^{w-1} \u0026\\text \\space \\space \\space Positive \\space \\space Overflow \\end{cases}$$\n因此，若 $x\u003e0, y\u003e0, x+_w^ty\\leq 0$，那么结果便出现了正溢出；若 $x\u003c0, y\u003c0, x+_w^ty\\geq 0$，结果便出现了负溢出。\n二进制补码的逆元计算公式如下：\n$$ -_w^tx = \\begin{cases} T\\min_w \u0026\\text x = T\\min_w \\cr -x \u0026\\text x \u003e T\\min_w \\end{cases}$$\n无符号乘法 无符号乘法运算（$\\times_w^u$）与加法类似，都可以转换为对 $2^w$ 的模运算：\n$$x\\times_w^uy=(x \\times y)\\bmod2^w$$\n二进制补码乘法 同样与加法类似，两个数的 $w$ 位二进制补码之积（$\\times_w^t$）与无符号之积有着完全相同的位级表示，因此：\n$$\\begin{split} x \\times_w^ty \u0026=U2T_w(T2U_w(x)\\times_w^uT2U_w(y))\\cr \u0026=U2T_w[(x \\times y)\\bmod 2^w] \\end{split}$$\n乘以常数 整数乘法运算在许多机器上运行缓慢，一个重要的优化便是使用移位运算和加法运算来代替它。我们首先考虑乘以 2 的幂的情况，然后推广到任意常数。若存在位向量 $[x_{w-1},x_{w-2},…,x_0]$，$x \\times 2^k$ 可以表示为在其右端添加 $k$ 个 0，即 $[x_{w-1},x_{w-2},…,x_0,0,…,0]$。因此在 C 中，对于整数 $x$ （无论是无符号数还是二进制补码）和 无符号数 $k$，$x \\times 2^k$ 就等于 $x«k$。\n如果一个常数可以拆分为 2 的幂的和，那么我们便可以使用左移运算和加（减）法运算来替换与相关的乘法运算。如 $14=2^3+2^2+2^1$，那么 $x\\times14=(x«3)+(x«2)+(x«1)$。\n除以 2 的幂 我们使用右移运算来代替除法运算，逻辑右移和算术右移分别适用于无符号数和二进制补码。由于结果为整数，因此很可能需要进行舍入（Round）。我们定义 $⌊ ⌋$ 为向下取整，$⌈ ⌉$ 为向上取整。如 $⌊3.14⌋=3$，$⌊-3.14⌋=-4$，而 $⌈3.14⌉=4$，$⌈-3.14⌉=-3$。\n在 C 中，对于无符号数 $x, k$， $x»k=⌊x/2^k⌋$；对于二进制补码 $x$ 和无符号数 $k$，则有 $x»k=⌊x/2^k⌋$。前者为逻辑右移，后者为算术右移。\n考虑到若 $x\u003c0$，$x/y$ 的结果应为 $⌈x/y⌉$，而非 $⌊x/y⌋$。我们可以利用性质：$⌈x/y⌉=⌊(x+y-1)/y⌋$，来修正这种不合适的舍入。因此，对于 $x\u003c0$ 的二进制补码除法，应使用：$(x+(1«k)-1)»k=⌈x/2^k⌉$。综上，二进制补码除以 2 的幂 $x/2^k$ 可以用三元运算符表示为：\n1 (x\u003c0 ? x+(1\u003c\u003ck)-1 : x) \u003e\u003e k 与乘法不同，除法无法推广到任意常数。\n浮点 二进制小数 十进制小数的表示方法为 $d_md_{m-1}…d_1d_0.d_{-1}d_{-2}…d_{-n}$，其中 $d_i$ 为 0～9 的整数。那么该数的大小为：\n$$d=\\displaystyle\\sum_{i=-n}^{m}10^id_i$$\n小数点左边的数的权值为 10 的非负幂，右边的则为 10 的负幂。类似地，我们可以得出二进制小数的表示方法。$b_i$ 为 0 或 1，则二进制数 $b_mb_{m-1}…b_1b_0.b_{-1}b_{-2}…b{-n}$ 的值为：\n$$b=\\displaystyle\\sum_{i=-n}^{m}2^ib_i$$\n二进制小数点向左移动一位，相当于数字除以 2。向右移动一位，则相当于数字乘以 2。这种方法只能表示可转化为 $x \\times 2^y$ 形式的数，无法精确表示如 $\\frac{1}{3}$、$\\frac{5}{7}$ 这样的数。\nIEEE 浮点数表示 二进制小数的表示方法难以表示很大的数，我们更希望通过给定 $x, y$ 的值来表示形如 $x \\times 2^y$ 的数。IEEE 浮点数标准使用 $V=(-1)^s\\times M \\times 2^E$ 的形式来表示小数：\n符号 $s$：为 1 代表负值，为 0 代表正值； 有效数 $M$：一个二进制小数，范围在 1 到 $2-\\varepsilon$ 或 0 到 $1-\\varepsilon$ 之间； 指数 $E$：2 的幂指数，有可能是负数。 因此，浮点数的位级表达分为了三个部分：\n一个符号位 $s$; $k$ 位的指数域 $exp=e_{k-1}…e_1e_0$ 编码指数 $E$； $n$ 位的小数域 $frac=f_{n-1}…f_1f_0$ 编码有效数 $M$。 对于 C 中的float类型，$s=1, k=8, n=23$。而对于double类型，$s=1, k=11, n=52$。IEEE 浮点数表示法有三种情况，如下图所示：\n第一种情况是最常见的，即指数域不全为 0，也不全为 1。在这种情况下，指数域的值为 $E=e-Bias$，其中 $e$ 是一个位级表达为 $e_{k-1}…e_1e_0$ 的无符号数，$Bias$ 则是一个等于 $2^{k-1}-1$ 的常数。小数域的值为 $M=1+f$，其中，$f$ 是一个二进制小数 $0.f_{n-1}…f_1f_0$。\n第二张情况是指数域全为 0，这样所表示的数就是非标准化形式的。在这种情况下，$E=1-Bias, M=f$。非标准化数可以表示第一种情况无法表示的 0 以及非常接近 0 的数字。\n第三种情况是指数域全为 1 时出现的。若小数域全为 0，得到的值则为 $\\pm \\infin$。若小数域不全为 0，则结果为 NaN，即不是一个数字。比如计算 $\\infin -\\infin$ 和 $\\sqrt{-1}$，就会得到这样的结果。\n以 8 位浮点数为例，$s=1, k=4, n=3$，此时偏移量 $Bias=2^{4-1}-1=7$。最靠近 0 的是非标准化数，$E=1-Bias=-6$，$2^E=\\frac{1}{64}$，$M=f=0,\\frac{1}{8},…,\\frac{7}{8}$，因此浮点数 $V$ 的范围就是 0 ～$\\frac{7}{8\\times64}=\\frac{7}{512}$。而对于最小的标准数来说，指数域为 [0001]，因此 $E=e-Bias=-6$，小数域 $M=1+f=1,\\frac{9}{8},…\\frac{15}{8}$，浮点数 $V$ 的范围为 $\\frac{8}{512}=\\frac{1}{64}$ ~ $\\frac{15}{512}$。\n我们可以观察到最大非标准数和最小标准数分别为 $\\frac{7}{512}$ 和 $\\frac{8}{512}$，这种平滑的过渡得益于我们将非标准数的 $E$ 使用 $1-Bias$ 来计算，而非 $-Bias$。\n在这种条件下，当指数域为 [1110]，$E=e-Bias=7, 2^E=128$，小数域 $M=1+0.111_2=\\frac{15}{8}$ 时，$V$ 取到最大值 240，超出这个值就会溢出到 $+\\infin$。值得一提的是，IEEE 浮点数可以使用整数排序函数来进行排序。\n舍入 对浮点数的表示限制了其范围和精度，因此浮点计算只能近似地表示实数计算。IEEE 浮点数格式定义了四种不同的舍入方式：\n向偶数舍入（Round-to-even），也称向最接近的数舍入（Round-to-nearest），是默认的方法。它试图找到一个最接近的匹配值，对于中间值（如表中的 1.5），则使结果的最低有效位为偶数（舍入为 2）。其他三种方法用来确定值的上下界。\n即使在舍入到小数的情况下，也可以使用整数舍入，只需简单地考虑最低有效数字是偶数还是奇数。如保留两位小数，我们把十进制小数 1.234999 舍入到 1.23，把 1.235001 舍入到 1.24，而 1.235 和 1.245 均舍入到 1.24。这种方法同样可以推广到二进制小数，此时应将中间值舍入到最低有效位等于 0 的数。\n浮点运算 浮点数的加法和乘法是实际运算后进行舍入后的结果，即对于实数 $x, y$，以及运算 $\\odot$，结果为 $Round(x\\odot y)$。IEEE 标准规定了浮点数运算的行为，这意味着它不依赖于任何具体的硬件或软件，从而实现了可移植性。\n上文提到整数的加法和乘法形成了阿贝尔群，而实数亦如此，但浮点数还要考虑舍入对其特性的影响。浮点数 $\\infin$ 和 NaN 没有逆元，加法也只满足交换律但不满足结合律。类似地，浮点数乘法只满足交换律，而不满足结合律和分配律。这些特性的缺少对程序员有着非常重要的影响，如示例的简单程序：\n1 2 x = a + b + c; y = b + c + d; 编译器可以生成下列代码以省去一次浮点加法运算，从而提升效率：\n1 2 3 t = b + c; x = t + a; y = t + d; 由于使用了加法结合律，计算结果可能与预期不同。因此大多数编译器对浮点运算的优化都较为保守，以免产生错误的结果。\n","description":"","tags":["OS"],"title":"CSAPP 读书笔记：信息的表示和处理","uri":"/posts/representing-and-manipulating-information-note/"},{"content":"信息就是 Bits + Context 一堆二进制位（Bits）可以表示系统中的所有信息，包括磁盘中的文件、内存中的程序和用户数据以及网络中传输的数据，唯一可以区分它们的便是我们查看这些数据对象时所处的上下文（Context）。例如，相同的一串二进制位在不同的上下文中可能代表一个整数，也可能代表一个浮点数，甚至字符串。\n程序的转化过程 一个简单的 C 程序hello.c如下：\n1 2 3 4 5 6 7 #include \u003cstdio.h\u003e int main() { printf(\"hello world\\n\"); return 0; } 高级的 C 程序文件hello.c被转化为一系列低级的机器语言指令，最后以二进制可执行文件存储在磁盘中。\n预处理阶段（Preprocessor）：预处理器修改 C 程序文件中以#号开头的命令。如示例程序中的#include \u003cstdio.h\u003e指示预处理器系统读取头文件stdio.h的内容，然后将其直接插入到程序文本中。生成的新程序文件为hello.i； 编译阶段（Compilation）：编译器将hello.i文件转化为由汇编语言组成的hello.s文件。每条汇编语句都描述了一条低级的机器语言指令，不同高级语言编译后的汇编语句是通用的； 汇编阶段（Assembly）：汇编器将hello.s文件转化为由二进制机器语言指令的hello.o文件。如果我们用文本编辑器打开该文件，将会出现一堆乱码； 链接阶段（Linking）：由于我们的程序调用了printf函数，而它存在于一个名为printf.o的预编译文件中。链接器负责将该文件并入，得到最终的可执行文件hello。 系统的硬件组成 总线（Buses）：贯穿整个系统的一组电子管道，负责在各个组件之间传递给定大小的字节块（也称 Word）。Word 的大小是系统的基本参数，一般有 4 字节（32 位）或 8 字节（64 位）两种； I/O 设备：系统与外部世界连接的桥梁。下图中的 I/O 设备包括用于用户输入的键盘⌨️和鼠标🖱️、用于展示的用户输出以及用于长期存储数据和程序的磁盘驱动，每个 I/O 设备都通过控制器（Controller）或适配器（Adapter）与 I/O 总线相连。其中，控制器是设备自身或系统主板（Motherboard）上的芯片组，而适配器则是插在主板插槽上的卡； 主存储器（Main Memory）：处理器执行程序时存放程序和数据的临时存储，简称主存。从物理上来说，主存储器是由 动态随机存取存储器（Dynamic Random Access Memory，DRAM）芯片组成的集合。而它在逻辑上则是一个线性的字节数组，每个字节都有其唯一地址； CPU（Central Processing Unit ）: 解释或执行主存储器中指令的引擎。 PC：CPU 的核心是一个大小与 Word 相同的存储设备（或寄存器），它被称为程序计数器（Program Counter，PC）。PC 始终指向主存储器中某条机器语言指令，即内含其地址。CPU 会不断地重复执行 PC 指向的机器指令，并更新 PC 使其指向下一条指令； Register File：寄存器文件是一个由一组以 Word 为大小的寄存器组成的小型存储设备，每个寄存器都有其唯一名称； ALU： 算术/逻辑单元（Arithmetic/Logic Unit），能够计算新的数据和地址值。 程序的运行过程 从键盘上读取命令：当我们在终端中输入命令./hello后，Bash 程序将逐一读取命令字符串到寄存器（Register），然后存储于主存中；\n从磁盘加载可执行文件到主存：当我们输入回车键后，Bash 程序得知输入结束，于是开始加载可执行文件hello，其中的代码和数据将通过 直接存储器访问技术（DMA, Direct Memory Access）从磁盘拷贝到主存中；\n从主存中将结果输出到显示器：处理器执行hello文件中的机器语言指令，然后将hello world\\n字符串中的字节从主存拷贝到寄存器文件中，最终传输到用于展示的屏幕🖥上。\n高速缓冲存储 在程序运行的过程中，操作系统花费了大量时间将信息从一个地方拷贝另一个地方，CPU 从寄存器文件中读取数据要比从主存储器中读取快近百倍。因此系统设计者引入了一种更小、更快的存储设备，即高速缓冲存储（Cache Memories 或 Caches），它会暂存 CPU 在短期内需要用到的数据。\nL1 级别的 Caches 位于 CPU 芯片之上，容量为上万字节并且拥有和寄存器文件相当的访问速度。而 L2 级别的 Caches 则通过一条特殊总线连接到 CPU，容量可达十万到百万字节。虽然其访问速度比 L1 Cache 慢五倍左右，但依然比主存储器要快五到十倍。在某些先进的操作系统中，还会使用 L3 级别的 Cache，它们均是通过静态随机存取存储器（SRAM, Static Random Access Memory）实现的。\n计算机系统中的存储器层级结构如下图所示，低层次的存储设备作为相邻高层次设备的缓存：\n操作系统对硬件的管理 操作系统是应用程序和硬件的中间层，应用程序对硬件的所有操作必须通过操作系统实现。\n操作系统有两个主要功能：防止硬件被失控的应用程序所滥用；为应用程序提供一种简单而统一的机制来处理复杂且通常差异很大的低级硬件设备。上述两种功能是通过下图中的几个基本抽象实现的：\n文件（Files）是对 I/O 设备的抽象，虚拟内存 (Virtual Memory) 是对主存储器和 I/O 设备的抽象，而进程（Processes）则是对处理器，主存储器和 I/O 设备的抽象。\n进程 进程是操作系统对正在运行的程序的抽象，它让我们的hello程序看起来像是系统中唯一运行的程序。多个进程可以并发地在同一个系统中运行，同时每个进程都好像在独占硬件的使用权。而实际上不同进程中的指令是交错执行的，基于下图中的上下文切换：\n操作系统会跟踪进程运行所需的所有状态信息，即上下文，它包括了程序计数器 PC 的当前值，寄存器文件和主存储器的内容之类的信息。 在任何时间点，单处理器系统只能为单个进程执行代码。 当操作系统决定将控制权从当前进程转移到某个新进程时，它需要首先保存当前进程的上下文，然后还原新进程的上下文，最后将控制权传递给新进程以完成上下文切换。\n进程间的转换是由操作系统内核（Kernel）管理的。内核并不是一个单独的进程，而是操作系统代码的一部分，始终存在于内存中。当一个应用程序需要操作系统完成一些操作，比如读写文件时，它便会执行一个特殊的系统调用指令，然后将控制权移交给内核。内核负责实现程序需要进行的操作，并将结果返回给程序。\n线程 每个进程可以由多个执行单元（线程）组成。由于每个线程都运行在进程的上下文中，且不同线程之间可以共享进程内的代码和全局数据，因此线程要比进程更加高效。\n虚拟内存 虚拟内存让每个进程都看似独占了主存储器的使用权。所有进程的内存空间结构均相同，它被称为虚拟地址空间（Virtual Address Space），其组成如下：\n程序代码和数据：所有进程的代码都始于相同的固定地址，随后则是与全局变量相关的数据区。它们的大小在进程开始运行时固定； 堆（Heap）：调用 malloc或free 这样的 C 标准库函数的结果，其大小可以在程序运行时动态扩缩容； 共享库（Share Libraries）：存放如 C 标准库、数学库这样的共享库的代码和数据的区域； 栈（Stack）：编译器实现函数调用的区域，其大小同样可以在运行时动态扩缩容。如果我们调用一个函数，栈就会增长。而每当一个函数返回时，栈便会缩小； 内核虚拟内存：为内核预留的内存空间。 文件 文件是由字节组成的序列，因此所有的 I/O 设备（包括网络）都可以被看作文件。系统中的所有输入和输出都可以通过 Unix I/O（一组系统调用）对文件进行读写来实现。\n多处理器系统 由单一操作系统内核控制的多个处理器可以共同组成一个多处理器系统（Multiprocessor System），它基于多核（Multi-core）处理器以及超线程技术（Hyperthreading）。\n多核处理器 多核处理器将多个 CPU 集成到单个集成电路芯片中，每个 CPU 都被称为一个核（Cores）。下图展示了一个典型的多核处理器的架构。其中 L1 级别的 Cache 被分成了两部分，分别存储短期内需要使用的指令（下图中的“i-cache”）和数据（下图中的“d-cache”）：\n超线程技术 超线程技术允许单个 CPU 执行多个控制流，有时也被称为同步多线程（Simultaneous Multi-threading）。通过对 CPU 中的程序计数器、寄存器文件等硬件资源进行拷贝，将一个物理 CPU 虚拟为多个逻辑 CPU，从而实现多个线程的并行计算。常规的 CPU 需要大约两万个时钟周期（Clock Cycle）完成不同线程间的切换，而超线程的 CPU 可以在单个时钟周期内决定要执行哪一个线程，这使得 CPU 能够更好地利用它的执行资源。比如一个逻辑 CPU 执行的线程需要等待数据加载到 Cache 中，那么另一个逻辑 CPU 就可以向其借用执行资源继续执行其他线程。\n与使用多个物理 CPU 的传统多处理器系统不同，超线程内核中的逻辑 CPU 共享执行资源。因此当两个线程同时需要某个执行资源时，其中一个线程必须让出资源暂时挂起，直到这些资源空闲后才能继续执行。\n","description":"","tags":["OS"],"title":"CSAPP 读书笔记：计算机系统之旅","uri":"/posts/a-tour-of-computer-systems-note/"},{"content":"前言 在 Kubernetes Pod 是如何跨节点通信的？ 中，我们简单地介绍了 Kubernetes 中的两种 SDN 网络模型：Underlay 和 Overlay。而 Openshift 中的 SDN 则是由 Overlay 网络 OVS（Open vSwitch）实现的，其使用的插件如下：\novs-subnet: 默认插件，提供一个扁平化的 Pod 网络以实现 Pod 与其他任何 Pod 或 Service 的通信； ovs-multitenant：实现多租户管理，隔离不同 Project 之间的网络通信。每个 Project 都有一个 NETID（即 VxLAN 中的 VNID），可以使用oc get netnamespaces命令查看； ovs-networkpolicy：基于 Kubernetes 中的 NetworkPolicy 资源实现网络策略管理。 OVS 在每个 Openshift 节点上都创建了如下网络接口：\nbr0：OpenShift 创建和管理的 OVS 网桥，它会使用 OpenFlow 流表来实现数据包的转发和隔离； vxlan0：VxLAN 隧道端点，即 VTEP（Virtual Tunnel End Point）。用于集群内部的 Pod 跨节点通信； tun0：节点上所有 Pod 的默认网关，用于 Pod 与集群外部以及 Pod 与 Service 之间的通信； veth：Pod 通过veth-pair连接到br0网桥的端点。 使用以下命令可以查看br0上的所有端口及其编号：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 [root@node1 ~]# ovs-ofctl -O OpenFlow13 show br0 OFPT_FEATURES_REPLY (OF1.3) (xid=0x2): dpid:0000ea00372f1940 n_tables:254, n_buffers:0 capabilities: FLOW_STATS TABLE_STATS PORT_STATS GROUP_STATS QUEUE_STATS OFPST_PORT_DESC reply (OF1.3) (xid=0x3): 1(vxlan0): addr:72:23:a0:a9:14:a7 config: 0 state: 0 speed: 0 Mbps now, 0 Mbps max 2(tun0): addr:62:80:67:c6:38:58 config: 0 state: 0 speed: 0 Mbps now, 0 Mbps max 8381(vethd040c191): addr:7a:d9:f4:12:94:5f config: 0 state: 0 current: 10GB-FD COPPER speed: 10000 Mbps now, 0 Mbps max ... LOCAL(br0): addr:76:ab:cf:6f:e1:46 config: PORT_DOWN state: LINK_DOWN speed: 0 Mbps now, 0 Mbps max OFPT_GET_CONFIG_REPLY (OF1.3) (xid=0x5): frags=nx-match miss_send_len=0 考虑到 Openshift 集群的复杂性，我们分别按以下几种场景分析数据包的流向：\n节点内 Pod 互访：Pod to Local Pod Pod 跨节点互访：Pod to Remote Pod Pod 访问 Service：Pod to Service Pod 与集群外部互访：Pod to External 由于 3.11 以上版本的 Openshift 不再以守护进程而是以 Pod 的形式部署 OVS 组件，不方便对 OpenFlow 流表进行查看，本文选用的集群版本为 3.6：\n1 2 3 4 5 6 7 8 [root@node1 ~]# oc version oc v3.6.173.0.5 kubernetes v1.6.1+5115d708d7 features: Basic-Auth GSSAPI Kerberos SPNEGO Server https://test-cluster.ocp.koktlzz.com:8443 openshift v3.6.173.0.5 kubernetes v1.6.1+5115d708d7 另外，实验用集群并未开启 ovs-multitenant，即未进行多租户隔离。整个集群 Pod 网络是扁平化的，所有 Pod 的 VNID 都为默认值 0。\nPod to Local Pod 数据包首先通过veth-pair送往 OVS 网桥br0，随后便进入了br0上的 OpenFlow 流表。我们可以用ovs-ofctl -O OpenFlow13 dump-flows br0命令查看流表中的规则，同时为了让输出结果更加简洁，略去 cookie 和 duration 的信息：\ntable=0, n_packets=62751550874, n_bytes=25344802160312, priority=200,ip,in_port=1,nw_src=10.128.0.0/14,nw_dst=10.130.8.0/23 actions=move:NXM_NX_TUN_ID[0..31]-\u003eNXM_NX_REG0[],goto_table:10 table=0, n_packets=1081527047094, n_bytes=296066911370148, priority=200,ip,in_port=2 actions=goto_table:30 table=0, n_packets=833353346930, n_bytes=329854403266173, priority=100,ip actions=goto_table:20 table0 中关于 IP 数据包的规则主要有三条，其中前两条分别对应流入端口in_port为 1 号端口vxlan0和 2 号端口tun0的数据包。这两条规则的优先级priority都是 200，因此只有在两者均不符合情况下，才会匹配第三条规则。本地 Pod 发出的数据包是由veth端口进入的，因此将转到 table20；\ntable=20, n_packets=607178746, n_bytes=218036511085, priority=100,ip,in_port=8422,nw_src=10.130.9.154 actions=load:0-\u003eNXM_NX_REG0[],goto_table:21 table=21, n_packets=833757781068, n_bytes=329871389393381, priority=0 actions=goto_table:30 table20 会匹配源地址nw_src为 10.130.9.154 且流入端口in_port为 8422 的数据包，随后将 Pod1 的 VNID 0 作为源 VNID 存入寄存器 0 中，经由 table21 转到 table30；\ntable=30, n_packets=1116329752668, n_bytes=294324730186808, priority=200,ip,nw_dst=10.130.8.0/23 actions=goto_table:70 table=30, n_packets=59672345347, n_bytes=41990349575805, priority=100,ip,nw_dst=10.128.0.0/14 actions=goto_table:90 table=30, n_packets=21061319859, n_bytes=29568807363654, priority=100,ip,nw_dst=172.30.0.0/16 actions=goto_table:60 table=30, n_packets=759636044089, n_bytes=280576476818108, priority=0,ip actions=goto_table:100 table30 中匹配数据包目的地址nw_dst的规则有四条，前三条分别对应本节点内 Pod 的 CIDR 网段 10.130.8.0/23、集群内 Pod 的 CIDR 网段 10.128.0.0/14 和 Service 的 ClusterIP 网段 172.30.0.0/16。第四条优先级最低，用于 Pod 对集群外部的访问。数据包的目的地址 10.130.9.158 符合第一条规则，且第一条规则的优先级最高，因此将转到 table70；\ntable=70, n_packets=597219981, n_bytes=243824445346, priority=100,ip,nw_dst=10.130.9.158 actions=load:0-\u003eNXM_NX_REG1[],load:0x20ea-\u003eNXM_NX_REG2[],goto_table:80 table70 匹配目的地址nw_dst为 Pod2 IP 10.130.9.158 的数据包，并将 Pod2 的 VNID 0 作为目的 VNID 存入寄存器 1 中。同时端口号0x20ea被保存到寄存器 2 中，然后转到 table80；\ntable=80, n_packets=1112713040332, n_bytes=293801616636499, priority=200 actions=output:NXM_NX_REG2[] table80 比较寄存器 0 和寄存器 1 中保存的源/目的 VNID。若二者一致，则根据寄存器 2 中保存的端口号将数据包送出。\n端口号0x20ea是一个十六进制数字，即十进制数 8426。而 Pod2 正是通过 8426 号端口设备vethba48c6de连接到br0上，因此数据包便最终通过它流入到了 Pod2 中。\n1 2 [root@node1 ~]# ovs-ofctl -O OpenFlow13 show br0 | grep 8426 8426(vethba48c6de): addr:e6:b2:7e:42:41:91 Pod to Remote Pod Packet in Local Pod 数据包依然首先通过veth-pair送往 OVS 网桥br0，随后便进入了br0上的 OpenFlow 流表：\ntable=0, n_packets=830232155588, n_bytes=328613498734351, priority=100,ip actions=goto_table:20 table=20, n_packets=1901, n_bytes=299279, priority=100,ip,in_port=6635,nw_src=10.130.9.154 actions=load:0-\u003eNXM_NX_REG0[],goto_table:21 table=21, n_packets=834180030914, n_bytes=330064497351030, priority=0 actions=goto_table:30 与 Pod to Local Pod 的流程一致，数据包根据规则转到 table30；\ntable=30, n_packets=59672345347, n_bytes=41990349575805, priority=100,ip,nw_dst=10.128.0.0/14 actions=goto_table:90 table=30, n_packets=1116329752668, n_bytes=294324730186808, priority=200,ip,nw_dst=10.130.8.0/23 actions=goto_table:70 数据包的目的地址为 Pod2 IP 10.131.8.206，不属于本节点 Pod 的 CIDR 网段 10.130.8.0/23，而属于集群 Pod 的 CIDR 网段 10.128.0.0/14，因此转到 table90；\ntable=90, n_packets=15802525677, n_bytes=6091612778189, priority=100,ip,nw_dst=10.131.8.0/23 actions=move:NXM_NX_REG0[]-\u003eNXM_NX_TUN_ID[0..31],set_field:10.122.28.8-\u003etun_dst,output:1 table90 根据目的 IP 的所属网段 10.131.8.0/23 判断其位于 Node2 上，于是将 Node2 IP 10.122.28.8 设置为tun_dst。并且从寄存器 0 中取出 VNID 的值，从 1 号端口vxlan0输出。\nvxlan0作为一个 VTEP 设备（参见 Overlay Network），将根据 table90 发来的信息，对数据包进行一层封装：\n目的地址（dst IP） –\u003e tun_dst –\u003e 10.122.28.8 源地址（src IP） –\u003e Node1 IP –\u003e 10.122.28.7 源 VNID –\u003e NXM_NX_TUN_ID[0..31] –\u003e 0 封装后的数据包源/目的地址均为节点 IP，因此从 Node1 的网卡流出后，可以通过物理网络设备转发到 Node2 上。\nPacket in Remote Pod Node2 上的vxlan0对数据包进行解封，随后从br0上的 1 号端口进入 OpenFlow 流表中：\ntable=0, n_packets=52141153195, n_bytes=17269645342781, priority=200,ip,in_port=1,nw_src=10.128.0.0/14,nw_dst=10.131.8.0/23 actions=move:NXM_NX_TUN_ID[0..31]-\u003eNXM_NX_REG0[],goto_table:10 table0 判断数据包的流入端口in_port、源 IP 所属网段nw_src和目的 IP 所属网段nw_dst均符合该条规则，于是保存数据包中的源 VNID 到寄存器 0 后转到 table10；\ntable=10, n_packets=10147760036, n_bytes=4060517391502, priority=100,tun_src=10.122.28.7 actions=goto_table:30 table10 确认 VxLAN 隧道的源 IPtun_src就是节点 Node1 的 IP 地址，于是转到 table30；\ntable=30, n_packets=678759566065, n_bytes=172831151192704, priority=200,ip,nw_dst=10.131.8.0/23 actions=goto_table:70 table30 确认数据包的目的 IP（即 Pod2 IP）存在于 Node2 中 Pod 的 CIDR 网段内，因此转到 table70；\ntable=70, n_packets=193211683, n_bytes=27881218388, priority=100,ip,nw_dst=10.131.8.206 actions=load:0-\u003eNXM_NX_REG1[],load:0x220-\u003eNXM_NX_REG2[],goto_table:80 table70 发现数据包的目的 IP 与 Pod2 IP 相符，于是将 Pod2 的 VNID 作为目的 VNID 存于寄存器 1 中，将0x220（十进制数 544）保存在寄存器 2 中，然后转到 table80；\ntable=80, n_packets=676813794014, n_bytes=172576112594488, priority=200 actions=output:NXM_NX_REG2[] table80 会检查保存在寄存器 0 和寄存器 1 中的源/目的 VNID，若相等（此例中均为 0），则从 544 号端口输出。\nbr0上的 544 端口对应的网络接口是vethe9f523a9，因此数据包便最终通过它流入到了 Pod2 中。\n1 2 [root@node2 ~]# ovs-ofctl -O OpenFlow13 show br0 | grep 544 544(vethe9f523a9): addr:b2:a1:61:00:dc:3b Pod to Service 在本例中，Pod1 通过 Service 访问其后端的 Pod2，其 ClusterIP 为 172.30.107.57，监听的端口为 8080：\n1 2 3 [root@node1 ~]# oc get svc NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE myService 172.30.107.57 \u003cnone\u003e 8080/TCP 2y table=30, n_packets=21065939280, n_bytes=29573447694924, priority=100,ip,nw_dst=172.30.0.0/16 actions=goto_table:60 数据包在送到 OpenFlow 流表 table30 前的步骤与 Pod to Local Pod 和 Pod to Remote Pod 中的情况一致，但数据包的目的地址变为了 myService 的 ClusterIP。因此将匹配nw_dst中的 172.30.0.0/16 网段，转到 table60；\ntable=60, n_packets=0, n_bytes=0, priority=100,tcp,nw_dst=172.30.107.57,tp_dst=8080 actions=load:0-\u003eNXM_NX_REG1[],load:0x2-\u003eNXM_NX_REG2[],goto_table:80 table60 匹配目的地址nw_dst为 172.30.107.57 且目的端口为 8080 的数据包，并将 Pod1 的 VNID 0 保存到寄存器 1 中，将0x2（十进制数字 2）保存到寄存器 2 中，转到 table80；\ntable=80, n_packets=1113435014018, n_bytes=294106102133061, priority=200 actions=output:NXM_NX_REG2[] table80 根据寄存器 2 中的数字将数据包从 2 号端口tun0传出，随后进入节点的 iptables 处理流中：\n由于 Service 的实现依赖于 NAT（上图中的紫色方框），我们可以在 NAT 表中看到与之相关的规则：\n1 2 3 4 5 6 7 8 [root@node1 ~]# iptables -t nat -nvL Chain OUTPUT (policy ACCEPT 4753 packets, 489K bytes) pkts bytes target prot opt in out source destination 2702M 274G KUBE-SERVICES all -- * * 0.0.0.0/0 0.0.0.0/0 /* kubernetes service portals */ Chain KUBE-SERVICES (2 references) pkts bytes target prot opt in out source destination 4 240 KUBE-SVC-QYWOVDCBPMWAGC37 tcp -- * * 0.0.0.0/0 172.30.107.57 /* demo/myService:8080-8080 cluster IP */ tcp dpt:8080 本机产生的数据包（Locally-generated Packet）首先进入OUTPUT链，然后匹配到自定义链KUBE-SERVICES。其目的地址为 Service 的 ClusterIP 172.30.107.57，因此将再次跳转到对应的KUBE-SVC-QYWOVDCBPMWAGC37链：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 Chain KUBE-SVC-QYWOVDCBPMWAGC37 (1 references) pkts bytes target prot opt in out source destination 1 60 KUBE-SEP-AF5DIL6JV3XLLV6G all -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ statistic mode random probability 0.50000000000 1 60 KUBE-SEP-ADAJHSV7RYS5DUBX all -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ Chain KUBE-SEP-ADAJHSV7RYS5DUBX (1 references) pkts bytes target prot opt in out source destination 0 0 KUBE-MARK-MASQ all -- * * 10.131.8.206 0.0.0.0/0 /* demo/myService:8080-8080 */ 0 0 DNAT tcp -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ tcp to:10.131.8.206:8080 Chain KUBE-SEP-AF5DIL6JV3XLLV6G (1 references) pkts bytes target prot opt in out source destination 0 0 KUBE-MARK-MASQ all -- * * 10.128.10.57 0.0.0.0/0 /* demo/myService:8080-8080 */ 23 1380 DNAT tcp -- * * 0.0.0.0/0 0.0.0.0/0 /* demo/myService:8080-8080 */ tcp to:10.128.10.57:8080 KUBE-SVC-QYWOVDCBPMWAGC37链下有两条完全相同的匹配规则，对应了该 Service 后端的两个 Pod。KUBE-SEP-ADAJHSV7RYS5DUBX链和 KUBE-SEP-AF5DIL6JV3XLLV6G链能够执行 DNAT 操作，分别将数据包的目的地址转化为 Pod IP 10.131.8.206 和 10.128.10.57。在一次通信中只会有一条链生效，这体现了 Service 的负载均衡能力。\n完成OUTPUTDNAT 的数据包将进入节点的路由判断（Routing Decision）。由于当前目的地址已经属于集群内 Pod 的 CIDR 网段 10.128.0.0/14，数据包将从tun0端口再次进入 OVS 网桥br0中。\n1 2 3 4 5 6 7 8 9 [rootnode1 ~]# route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 10.122.28.1 0.0.0.0 UG 0 0 0 eth0 10.122.28.0 0.0.0.0 255.255.255.128 U 0 0 0 eth0 10.128.0.0 0.0.0.0 255.252.0.0 U 0 0 0 tun0 169.254.0.0 0.0.0.0 255.255.0.0 U 1008 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0 172.30.0.0 0.0.0.0 255.255.0.0 U 0 0 0 tun0 不过数据包在进入br0之前，还需要经过 iptables 中的POSTROUTING链，完成一次MASQUERADE：数据包的源地址转换为其传出端口的 IP，即tun0的 IP 10.130.8.1。\n1 2 3 4 5 6 7 8 9 10 11 [root@node1 ~]# iptables -t nat -nvL Chain POSTROUTING (policy ACCEPT 5083 packets, 524K bytes) pkts bytes target prot opt in out source destination 2925M 288G OPENSHIFT-MASQUERADE all -- * * 0.0.0.0/0 0.0.0.0/0 /* rules for masquerading OpenShift traffic */ Chain OPENSHIFT-MASQUERADE (1 references) pkts bytes target prot opt in out source destination 321M 19G MASQUERADE all -- * * 10.128.0.0/14 0.0.0.0/0 /* masquerade pod-to-service and pod-to-external traffic */ [root@node1 ~]# ip a | grep tun0 16: tun0: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1450 qdisc noqueue state UNKNOWN qlen 1000 inet 10.130.8.1/23 scope global tun0 本例中 Service 的后端 Pod 均在 Pod1 所在的节点外，因此数据包第二次进入 OpenFlow 流表时匹配的规则基本与 Pod to Remote Pod 一致：\ntable=0, n_packets=1081527047094, n_bytes=296066911370148, priority=200,ip,in_port=2 actions=goto_table:30 table=30, n_packets=59672345347, n_bytes=41990349575805, priority=100,ip,nw_dst=10.128.0.0/14 actions=goto_table:90 table=90, n_packets=15802525677, n_bytes=6091612778189, priority=100,ip,nw_dst=10.131.8.0/23 actions=move:NXM_NX_REG0[]-\u003eNXM_NX_TUN_ID[0..31],set_field:10.122.28.8-\u003etun_dst,output:1 其传递流程如下图所示：\nPod2 返回的数据包在到达 Node1 后将被vxlan0解封装，然后根据其目的地址tun0进入 OpenFlow 流表：\ntable=0, n_packets=1084362760247, n_bytes=297224518823222, priority=200,ip,in_port=2 actions=goto_table:30 table=30, n_packets=20784385211, n_bytes=4742514750371, priority=300,ip,nw_dst=10.130.8.1 actions=output:2 数据包从 2 号端口tun0送出后进入节点的 iptables 处理流，随后将触发 Connection Tracking：根据/proc/net/nf_conntrack文件中的记录进行“DeNAT”。返回数据包的源/目的地址从 Pod2 IP 10.131.8.206 和 tun0 IP 10.130.8.1，变回 Service 的 ClusterIP 172.30.107.57 和 Pod1 IP 10.130.9.154。\n1 2 [root@node1 ~]# cat /proc/net/nf_conntrack | grep -E \"src=10.130.9.154.*dst=172.30.107.57.*dport=8080.*src=10.131.8.206\" ipv4 2 tcp 6 431986 ESTABLISHED src=10.130.9.154 dst=172.30.107.57 sport=80 dport=8080 src=10.131.8.206 dst=10.130.8.1 sport=8080 dport=80 [ASSURED] mark=0 secctx=system_u:object_r:unlabeled_t:s0 zone=0 use=2 Pod to External 数据包依然首先通过veth-pair送往 OVS 网桥br0，随后便进入了br0上的 OpenFlow 流表：\ntable=0, n_packets=837268653828, n_bytes=331648403594327, priority=100,ip actions=goto_table:20 table=20, n_packets=613807687, n_bytes=220557571042, priority=100,ip,in_port=8422,nw_src=10.130.9.154 actions=load:0-\u003eNXM_NX_REG0[],goto_table:21 table=21, n_packets=837674296060, n_bytes=331665441915651, priority=0 actions=goto_table:30 table=30, n_packets=759636044089, n_bytes=280576476818108, priority=0,ip actions=goto_table:100 table=100, n_packets=761732023982, n_bytes=282091648536325, priority=0 actions=output:2 数据包从tun0端口传出后进入节点的路由表及 iptables 处理流：\n1 2 3 4 5 6 7 8 Chain POSTROUTING (policy ACCEPT 2910 packets, 299K bytes) pkts bytes target prot opt in out source destination 0 0 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 2940M 289G OPENSHIFT-MASQUERADE all -- * * 0.0.0.0/0 0.0.0.0/0 /* rules for masquerading OpenShift traffic */ Chain OPENSHIFT-MASQUERADE (1 references) pkts bytes target prot opt in out source destination 322M 19G MASQUERADE all -- * * 10.128.0.0/14 0.0.0.0/0 /* masquerade pod-to-service and pod-to-external traffic */ 访问集群外部显然需要通过节点的默认网关，因此数据包将从节点网卡eth0送出。而在POSTROUTING链中，数据包的源地址由 Pod IP 转换为了eth0的 IP 10.122.28.7。完整流程如下图所示（图中的“Router”指的是路由器而非 Openshift 中的概念）：\nFuture Work 本文并未涉及 External to Pod 的场景，它是如何实现的？我们都知道 Openshift 是通过 Router（HAProxy）来暴露集群内部服务的，那么数据包在传输过程中的 NAT 操作是怎样进行的？ 除了本文提到的几种网络接口外，Openshift 节点上还存在着ovs-system和vxlan_sys_4789。它们的作用是什么？ 更新：vxlan_sys_4789就是上文提到的端口vxlan0，而ovs-system是一个历史遗留问题，没有任何作用； Openshift 4.X 版本的网络模型与本文实验用的 3.6 版本相比有那些变化？ 参考文献 OpenFlow - Wikipedia\nOVS 在云项目中的使用\nOpenShift SDN - OpenShift Container Platform 3.11\n理解 OpenShift（3）：网络之 SDN\n[译] 深入理解 iptables 和 netfilter 架构\nLinux Netfilter: How does connection tracking track connections changed by NAT?\n","description":"","tags":["Openshift","Network","Container","CNI","Open vSwitch"],"title":"对 Openshift SDN 网络模型的一些探索","uri":"/posts/explorations-on-the-openshift-sdn-network-model/"},{"content":"前言 A Guide to the Kubernetes Networking Model 一文生动形象地介绍了 Kubernetes 中的网络模型，然而受篇幅所限，作者并没有对 Pod 跨节点通信时数据包在节点之间传递的细节进行过多讨论。\n我们已经知道，Docker 使用端口映射的方式实现不同主机间容器的通信，Kubernetes 中同样也有 hostPort 的概念。但是当节点和 Pod 的数量上升后，手动管理节点上绑定的端口是十分困难的，这也是NodePort类型的 Service 的缺点之一。而一旦 Pod 不再“借用”节点的 IP 和端口来暴露自身的服务，就不得不面临一个棘手的问题：Pod 的本质是节点中的进程，节点外的物理网络设备（交换机/路由器）并不知晓 Pod 的存在。它们在接收目的地址为 Pod IP 的数据包时，无法完成进一步的传输工作。\n为此我们需要使用一些 CNI（Container Network Interface）插件来完善 Kubernetes 集群的网络模型，这种新型的网络设计理念被称为 SDN（Software-defined Networking）。根据 SDN 实现的层级，我们可以将其分为 Underlay Network 和 Overlay Network：\nOverlay 网络允许设备跨越底层物理网络（Underlay Network）进行通信，而底层却并不知晓 Overlay 网络的存在。Underlay 网络是专门用来承载用户 IP 流量的基础架构层，它与 Overlay 网络之间的关系有点类似物理机和虚拟机。Underlay 网络和物理机都是真正存在的实体，它们分别对应着真实存在的网络设备和计算设备，而 Overlay 网络和虚拟机都是依托在下层实体使用软件虚拟出来的层级。\nUnderlay Network 利用 Underlay Network 实现 Pod 跨节点通信，既可以只依赖 TCP/IP 模型中的二层协议，也可以使用三层。但无论哪种实现方式，都必须对底层的物理网络有所要求。\n二层 如图所示，Pod 与节点的 IP 地址均处于同一网段。当 Pod1 向另一节点上的 Pod2 发起通信时，数据包首先通过veth-pair和cbr0送往 Node1 的网卡。由于目的地址 10.86.44.4 与 Node1 同网段，因此 Node1 将通过 ARP 广播请求 10.86.44.4 的 MAC 地址。\nCNI 插件不仅为 Pod 分配 IP 地址，它还会将每个 Pod 所在的节点信息下发给 SDN 交换机。这样当 SDN 交换机接收到 ARP 请求时，将会答复 Pod2 所在节点 Node2 的 MAC 地址，数据包也就顺利地送到了 Node2 上。\n阿里云 Terway 模式的 ACK 服务使用的便是这种网络模型，只不过 Pod 间通信使用的 SDN 交换机不再是节点的交换机（下图中的“Node vSwitch”），而是单独创建的“Pod vSwitch”：\n三层 如图所示，Pod 与节点的 IP 地址不再处于同一网段。当 Pod1 向另一节点上的 Pod2 发起通信时，数据包首先通过veth-pair和cbr0进入宿主机内核的路由表（Routing Table）。CNI 插件在该表中添加了若干条路由规则，如目的地址为 Pod2 IP 的网关为 Node2 的 IP。这样数据包的目的 MAC 地址就变为了 Node2 的 MAC 地址，它将会通过交换机发送到 Node2 上。\n由于这种实现方式基于三层协议，因此不要求两节点处于同一网段。不过需要将目的地址为 Pod2 IP 的网关设置为 SDN 路由器的 IP，且该路由器能够知晓目的 Pod 所在的节点。这样数据包的目的 MAC 地址就会首先变为 SDN 路由器的 MAC 地址，经过路由器后再变为 Node2 的 MAC 地址：\n通过上面的讨论我们发现，想要实现三层的 Underlay 网络，需要在多个节点间下发和同步路由表。于是很容易想到用于交换路由信息的 BGP（Border Gateway Protocol）协议：\n边界网关协议（英语：Border Gateway Protocol，缩写：BGP）是互联网上一个核心的去中心化自治路由协议。它通过维护 IP 路由表或“前缀”表来实现自治系统（AS）之间的可达性，属于矢量路由协议。BGP 不使用传统的内部网关协议（IGP）的指标，而使用基于路径、网络策略或规则集来决定路由。因此，它更适合被称为矢量性协议，而不是路由协议。\n对于 Calico 的 BGP 模式来说，我们可以把集群网络模型视为在每个节点上都部署了一台虚拟路由器。路由器可以与其他节点上的路由器通过 BGP 协议互通，它们被称为一对 BGP Peers。Calico 的默认部署方式为 Full-mesh，即创建一个完整的内部 BGP 连接网，每个节点上的路由器均互为 BGP Peers。这种方式仅适用于 100 个节点以内的中小型集群，在大型集群中使用的效率低下。而 Route Reflectors 模式则将部分节点作为路由反射器，其他节点上的路由器只需与路由反射器互为 BGP Peers。这样便可以大大减少集群中 BGP Peers 的数量，从而提升效率。\nOverlay Network Overlay 网络可以通过多种协议实现，但通常是对 IP 数据包进行一层外部封装（Encapsulation）。这样底层的 Underlay 网络便只会看到外部封装的数据，而无需处理内部的原有数据。Overlay 网络发送数据包的方式取决于其类型和使用的协议，如基于 VxLAN 实现 Overlay 网络，数据包将被外部封装后以 UDP 协议进行发送：\nOverlay 网络的实现并不依赖于底层物理网络设备，因此我们就以一个两节点不处于同一网段且 Pod 与节点亦处于不同网段的例子来说明 Overlay 网络中的数据包传递过程。集群网络使用 VxLAN 技术组建，虚拟网络设备 VTEP（Virtual Tunnel End Point）将会完成数据包的封装和解封操作。\nNode1 上的 VTEP 收到 Pod1 发来的数据包后，首先会在本地的转发表中查找目的 Pod 所在节点的 IP，即 192.168.1.100。随后它将本机 IP 地址 10.86.44.2、Node2 的 IP 地址 192.168.1.100 和 Pod1 的 VNID（VxLAN Network Identifier）封装在原始数据包外，从 Node1 的网络接口 eth0 送出。由于新构建的数据包源/目的地址均为节点的 IP，因此外部的路由器可以将其转发到 Node2 上。Node2 中的 VTEP 在接收到数据包后会首先进行解封，若源 VNID（Pod1 的 VNID）与目的 VNID（Pod2 的 VNID）一致，便会根据原始数据包中的目的地址 172.100.1.2 将其发送到 Pod2 上。此处的 VNID 检查，主要是为了实现集群的网络策略管理和多租户隔离。\n通过对上述几种 SDN 网络模型的讨论，我们发现只有 Overlay 网络需要对数据包进行封装和解封，因此它的性能相比于 Underlay 网络较差。但 Overlay 网络也有以下优点：\n对底层网络设备的依赖性最小。即使 Pod 所在的节点发生迁移，依然可以通过 Overlay 网络与原集群实现二层网络的互通； VNID 共有 24 位，因此可以构造出约 1600 万个互相隔离的虚拟网络。 Future Work 除了 VxLAN 以外，还有哪些技术可以实现 Overlay 网络？它们是怎样传输数据的呢？ 本文在讨论 Underlay 网络时提到了 Terway 和 Calico，那么有哪些使用 Overlay 网络的 CNI 插件呢？ 更新：我在 对 Openshift SDN 网络模型的一些探索 中介绍了基于 Overlay 网络的 Open vSwitch； 近年来发展迅速的 Cilium 是怎样实现 SDN 网络的？它所依赖的 eBPF 技术又是什么？ 参考文献 Software-defined networking - Wikipedia\nAbout Kubernetes Networking\n使用 Terway 网络插件\n边界网关协议 - Wikipedia\nConfigure BGP peering - Calico\n为什么集群需要 Overlay 网络\n","description":"","tags":["Kubernetes","Container","Network","CNI","Calico"],"title":"Kubernetes Pod 是如何跨节点通信的？","uri":"/posts/how-kubernetes-pods-communicate-across-nodes/"},{"content":"前言 通常，Kafka 中的每个 Partiotion 中有多个副本 (Replica) 以实现高可用。想象一个场景，Consumer 正在消费 Leader 中 Offset = 10 的数据，而此时 Follower 中只同步到 Offset = 8。那么当 Leader 所在的 Broker 宕机后，当前 Follower 经选举成为新的 Leader，Consumer 再次消费时便会报错。因此，Kafka 引入了 HW（High Watermark，高水位）机制来保证副本数据的可靠性和一致性。\nHW 是什么？ HW 定义了消息的可见性，即标识 Partition 中的哪些消息是可以被 Consumer 消费的，只有小于 HW 值的消息才被认为是已备份或已提交的（Committed）。而 LEO（Log End Offset）则表示副本写入下一条消息的 Offset，因此同一副本的 HW 值永远不会大于其 LEO 值。\n当集群中副本所在的 Broker 发生故障而后恢复时，副本先将数据截断（Truncation）到其 HW 处（LEO 等于 HW），然后再开始向 Leader 同步数据。\nHW 的更新机制 每一个副本都保存了其 HW 值和 LEO 值，即 Leader HW（实际上也是 Partition HW）、Leader LEO 和 Follower HW、Follower LEO。而 Leader 所在的 Broker 上还保存了其他 Follower 的 LEO 值，即 Remote LEO。上述几个值的更新流程如下：\n如图所示，当 Producer 向 log 文件写入数据时，Leader LEO 首先被更新。而 Remote LEO 要等到 Follower 向 Leader 发送同步请求（Fetch）时，才会根据请求携带的当前 Follower LEO 值更新。随后，Leader 计算所有副本 LEO 的最小值，将其作为新的 Leader HW。考虑到 Leader HW 只能单调递增，因此还增加了一个 LEO 最小值与当前 Leader HW 的比较，防止 Leader HW 值降低（max[Leader HW, min(All LEO)]）。\nFollower 在接收到 Leader 的响应（Response）后，首先将消息写入 log 文件中，随后更新 Follower LEO。由于 Response 中携带了新的 Leader HW，Follower 将其与刚刚更新过的 Follower LEO 相比较，取最小值作为 Follower HW（min(Follower LEO, Leader HW)）。\n举例来说，如果一开始 Leader 和 Follower 中没有任何数据，即所有值均为 0。那么当 Prouder 向 Leader 写入第一条消息，上述几个值的变化顺序如下：\nLeader LEO Remote LEO Leader HW Follower LEO Follower HW Producer Write 1 0 0 0 0 Follower Fetch 1 0 0 0 0 Leader Update HW 1 0 0 0 0 Leader Response 1 0 0 1 0 Follower Update HW 1 0 0 1 0 Follower Fetch 1 1 0 1 0 Leader Update HW 1 1 1 1 0 Leader Response 1 1 1 1 0 Follower Update HW 1 1 1 1 1 HW 的隐患 通过上面的表格我们发现，Follower 往往需要进行两次 Fetch 请求才能成功更新 HW。Follower HW 在某一阶段内总是落后于 Leader HW，因此副本在根据 HW 值截取数据时将有可能发生数据的丢失或不一致。\n图中两副本的 LEO 均为 2，但 Leader 副本 B 上的 HW 为 2，Follower 副本 A 上的 HW 为 1。正常情况下，副本 A 将在接收 Leader Response 后根据 Leader HW 更新其 Follower HW 为 2。但假如此时副本 A 所在的 Broker 重启，它会把 Follower LEO 修改为重启前自身的 HW 值 1，因此数据 M1（Offset = 1）被截断。当副本 A 重新向副本 B 发送同步请求时，如果副本 B 所在的 Broker 发生宕机，副本 A 将被选举成为新的 Leader。即使副本 B 所在的 Broker 能够成功重启且其 LEO 值依然为 2，但只要它向当前 Leader（副本 A）发起同步请求后就会更新其 HW 为 1（计算min(Follower LEO, Leader HW)），数据 M1（Offset = 1）随即被截断。如果min.insync.replicas参数为 1，那么 Producer 不会因副本 A 没有同步成功而重新发送消息，M1 也就永远丢失了。\n图中 Leader 副本 B 写入了两条数据 M0 和 M1，Follower 副本 A 只写入了一条数据 M0。此时 Leader HW 为 2，Follower HW 为 1。如果在 Follower 同步第二条数据前，两副本所在的 Broker 均发生重启且副本 B 所在的 Broker 先重启成功，那么副本 A 将成为新的 Leader。这时 Producer 向其写入数据 M2，副本 A 作为集群中的唯一副本，更新其 HW 为 2。当副本 B 所在的 Broker 重启后，它将向当前的 Leader 副本 A 同步数据。由于两者的 HW 均为 2，因此副本 B 不需要进行任何截断操作。在这种情况下，副本 B 中的数据为重启前的 M0 和 M1，副本 A 中的数据却是 M0 和 M2，副本间的数据出现了不一致。\nLeader Epoch Kakfa 引入 Leader Epoch 后，Follower 就不再参考 HW，而是根据 Leader Epoch 信息来截断 Leader 中不存在的消息。这种机制可以弥补基于 HW 的副本同步机制的不足，Leader Epoch 由两部分组成：\nEpoch：一个单调增加的版本号。每当 Leader 副本发生变更时，都会增加该版本号。Epoch 值较小的 Leader 被认为是过期 Leader，不能再行使 Leader 的权力； 起始位移（Start Offset）：Leader 副本在该 Epoch 值上写入首条消息的 Offset。 举例来说，某个 Partition 有两个 Leader Epoch，分别为 (0, 0) 和 (1, 100)。这意味该 Partion 历经一次 Leader 副本变更，版本号为 0 的 Leader 从 Offset = 0 处开始写入消息，共写入了 100 条。而版本号为 1 的 Leader 则从 Offset = 100 处开始写入消息。\n每个副本的 Leader Epoch 信息既缓存在内存中，也会定期写入消息目录下的 leaderer-epoch-checkpoint 文件中。当一个 Follower 副本从故障中恢复重新加入 ISR 中，它将：\n向 Leader 发送 LeaderEpochRequest，请求中包含了 Follower 的 Epoch 信息； Leader 将返回其 Follower 所在 Epoch 的 Last Offset； 如果 Leader 与 Follower 处于同一 Epoch，那么 Last Offset 显然等于 Leader LEO； 如果 Follower 的 Epoch 落后于 Leader，则 Last Offset 等于 Follower Epoch + 1 所对应的 Start Offset。这可能有点难以理解，我们还是以 (0, 0) 和 (1, 100) 为例进行说明：Offset = 100 的消息既是 Epoch = 1 的 Start Offset，也是 Epoch = 0 的 Last Offset； Follower 接收响应后根据返回的 Last Offset 截断数据； 在数据同步期间，只要 Follower 发现 Leader 返回的 Epoch 信息与自身不一致，便会随之更新 Leader Epoch 并写入磁盘。 在刚刚介绍的数据丢失场景中，副本 A 所在的 Broker 重启后根据自身的 HW 将数据 M1 截断。而现在，副本 A 重启后会先向副本 B 发送一个请求（LeaderEpochRequest）。由于两副本的 Epoch 均为 0，副本 B 返回的 Last Offset 为 Leader LEO 值 2。而副本 A 上并没有 Offset 大于等 2 的消息，因此无需进行数据截断，同时其 HW 也会更新为 2。之后副本 B 所在的 Broker 宕机，副本 A 成为新的 Leader，Leader Epoch 随即更新为 (1, 2)。当副本 B 重启回来并向当前 Leader 副本 A 发送 LeaderEpochRequest，得到的 Last Offset 为 Epoch = 1 对应的 Start Offset 值 2。同样，副本 B 中消息的最大 Offset 值只有 1，因此也无需进行数据截断，消息 M1 成功保留了下来。\n在刚刚介绍的数据不一致场景中，由于最后两副本 HW 值相等，因此没有将不一致的数据截断。而现在，副本 A 重启后并便会更新 Leader Epoch 为 (1, 1)，同时也会更新其 HW 值为 2。副本 B 重启后向当前 Leader 副本 A 发送 LeaderEpochRequest，得到的 Last Offset 为 Epoch = 1 对应的 Start Offset 值 1，因此截断 Offset = 1 的消息 M1。这样只要副本 B 再次发起请求同步消息 M2，两副本的数据便可以保持一致。\n值得一提的是，Leader Epoch 机制在min.insync.replicas参数为 1 且unclean.leader.election.enabled参数为true时依然无法保证数据的可靠性。感兴趣的读者可以阅读 KIP-101 - Alter Replication Protocol to use Leader Epoch rather than High Watermark for Truncation 文中的附录部分。\n参考文献 KIP-101 - Alter Replication Protocol to use Leader Epoch rather than High Watermark for Truncation\n","description":"","tags":["Kafka"],"title":"Kafka 是如何同步副本的？","uri":"/posts/how-does-kafka-synchronize-replicas/"}]